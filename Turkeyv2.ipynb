{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Turkeyv2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBxXNdvTpJrc",
        "colab_type": "code",
        "outputId": "c9da0bfe-7f61-49e2-df09-8d21345aa480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "#Created By Panther Creek High School Data Science Club\n",
        "#CSV File can be found on pchsdatascience.com\n",
        "\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "import io\n",
        "import math\n",
        "import requests\n",
        "\n",
        "\n",
        "print(tf.test.gpu_device_name())\n",
        "\n",
        "\n",
        "#Uncomment if you want to manually load a csv\n",
        "'''\n",
        "print(\"Please Load Production CSV File\")\n",
        "uploaded = files.upload()\n",
        "data = pd.read_csv(io.BytesIO(uploaded[\"ProductionData.csv\"]))\n",
        "'''\n",
        "\n",
        "# Fetch Dataset from Our Website\n",
        "response = requests.get('https://pchsdatascience.com/wp-content/uploads/2019/12/ProductionData.csv')\n",
        "file_object = io.StringIO(response.content.decode('utf-8'))\n",
        "data = pd.read_csv(file_object)\n",
        "\n",
        "#Load CSV Data\n",
        "data.head()\n",
        "\n",
        "#Remove Header and Footer from file\n",
        "d1 = data.iloc[2:698]\n",
        "dates = d1.iloc[:,0]\n",
        "\n",
        "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 2} ) \n",
        "sess = tf.Session(config=config) \n",
        "keras.backend.set_session(sess)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShtuW5_P1e_O",
        "colab_type": "code",
        "outputId": "fa76c5b1-5649-432f-d81f-b529a1b99c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        }
      },
      "source": [
        "#Create Pandas Dataframe\n",
        "turkey = d1.iloc[:,13]\n",
        "pd.to_numeric(turkey)\n",
        "dataset = pd.DataFrame({'Date': dates, 'Weight': turkey})\n",
        "dataset = dataset.iloc[::-1]\n",
        "dataset.index = np.arange(0, len(dataset))\n",
        "dataset.index.name = \"Month number\"\n",
        "\n",
        "#view dataframe\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Weight</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Month number</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jan-1960</td>\n",
              "      <td>22.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Feb-1960</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mar-1960</td>\n",
              "      <td>13.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Apr-1960</td>\n",
              "      <td>16.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>May-1960</td>\n",
              "      <td>27.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>691</th>\n",
              "      <td>Aug-2017</td>\n",
              "      <td>543.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>692</th>\n",
              "      <td>Sep-2017</td>\n",
              "      <td>467.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>693</th>\n",
              "      <td>Oct-2017</td>\n",
              "      <td>554.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>Nov-2017</td>\n",
              "      <td>517.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>Dec-2017</td>\n",
              "      <td>461.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>696 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Date Weight\n",
              "Month number                 \n",
              "0             Jan-1960   22.1\n",
              "1             Feb-1960   14.0\n",
              "2             Mar-1960   13.4\n",
              "3             Apr-1960   16.2\n",
              "4             May-1960   27.1\n",
              "...                ...    ...\n",
              "691           Aug-2017  543.1\n",
              "692           Sep-2017  467.9\n",
              "693           Oct-2017  554.2\n",
              "694           Nov-2017  517.2\n",
              "695           Dec-2017  461.1\n",
              "\n",
              "[696 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eEDylljpP1l",
        "colab_type": "code",
        "outputId": "af7b6717-bfd6-491d-cf56-fff26ac8a6b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#Create Array stroring Monthly Data from data frame\n",
        "arrdata = dataset.to_numpy()\n",
        "arrMonth = []\n",
        "arrDate = []\n",
        "arrWeight = []\n",
        "\n",
        "for i in range(len(arrdata)):\n",
        "    arrMonth.append(i)\n",
        "    arrDate.append(arrdata[i][0])\n",
        "    arrWeight.append(float(arrdata[i][1]))\n",
        "\n",
        "#plot monthly production data\n",
        "plt.scatter(arrMonth, arrWeight)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFUVRehBV7oqiKD3I/w+D2Mqhxdy2wAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj4kfV1E2hVO",
        "colab_type": "code",
        "outputId": "1df9ca63-d24c-46b1-f6bb-42c86095b750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "arrWeightyr = []\n",
        "arrYear = []\n",
        "\n",
        "#Sum Monthly Data to create yearly data\n",
        "for i in range(58):\n",
        "    sum = 0\n",
        "    for j in range(0,11):\n",
        "        sum += float(arrWeight[12*i + j])\n",
        "    arrWeightyr.append(sum)\n",
        "    arrYear.append(i)\n",
        "   \n",
        "plt.scatter(arrYear, arrWeightyr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f1f0429b320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQhz0zcwqxEHfzKxCHPTNzCrk/wPhBUYRgcC5ogAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBU_ChhGpUSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "x_val = []\n",
        "y_val = []\n",
        "\n",
        "#Split data in half for training and validation\n",
        "\n",
        "#Use monthly data to create training data (Give model as much data as possible)\n",
        "for i in arrMonth:\n",
        "    if i % 2 == 0:\n",
        "        x_train.append(i)\n",
        "        y_train.append(arrWeight[i])\n",
        "    else:\n",
        "        x_val.append(i)\n",
        "        y_val.append(arrWeight[i])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkYvgGSX-ylP",
        "colab_type": "text"
      },
      "source": [
        "Important Note on Model:\n",
        "\n",
        "Since we are dealing with fairly large numbers and our loss function is Mean Squared Error our gradient and loss is going to be massively large, to reduce the size of these numbers we will use a process called batch normalization. This will scale all the neuron values down with respect to each other's magnitudes.\n",
        "\n",
        "tf.keras.layers.BatchNormalization(momentum=0.99, epsilon=0.001)\n",
        "\n",
        "Since it is possible for a previous neuron to be zero, we need to add a small number to prevent division by zero this is done though \"epsilon\" which is essentially just a small number we set.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhIfg_mGt93j",
        "colab_type": "code",
        "outputId": "02e8f017-0d22-480d-f8f8-454c1cd31306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Define Sequential Machine Learning Model\n",
        "\n",
        "\n",
        "#In order to save time training - we have already trained the model for for you and will just download the model from our servers\n",
        "#Set this option to false if you want to retrain live (might take a while)\n",
        "LoadPretrainedModel = False\n",
        "\n",
        "if LoadPretrainedModel == True:\n",
        "  model_data = requests.get('https://pchsdatascience.com/wp-content/uploads/2019/12/ProductionData.csv')\n",
        "  model_file = io.StringIO(response.content.decode('utf-8'))\n",
        "  \n",
        "else:\n",
        "  model = tf.keras.models.Sequential(\n",
        "      [tf.keras.layers.Dense(10, input_shape=[1], activation='relu'),\n",
        "      tf.keras.layers.BatchNormalization(momentum=0.99, epsilon=0.001),\n",
        "      tf.keras.layers.Dense(90, activation='relu'),\n",
        "      tf.keras.layers.Dense(1)\n",
        "      ])\n",
        "\n",
        "  #sgd = tf.optimizers.SGD(lr=.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error', metrics=[\"accuracy\"])\n",
        "\n",
        "  #adjust number of epochs to suit processing power and required training\n",
        "  model.fit(x_train, y_train, epochs=1500, validation_data=(x_val,y_val))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 348 samples, validate on 348 samples\n",
            "Epoch 1/1500\n",
            "348/348 [==============================] - 0s 543us/sample - loss: 122205.8606 - acc: 0.0000e+00 - val_loss: 119749.2608 - val_acc: 0.0000e+00\n",
            "Epoch 2/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 121847.0023 - acc: 0.0000e+00 - val_loss: 119210.3314 - val_acc: 0.0000e+00\n",
            "Epoch 3/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 121486.3533 - acc: 0.0000e+00 - val_loss: 118676.2158 - val_acc: 0.0000e+00\n",
            "Epoch 4/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 121091.9181 - acc: 0.0000e+00 - val_loss: 118051.3097 - val_acc: 0.0000e+00\n",
            "Epoch 5/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 120639.1730 - acc: 0.0000e+00 - val_loss: 117473.2503 - val_acc: 0.0000e+00\n",
            "Epoch 6/1500\n",
            "348/348 [==============================] - 0s 112us/sample - loss: 120095.9542 - acc: 0.0000e+00 - val_loss: 116775.1488 - val_acc: 0.0000e+00\n",
            "Epoch 7/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 119485.9734 - acc: 0.0000e+00 - val_loss: 115924.1977 - val_acc: 0.0000e+00\n",
            "Epoch 8/1500\n",
            "348/348 [==============================] - 0s 117us/sample - loss: 118759.1715 - acc: 0.0000e+00 - val_loss: 115072.4110 - val_acc: 0.0000e+00\n",
            "Epoch 9/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 117915.7739 - acc: 0.0000e+00 - val_loss: 114201.7584 - val_acc: 0.0000e+00\n",
            "Epoch 10/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 116935.7079 - acc: 0.0000e+00 - val_loss: 113155.5646 - val_acc: 0.0000e+00\n",
            "Epoch 11/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 115774.7562 - acc: 0.0000e+00 - val_loss: 112036.5669 - val_acc: 0.0000e+00\n",
            "Epoch 12/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 114485.7097 - acc: 0.0000e+00 - val_loss: 110565.3706 - val_acc: 0.0000e+00\n",
            "Epoch 13/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 113057.7154 - acc: 0.0000e+00 - val_loss: 109471.1382 - val_acc: 0.0000e+00\n",
            "Epoch 14/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 111353.8082 - acc: 0.0000e+00 - val_loss: 107975.8223 - val_acc: 0.0000e+00\n",
            "Epoch 15/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 109547.3069 - acc: 0.0000e+00 - val_loss: 106209.5388 - val_acc: 0.0000e+00\n",
            "Epoch 16/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 107493.9031 - acc: 0.0000e+00 - val_loss: 104726.5304 - val_acc: 0.0000e+00\n",
            "Epoch 17/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 105287.5007 - acc: 0.0000e+00 - val_loss: 103149.7691 - val_acc: 0.0000e+00\n",
            "Epoch 18/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 102604.6794 - acc: 0.0000e+00 - val_loss: 101604.6293 - val_acc: 0.0000e+00\n",
            "Epoch 19/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 100021.4448 - acc: 0.0000e+00 - val_loss: 100039.5760 - val_acc: 0.0000e+00\n",
            "Epoch 20/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 97042.2079 - acc: 0.0000e+00 - val_loss: 98054.7369 - val_acc: 0.0000e+00\n",
            "Epoch 21/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 94188.4016 - acc: 0.0000e+00 - val_loss: 96435.4018 - val_acc: 0.0000e+00\n",
            "Epoch 22/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 90715.2679 - acc: 0.0000e+00 - val_loss: 94258.0834 - val_acc: 0.0000e+00\n",
            "Epoch 23/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 87089.3119 - acc: 0.0000e+00 - val_loss: 93320.4596 - val_acc: 0.0000e+00\n",
            "Epoch 24/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 83532.6730 - acc: 0.0000e+00 - val_loss: 92206.1180 - val_acc: 0.0000e+00\n",
            "Epoch 25/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 79637.0767 - acc: 0.0000e+00 - val_loss: 92632.1360 - val_acc: 0.0000e+00\n",
            "Epoch 26/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 75609.6003 - acc: 0.0000e+00 - val_loss: 94033.2780 - val_acc: 0.0000e+00\n",
            "Epoch 27/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 75561.5735 - acc: 0.0000e+00 - val_loss: 92738.8730 - val_acc: 0.0000e+00\n",
            "Epoch 28/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 71589.6557 - acc: 0.0000e+00 - val_loss: 88683.6335 - val_acc: 0.0000e+00\n",
            "Epoch 29/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 67388.5699 - acc: 0.0000e+00 - val_loss: 84340.9792 - val_acc: 0.0000e+00\n",
            "Epoch 30/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 63423.4290 - acc: 0.0000e+00 - val_loss: 80634.3699 - val_acc: 0.0000e+00\n",
            "Epoch 31/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 59074.4524 - acc: 0.0000e+00 - val_loss: 77074.4710 - val_acc: 0.0000e+00\n",
            "Epoch 32/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 54752.0945 - acc: 0.0000e+00 - val_loss: 73625.7064 - val_acc: 0.0000e+00\n",
            "Epoch 33/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 51435.1713 - acc: 0.0000e+00 - val_loss: 69207.0223 - val_acc: 0.0000e+00\n",
            "Epoch 34/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 47042.2113 - acc: 0.0000e+00 - val_loss: 65799.8356 - val_acc: 0.0000e+00\n",
            "Epoch 35/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 43205.2775 - acc: 0.0000e+00 - val_loss: 61427.9926 - val_acc: 0.0000e+00\n",
            "Epoch 36/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 38966.9234 - acc: 0.0000e+00 - val_loss: 58100.9220 - val_acc: 0.0000e+00\n",
            "Epoch 37/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 35586.4262 - acc: 0.0000e+00 - val_loss: 54565.4517 - val_acc: 0.0000e+00\n",
            "Epoch 38/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 31932.9238 - acc: 0.0000e+00 - val_loss: 51187.6916 - val_acc: 0.0000e+00\n",
            "Epoch 39/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 29259.2226 - acc: 0.0000e+00 - val_loss: 47765.7065 - val_acc: 0.0000e+00\n",
            "Epoch 40/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 26708.2258 - acc: 0.0000e+00 - val_loss: 43950.4749 - val_acc: 0.0000e+00\n",
            "Epoch 41/1500\n",
            "348/348 [==============================] - 0s 111us/sample - loss: 23221.6597 - acc: 0.0000e+00 - val_loss: 40993.8812 - val_acc: 0.0000e+00\n",
            "Epoch 42/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 21428.3599 - acc: 0.0000e+00 - val_loss: 37285.4742 - val_acc: 0.0000e+00\n",
            "Epoch 43/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 19260.9344 - acc: 0.0000e+00 - val_loss: 34360.8833 - val_acc: 0.0000e+00\n",
            "Epoch 44/1500\n",
            "348/348 [==============================] - 0s 122us/sample - loss: 16836.1316 - acc: 0.0000e+00 - val_loss: 31781.6737 - val_acc: 0.0000e+00\n",
            "Epoch 45/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 15797.5083 - acc: 0.0000e+00 - val_loss: 30051.8647 - val_acc: 0.0000e+00\n",
            "Epoch 46/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 14578.9419 - acc: 0.0000e+00 - val_loss: 27723.2431 - val_acc: 0.0000e+00\n",
            "Epoch 47/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 13126.8835 - acc: 0.0000e+00 - val_loss: 25006.0551 - val_acc: 0.0000e+00\n",
            "Epoch 48/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 12616.7906 - acc: 0.0000e+00 - val_loss: 21862.2702 - val_acc: 0.0000e+00\n",
            "Epoch 49/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 10827.9020 - acc: 0.0000e+00 - val_loss: 19425.7321 - val_acc: 0.0000e+00\n",
            "Epoch 50/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 10413.4690 - acc: 0.0000e+00 - val_loss: 17567.7693 - val_acc: 0.0000e+00\n",
            "Epoch 51/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 9929.2543 - acc: 0.0000e+00 - val_loss: 16150.3462 - val_acc: 0.0000e+00\n",
            "Epoch 52/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 9415.3369 - acc: 0.0000e+00 - val_loss: 14677.9697 - val_acc: 0.0000e+00\n",
            "Epoch 53/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 8513.7154 - acc: 0.0000e+00 - val_loss: 13021.1903 - val_acc: 0.0000e+00\n",
            "Epoch 54/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 8478.6917 - acc: 0.0000e+00 - val_loss: 11741.7836 - val_acc: 0.0000e+00\n",
            "Epoch 55/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 8124.4149 - acc: 0.0000e+00 - val_loss: 10756.0972 - val_acc: 0.0000e+00\n",
            "Epoch 56/1500\n",
            "348/348 [==============================] - 0s 128us/sample - loss: 8143.0574 - acc: 0.0000e+00 - val_loss: 9813.0764 - val_acc: 0.0000e+00\n",
            "Epoch 57/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 7941.4687 - acc: 0.0000e+00 - val_loss: 9182.8099 - val_acc: 0.0000e+00\n",
            "Epoch 58/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 8619.1318 - acc: 0.0000e+00 - val_loss: 8784.4085 - val_acc: 0.0000e+00\n",
            "Epoch 59/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 7374.6404 - acc: 0.0000e+00 - val_loss: 8501.8144 - val_acc: 0.0000e+00\n",
            "Epoch 60/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 7747.8915 - acc: 0.0000e+00 - val_loss: 8420.9196 - val_acc: 0.0000e+00\n",
            "Epoch 61/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 7289.5803 - acc: 0.0000e+00 - val_loss: 8170.2777 - val_acc: 0.0000e+00\n",
            "Epoch 62/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 6935.8648 - acc: 0.0000e+00 - val_loss: 7761.0297 - val_acc: 0.0000e+00\n",
            "Epoch 63/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 6973.1454 - acc: 0.0000e+00 - val_loss: 7434.8513 - val_acc: 0.0000e+00\n",
            "Epoch 64/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 7056.5767 - acc: 0.0000e+00 - val_loss: 7247.7113 - val_acc: 0.0000e+00\n",
            "Epoch 65/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 6760.5099 - acc: 0.0000e+00 - val_loss: 7153.9511 - val_acc: 0.0000e+00\n",
            "Epoch 66/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 6755.1348 - acc: 0.0000e+00 - val_loss: 6896.4070 - val_acc: 0.0000e+00\n",
            "Epoch 67/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 6528.6498 - acc: 0.0000e+00 - val_loss: 6702.1062 - val_acc: 0.0000e+00\n",
            "Epoch 68/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 6965.4527 - acc: 0.0000e+00 - val_loss: 6597.6254 - val_acc: 0.0000e+00\n",
            "Epoch 69/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 6408.8510 - acc: 0.0000e+00 - val_loss: 6519.0335 - val_acc: 0.0000e+00\n",
            "Epoch 70/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 6521.3157 - acc: 0.0000e+00 - val_loss: 6455.5527 - val_acc: 0.0000e+00\n",
            "Epoch 71/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 6199.8791 - acc: 0.0000e+00 - val_loss: 6378.8329 - val_acc: 0.0000e+00\n",
            "Epoch 72/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 6045.8623 - acc: 0.0000e+00 - val_loss: 6304.7027 - val_acc: 0.0000e+00\n",
            "Epoch 73/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 6516.2151 - acc: 0.0000e+00 - val_loss: 6171.7584 - val_acc: 0.0000e+00\n",
            "Epoch 74/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 5870.8675 - acc: 0.0000e+00 - val_loss: 6083.2409 - val_acc: 0.0000e+00\n",
            "Epoch 75/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 5752.1946 - acc: 0.0000e+00 - val_loss: 6000.5794 - val_acc: 0.0000e+00\n",
            "Epoch 76/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 5890.9760 - acc: 0.0000e+00 - val_loss: 5938.4624 - val_acc: 0.0000e+00\n",
            "Epoch 77/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 5549.0819 - acc: 0.0000e+00 - val_loss: 5899.2175 - val_acc: 0.0000e+00\n",
            "Epoch 78/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 5586.3362 - acc: 0.0000e+00 - val_loss: 5891.1701 - val_acc: 0.0000e+00\n",
            "Epoch 79/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 5848.0844 - acc: 0.0000e+00 - val_loss: 5862.4413 - val_acc: 0.0000e+00\n",
            "Epoch 80/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 5052.7961 - acc: 0.0000e+00 - val_loss: 5810.3001 - val_acc: 0.0000e+00\n",
            "Epoch 81/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 5392.7313 - acc: 0.0000e+00 - val_loss: 5707.8154 - val_acc: 0.0000e+00\n",
            "Epoch 82/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 5745.7733 - acc: 0.0000e+00 - val_loss: 5668.6746 - val_acc: 0.0000e+00\n",
            "Epoch 83/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 6059.3095 - acc: 0.0000e+00 - val_loss: 5633.3061 - val_acc: 0.0000e+00\n",
            "Epoch 84/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 6596.8211 - acc: 0.0000e+00 - val_loss: 5603.8660 - val_acc: 0.0000e+00\n",
            "Epoch 85/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 5403.4997 - acc: 0.0000e+00 - val_loss: 5578.0103 - val_acc: 0.0000e+00\n",
            "Epoch 86/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 5317.9982 - acc: 0.0000e+00 - val_loss: 5556.2967 - val_acc: 0.0000e+00\n",
            "Epoch 87/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 5680.2883 - acc: 0.0000e+00 - val_loss: 5540.8672 - val_acc: 0.0000e+00\n",
            "Epoch 88/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 5610.4601 - acc: 0.0000e+00 - val_loss: 5521.2308 - val_acc: 0.0000e+00\n",
            "Epoch 89/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 5455.5897 - acc: 0.0000e+00 - val_loss: 5519.8079 - val_acc: 0.0000e+00\n",
            "Epoch 90/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 5727.3438 - acc: 0.0000e+00 - val_loss: 5525.7531 - val_acc: 0.0000e+00\n",
            "Epoch 91/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 5474.0628 - acc: 0.0000e+00 - val_loss: 5510.3205 - val_acc: 0.0000e+00\n",
            "Epoch 92/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 6051.5899 - acc: 0.0000e+00 - val_loss: 5498.6085 - val_acc: 0.0000e+00\n",
            "Epoch 93/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 5886.2179 - acc: 0.0000e+00 - val_loss: 5580.0489 - val_acc: 0.0000e+00\n",
            "Epoch 94/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 5583.7920 - acc: 0.0000e+00 - val_loss: 5597.4004 - val_acc: 0.0000e+00\n",
            "Epoch 95/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 5273.3140 - acc: 0.0000e+00 - val_loss: 5627.5124 - val_acc: 0.0000e+00\n",
            "Epoch 96/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 5121.2356 - acc: 0.0000e+00 - val_loss: 5763.5103 - val_acc: 0.0000e+00\n",
            "Epoch 97/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 6192.9589 - acc: 0.0000e+00 - val_loss: 5661.8804 - val_acc: 0.0000e+00\n",
            "Epoch 98/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 5475.0317 - acc: 0.0000e+00 - val_loss: 5664.7771 - val_acc: 0.0000e+00\n",
            "Epoch 99/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 5463.7078 - acc: 0.0000e+00 - val_loss: 5579.1478 - val_acc: 0.0000e+00\n",
            "Epoch 100/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 5163.9673 - acc: 0.0000e+00 - val_loss: 5569.4345 - val_acc: 0.0000e+00\n",
            "Epoch 101/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 5045.8941 - acc: 0.0000e+00 - val_loss: 5712.9966 - val_acc: 0.0000e+00\n",
            "Epoch 102/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 5108.1092 - acc: 0.0000e+00 - val_loss: 5815.8366 - val_acc: 0.0000e+00\n",
            "Epoch 103/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 5410.2227 - acc: 0.0000e+00 - val_loss: 6275.3223 - val_acc: 0.0000e+00\n",
            "Epoch 104/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 5736.3906 - acc: 0.0000e+00 - val_loss: 6657.8623 - val_acc: 0.0000e+00\n",
            "Epoch 105/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 5678.2091 - acc: 0.0000e+00 - val_loss: 7470.0118 - val_acc: 0.0000e+00\n",
            "Epoch 106/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 5913.7028 - acc: 0.0000e+00 - val_loss: 8164.3566 - val_acc: 0.0000e+00\n",
            "Epoch 107/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 5169.6150 - acc: 0.0000e+00 - val_loss: 7544.2986 - val_acc: 0.0000e+00\n",
            "Epoch 108/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 5399.6766 - acc: 0.0000e+00 - val_loss: 7312.4037 - val_acc: 0.0000e+00\n",
            "Epoch 109/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 5248.1610 - acc: 0.0000e+00 - val_loss: 7122.4382 - val_acc: 0.0000e+00\n",
            "Epoch 110/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 5270.4455 - acc: 0.0000e+00 - val_loss: 7204.5190 - val_acc: 0.0000e+00\n",
            "Epoch 111/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 5495.5666 - acc: 0.0000e+00 - val_loss: 7215.7696 - val_acc: 0.0000e+00\n",
            "Epoch 112/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 5969.2986 - acc: 0.0000e+00 - val_loss: 7455.7032 - val_acc: 0.0000e+00\n",
            "Epoch 113/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 5932.5949 - acc: 0.0000e+00 - val_loss: 7403.3105 - val_acc: 0.0000e+00\n",
            "Epoch 114/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 5338.9549 - acc: 0.0000e+00 - val_loss: 7493.7641 - val_acc: 0.0000e+00\n",
            "Epoch 115/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 5681.3005 - acc: 0.0000e+00 - val_loss: 7733.4602 - val_acc: 0.0000e+00\n",
            "Epoch 116/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 5249.1495 - acc: 0.0000e+00 - val_loss: 7820.8960 - val_acc: 0.0000e+00\n",
            "Epoch 117/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 5360.2101 - acc: 0.0000e+00 - val_loss: 7919.2579 - val_acc: 0.0000e+00\n",
            "Epoch 118/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 5586.0481 - acc: 0.0000e+00 - val_loss: 7833.0332 - val_acc: 0.0000e+00\n",
            "Epoch 119/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 5093.8329 - acc: 0.0000e+00 - val_loss: 7897.6329 - val_acc: 0.0000e+00\n",
            "Epoch 120/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 6115.4615 - acc: 0.0000e+00 - val_loss: 7107.2395 - val_acc: 0.0000e+00\n",
            "Epoch 121/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 5277.0589 - acc: 0.0000e+00 - val_loss: 6843.1361 - val_acc: 0.0000e+00\n",
            "Epoch 122/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 5389.1070 - acc: 0.0000e+00 - val_loss: 7013.2550 - val_acc: 0.0000e+00\n",
            "Epoch 123/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 5679.4207 - acc: 0.0000e+00 - val_loss: 7277.0607 - val_acc: 0.0000e+00\n",
            "Epoch 124/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 5194.0279 - acc: 0.0000e+00 - val_loss: 7232.0332 - val_acc: 0.0000e+00\n",
            "Epoch 125/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 5053.3425 - acc: 0.0000e+00 - val_loss: 7195.6483 - val_acc: 0.0000e+00\n",
            "Epoch 126/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 5105.2553 - acc: 0.0000e+00 - val_loss: 7190.4596 - val_acc: 0.0000e+00\n",
            "Epoch 127/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 5277.4714 - acc: 0.0000e+00 - val_loss: 6893.1554 - val_acc: 0.0000e+00\n",
            "Epoch 128/1500\n",
            "348/348 [==============================] - 0s 116us/sample - loss: 5343.2219 - acc: 0.0000e+00 - val_loss: 6561.7112 - val_acc: 0.0000e+00\n",
            "Epoch 129/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 6437.9627 - acc: 0.0000e+00 - val_loss: 6308.0143 - val_acc: 0.0000e+00\n",
            "Epoch 130/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 5490.2472 - acc: 0.0000e+00 - val_loss: 6138.7215 - val_acc: 0.0000e+00\n",
            "Epoch 131/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 5012.6864 - acc: 0.0000e+00 - val_loss: 6162.6453 - val_acc: 0.0000e+00\n",
            "Epoch 132/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 5260.6634 - acc: 0.0000e+00 - val_loss: 6634.5181 - val_acc: 0.0000e+00\n",
            "Epoch 133/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4967.5332 - acc: 0.0000e+00 - val_loss: 6804.3040 - val_acc: 0.0000e+00\n",
            "Epoch 134/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 5322.1319 - acc: 0.0000e+00 - val_loss: 7636.4554 - val_acc: 0.0000e+00\n",
            "Epoch 135/1500\n",
            "348/348 [==============================] - 0s 114us/sample - loss: 4984.8911 - acc: 0.0000e+00 - val_loss: 7977.8523 - val_acc: 0.0000e+00\n",
            "Epoch 136/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 5208.1285 - acc: 0.0000e+00 - val_loss: 8289.7452 - val_acc: 0.0000e+00\n",
            "Epoch 137/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 5390.2624 - acc: 0.0000e+00 - val_loss: 8594.7230 - val_acc: 0.0000e+00\n",
            "Epoch 138/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4843.9261 - acc: 0.0000e+00 - val_loss: 9001.8917 - val_acc: 0.0000e+00\n",
            "Epoch 139/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 4766.4163 - acc: 0.0000e+00 - val_loss: 9399.5784 - val_acc: 0.0000e+00\n",
            "Epoch 140/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 5483.1592 - acc: 0.0000e+00 - val_loss: 9077.9791 - val_acc: 0.0000e+00\n",
            "Epoch 141/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 4850.9158 - acc: 0.0000e+00 - val_loss: 8171.1062 - val_acc: 0.0000e+00\n",
            "Epoch 142/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 5007.7280 - acc: 0.0000e+00 - val_loss: 7628.6644 - val_acc: 0.0000e+00\n",
            "Epoch 143/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4923.8735 - acc: 0.0000e+00 - val_loss: 6993.2379 - val_acc: 0.0000e+00\n",
            "Epoch 144/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 5750.7028 - acc: 0.0000e+00 - val_loss: 6844.9191 - val_acc: 0.0000e+00\n",
            "Epoch 145/1500\n",
            "348/348 [==============================] - 0s 110us/sample - loss: 5234.8580 - acc: 0.0000e+00 - val_loss: 6877.0139 - val_acc: 0.0000e+00\n",
            "Epoch 146/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 5160.2365 - acc: 0.0000e+00 - val_loss: 7275.9408 - val_acc: 0.0000e+00\n",
            "Epoch 147/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 5404.0276 - acc: 0.0000e+00 - val_loss: 7273.8866 - val_acc: 0.0000e+00\n",
            "Epoch 148/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 5278.0204 - acc: 0.0000e+00 - val_loss: 6987.2422 - val_acc: 0.0000e+00\n",
            "Epoch 149/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 5429.2497 - acc: 0.0000e+00 - val_loss: 7016.3599 - val_acc: 0.0000e+00\n",
            "Epoch 150/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 6141.5732 - acc: 0.0000e+00 - val_loss: 7109.7943 - val_acc: 0.0000e+00\n",
            "Epoch 151/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 5327.5728 - acc: 0.0000e+00 - val_loss: 7933.0707 - val_acc: 0.0000e+00\n",
            "Epoch 152/1500\n",
            "348/348 [==============================] - 0s 84us/sample - loss: 5417.2883 - acc: 0.0000e+00 - val_loss: 7206.7920 - val_acc: 0.0000e+00\n",
            "Epoch 153/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 5222.6539 - acc: 0.0000e+00 - val_loss: 6596.2042 - val_acc: 0.0000e+00\n",
            "Epoch 154/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 5094.5467 - acc: 0.0000e+00 - val_loss: 6548.1077 - val_acc: 0.0000e+00\n",
            "Epoch 155/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4922.9991 - acc: 0.0000e+00 - val_loss: 5319.8817 - val_acc: 0.0000e+00\n",
            "Epoch 156/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 5443.9990 - acc: 0.0000e+00 - val_loss: 5632.6689 - val_acc: 0.0000e+00\n",
            "Epoch 157/1500\n",
            "348/348 [==============================] - 0s 113us/sample - loss: 5680.7683 - acc: 0.0000e+00 - val_loss: 5649.3964 - val_acc: 0.0000e+00\n",
            "Epoch 158/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 5735.9189 - acc: 0.0000e+00 - val_loss: 5447.1090 - val_acc: 0.0000e+00\n",
            "Epoch 159/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 5436.6784 - acc: 0.0000e+00 - val_loss: 5311.8524 - val_acc: 0.0000e+00\n",
            "Epoch 160/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 5275.4936 - acc: 0.0000e+00 - val_loss: 5252.8294 - val_acc: 0.0000e+00\n",
            "Epoch 161/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 5035.8648 - acc: 0.0000e+00 - val_loss: 5212.7066 - val_acc: 0.0000e+00\n",
            "Epoch 162/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 5565.3055 - acc: 0.0000e+00 - val_loss: 5143.3832 - val_acc: 0.0000e+00\n",
            "Epoch 163/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 5470.8853 - acc: 0.0000e+00 - val_loss: 5120.2648 - val_acc: 0.0000e+00\n",
            "Epoch 164/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 5440.7711 - acc: 0.0000e+00 - val_loss: 5106.7161 - val_acc: 0.0000e+00\n",
            "Epoch 165/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 6598.6119 - acc: 0.0000e+00 - val_loss: 5133.1096 - val_acc: 0.0000e+00\n",
            "Epoch 166/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 5249.9493 - acc: 0.0000e+00 - val_loss: 5148.3846 - val_acc: 0.0000e+00\n",
            "Epoch 167/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 5436.3512 - acc: 0.0000e+00 - val_loss: 5158.4114 - val_acc: 0.0000e+00\n",
            "Epoch 168/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4837.5344 - acc: 0.0000e+00 - val_loss: 5163.2885 - val_acc: 0.0000e+00\n",
            "Epoch 169/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 5134.0173 - acc: 0.0000e+00 - val_loss: 5165.7301 - val_acc: 0.0000e+00\n",
            "Epoch 170/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 5091.5063 - acc: 0.0000e+00 - val_loss: 5181.7041 - val_acc: 0.0000e+00\n",
            "Epoch 171/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4788.0364 - acc: 0.0000e+00 - val_loss: 5161.6026 - val_acc: 0.0000e+00\n",
            "Epoch 172/1500\n",
            "348/348 [==============================] - 0s 120us/sample - loss: 4953.1895 - acc: 0.0000e+00 - val_loss: 5121.8901 - val_acc: 0.0000e+00\n",
            "Epoch 173/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4956.9091 - acc: 0.0000e+00 - val_loss: 5109.1374 - val_acc: 0.0000e+00\n",
            "Epoch 174/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4748.3713 - acc: 0.0000e+00 - val_loss: 5088.2130 - val_acc: 0.0000e+00\n",
            "Epoch 175/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4871.9562 - acc: 0.0000e+00 - val_loss: 5092.8237 - val_acc: 0.0000e+00\n",
            "Epoch 176/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4875.8812 - acc: 0.0000e+00 - val_loss: 5078.6935 - val_acc: 0.0000e+00\n",
            "Epoch 177/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 5270.8470 - acc: 0.0000e+00 - val_loss: 5075.0366 - val_acc: 0.0000e+00\n",
            "Epoch 178/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4969.1468 - acc: 0.0000e+00 - val_loss: 5073.0366 - val_acc: 0.0000e+00\n",
            "Epoch 179/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 5082.0232 - acc: 0.0000e+00 - val_loss: 5070.3126 - val_acc: 0.0000e+00\n",
            "Epoch 180/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 5306.4098 - acc: 0.0000e+00 - val_loss: 5068.1001 - val_acc: 0.0000e+00\n",
            "Epoch 181/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4785.8646 - acc: 0.0000e+00 - val_loss: 5068.7401 - val_acc: 0.0000e+00\n",
            "Epoch 182/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 5169.7586 - acc: 0.0000e+00 - val_loss: 5097.8079 - val_acc: 0.0000e+00\n",
            "Epoch 183/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4905.4341 - acc: 0.0000e+00 - val_loss: 5103.0422 - val_acc: 0.0000e+00\n",
            "Epoch 184/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 5114.1784 - acc: 0.0000e+00 - val_loss: 5134.8025 - val_acc: 0.0000e+00\n",
            "Epoch 185/1500\n",
            "348/348 [==============================] - 0s 111us/sample - loss: 5694.5239 - acc: 0.0000e+00 - val_loss: 5132.2927 - val_acc: 0.0000e+00\n",
            "Epoch 186/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4986.7967 - acc: 0.0000e+00 - val_loss: 5133.9508 - val_acc: 0.0000e+00\n",
            "Epoch 187/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 4580.2453 - acc: 0.0000e+00 - val_loss: 5100.4681 - val_acc: 0.0000e+00\n",
            "Epoch 188/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 5366.4599 - acc: 0.0000e+00 - val_loss: 5061.5092 - val_acc: 0.0000e+00\n",
            "Epoch 189/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 5321.8139 - acc: 0.0000e+00 - val_loss: 5050.1266 - val_acc: 0.0000e+00\n",
            "Epoch 190/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4750.5309 - acc: 0.0000e+00 - val_loss: 5054.0500 - val_acc: 0.0000e+00\n",
            "Epoch 191/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 5412.6614 - acc: 0.0000e+00 - val_loss: 5135.8315 - val_acc: 0.0000e+00\n",
            "Epoch 192/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 5323.5144 - acc: 0.0000e+00 - val_loss: 5180.2335 - val_acc: 0.0000e+00\n",
            "Epoch 193/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4866.3432 - acc: 0.0000e+00 - val_loss: 5202.5093 - val_acc: 0.0000e+00\n",
            "Epoch 194/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4840.5876 - acc: 0.0000e+00 - val_loss: 5188.4494 - val_acc: 0.0000e+00\n",
            "Epoch 195/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4746.8468 - acc: 0.0000e+00 - val_loss: 5212.1633 - val_acc: 0.0000e+00\n",
            "Epoch 196/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 5065.8269 - acc: 0.0000e+00 - val_loss: 5224.3818 - val_acc: 0.0000e+00\n",
            "Epoch 197/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4706.7211 - acc: 0.0000e+00 - val_loss: 5291.5017 - val_acc: 0.0000e+00\n",
            "Epoch 198/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4833.8741 - acc: 0.0000e+00 - val_loss: 5201.2500 - val_acc: 0.0000e+00\n",
            "Epoch 199/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4822.8015 - acc: 0.0000e+00 - val_loss: 5135.0147 - val_acc: 0.0000e+00\n",
            "Epoch 200/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 5110.1540 - acc: 0.0000e+00 - val_loss: 5075.4492 - val_acc: 0.0000e+00\n",
            "Epoch 201/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 5305.8588 - acc: 0.0000e+00 - val_loss: 5039.0111 - val_acc: 0.0000e+00\n",
            "Epoch 202/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 5356.8236 - acc: 0.0000e+00 - val_loss: 5081.1747 - val_acc: 0.0000e+00\n",
            "Epoch 203/1500\n",
            "348/348 [==============================] - 0s 84us/sample - loss: 4880.0003 - acc: 0.0000e+00 - val_loss: 5128.7499 - val_acc: 0.0000e+00\n",
            "Epoch 204/1500\n",
            "348/348 [==============================] - 0s 81us/sample - loss: 4892.9764 - acc: 0.0000e+00 - val_loss: 5141.1557 - val_acc: 0.0000e+00\n",
            "Epoch 205/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 5163.3503 - acc: 0.0000e+00 - val_loss: 5187.1551 - val_acc: 0.0000e+00\n",
            "Epoch 206/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 5238.2153 - acc: 0.0000e+00 - val_loss: 5201.5856 - val_acc: 0.0000e+00\n",
            "Epoch 207/1500\n",
            "348/348 [==============================] - 0s 84us/sample - loss: 5074.2231 - acc: 0.0000e+00 - val_loss: 5258.9532 - val_acc: 0.0000e+00\n",
            "Epoch 208/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 5089.7114 - acc: 0.0000e+00 - val_loss: 5178.5098 - val_acc: 0.0000e+00\n",
            "Epoch 209/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 5023.4674 - acc: 0.0000e+00 - val_loss: 5099.0328 - val_acc: 0.0000e+00\n",
            "Epoch 210/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4943.8480 - acc: 0.0000e+00 - val_loss: 5152.9004 - val_acc: 0.0000e+00\n",
            "Epoch 211/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 5151.9548 - acc: 0.0000e+00 - val_loss: 5145.7593 - val_acc: 0.0000e+00\n",
            "Epoch 212/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4752.8331 - acc: 0.0000e+00 - val_loss: 5240.3517 - val_acc: 0.0000e+00\n",
            "Epoch 213/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 5000.1054 - acc: 0.0000e+00 - val_loss: 5170.5597 - val_acc: 0.0000e+00\n",
            "Epoch 214/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 5014.1640 - acc: 0.0000e+00 - val_loss: 5194.2480 - val_acc: 0.0000e+00\n",
            "Epoch 215/1500\n",
            "348/348 [==============================] - 0s 110us/sample - loss: 5325.8040 - acc: 0.0000e+00 - val_loss: 5121.8690 - val_acc: 0.0000e+00\n",
            "Epoch 216/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 4929.3952 - acc: 0.0000e+00 - val_loss: 5055.3190 - val_acc: 0.0000e+00\n",
            "Epoch 217/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 5207.2885 - acc: 0.0000e+00 - val_loss: 5034.6140 - val_acc: 0.0000e+00\n",
            "Epoch 218/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 5299.4410 - acc: 0.0000e+00 - val_loss: 5023.6411 - val_acc: 0.0000e+00\n",
            "Epoch 219/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 5464.1122 - acc: 0.0000e+00 - val_loss: 5009.8524 - val_acc: 0.0000e+00\n",
            "Epoch 220/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4467.3735 - acc: 0.0000e+00 - val_loss: 4993.5692 - val_acc: 0.0000e+00\n",
            "Epoch 221/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 5048.1102 - acc: 0.0000e+00 - val_loss: 4995.7920 - val_acc: 0.0000e+00\n",
            "Epoch 222/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 5243.8731 - acc: 0.0000e+00 - val_loss: 5006.1506 - val_acc: 0.0000e+00\n",
            "Epoch 223/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 5289.5263 - acc: 0.0000e+00 - val_loss: 4990.6125 - val_acc: 0.0000e+00\n",
            "Epoch 224/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4975.6942 - acc: 0.0000e+00 - val_loss: 4981.9989 - val_acc: 0.0000e+00\n",
            "Epoch 225/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 4876.9450 - acc: 0.0000e+00 - val_loss: 4979.7201 - val_acc: 0.0000e+00\n",
            "Epoch 226/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4615.5220 - acc: 0.0000e+00 - val_loss: 4977.9025 - val_acc: 0.0000e+00\n",
            "Epoch 227/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4740.1851 - acc: 0.0000e+00 - val_loss: 4977.2525 - val_acc: 0.0000e+00\n",
            "Epoch 228/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 4805.0088 - acc: 0.0000e+00 - val_loss: 4992.5778 - val_acc: 0.0000e+00\n",
            "Epoch 229/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 5026.8835 - acc: 0.0000e+00 - val_loss: 5036.8008 - val_acc: 0.0000e+00\n",
            "Epoch 230/1500\n",
            "348/348 [==============================] - 0s 112us/sample - loss: 4453.9761 - acc: 0.0000e+00 - val_loss: 5067.2631 - val_acc: 0.0000e+00\n",
            "Epoch 231/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 5481.5948 - acc: 0.0000e+00 - val_loss: 5116.3945 - val_acc: 0.0000e+00\n",
            "Epoch 232/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4764.3785 - acc: 0.0000e+00 - val_loss: 5111.1221 - val_acc: 0.0000e+00\n",
            "Epoch 233/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 5003.0768 - acc: 0.0000e+00 - val_loss: 5085.4883 - val_acc: 0.0000e+00\n",
            "Epoch 234/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4808.8017 - acc: 0.0000e+00 - val_loss: 5074.4509 - val_acc: 0.0000e+00\n",
            "Epoch 235/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 5079.8904 - acc: 0.0000e+00 - val_loss: 5011.8178 - val_acc: 0.0000e+00\n",
            "Epoch 236/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4939.5192 - acc: 0.0000e+00 - val_loss: 4993.9921 - val_acc: 0.0000e+00\n",
            "Epoch 237/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 5409.9030 - acc: 0.0000e+00 - val_loss: 4976.0066 - val_acc: 0.0000e+00\n",
            "Epoch 238/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 5031.7737 - acc: 0.0000e+00 - val_loss: 5080.6699 - val_acc: 0.0000e+00\n",
            "Epoch 239/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4905.5616 - acc: 0.0000e+00 - val_loss: 5106.9290 - val_acc: 0.0000e+00\n",
            "Epoch 240/1500\n",
            "348/348 [==============================] - 0s 84us/sample - loss: 4542.6019 - acc: 0.0000e+00 - val_loss: 5109.0419 - val_acc: 0.0000e+00\n",
            "Epoch 241/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4584.2332 - acc: 0.0000e+00 - val_loss: 5077.4955 - val_acc: 0.0000e+00\n",
            "Epoch 242/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4813.3778 - acc: 0.0000e+00 - val_loss: 5076.6902 - val_acc: 0.0000e+00\n",
            "Epoch 243/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4972.9093 - acc: 0.0000e+00 - val_loss: 5030.7848 - val_acc: 0.0000e+00\n",
            "Epoch 244/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4721.7240 - acc: 0.0000e+00 - val_loss: 5076.4455 - val_acc: 0.0000e+00\n",
            "Epoch 245/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 5212.9182 - acc: 0.0000e+00 - val_loss: 5164.4518 - val_acc: 0.0000e+00\n",
            "Epoch 246/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4471.2079 - acc: 0.0000e+00 - val_loss: 5250.8974 - val_acc: 0.0000e+00\n",
            "Epoch 247/1500\n",
            "348/348 [==============================] - 0s 112us/sample - loss: 4613.7952 - acc: 0.0000e+00 - val_loss: 5205.8648 - val_acc: 0.0000e+00\n",
            "Epoch 248/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4880.4940 - acc: 0.0000e+00 - val_loss: 5082.5508 - val_acc: 0.0000e+00\n",
            "Epoch 249/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4748.6252 - acc: 0.0000e+00 - val_loss: 5010.3981 - val_acc: 0.0000e+00\n",
            "Epoch 250/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4953.7114 - acc: 0.0000e+00 - val_loss: 4976.6515 - val_acc: 0.0000e+00\n",
            "Epoch 251/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4830.0752 - acc: 0.0000e+00 - val_loss: 4961.9191 - val_acc: 0.0000e+00\n",
            "Epoch 252/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 5081.9639 - acc: 0.0000e+00 - val_loss: 4949.5104 - val_acc: 0.0000e+00\n",
            "Epoch 253/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4446.5094 - acc: 0.0000e+00 - val_loss: 4933.7162 - val_acc: 0.0000e+00\n",
            "Epoch 254/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4348.6503 - acc: 0.0000e+00 - val_loss: 4926.6799 - val_acc: 0.0000e+00\n",
            "Epoch 255/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 5406.9595 - acc: 0.0000e+00 - val_loss: 4923.7900 - val_acc: 0.0000e+00\n",
            "Epoch 256/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 5236.4109 - acc: 0.0000e+00 - val_loss: 4975.1453 - val_acc: 0.0000e+00\n",
            "Epoch 257/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4997.6839 - acc: 0.0000e+00 - val_loss: 4978.8666 - val_acc: 0.0000e+00\n",
            "Epoch 258/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4984.6737 - acc: 0.0000e+00 - val_loss: 5147.2373 - val_acc: 0.0000e+00\n",
            "Epoch 259/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4578.1955 - acc: 0.0000e+00 - val_loss: 5212.8446 - val_acc: 0.0000e+00\n",
            "Epoch 260/1500\n",
            "348/348 [==============================] - 0s 117us/sample - loss: 5418.1823 - acc: 0.0000e+00 - val_loss: 5355.3403 - val_acc: 0.0000e+00\n",
            "Epoch 261/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 5017.3308 - acc: 0.0000e+00 - val_loss: 5433.7229 - val_acc: 0.0000e+00\n",
            "Epoch 262/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 6443.7611 - acc: 0.0000e+00 - val_loss: 5234.6532 - val_acc: 0.0000e+00\n",
            "Epoch 263/1500\n",
            "348/348 [==============================] - 0s 112us/sample - loss: 4630.5150 - acc: 0.0000e+00 - val_loss: 5740.9687 - val_acc: 0.0000e+00\n",
            "Epoch 264/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4955.4517 - acc: 0.0000e+00 - val_loss: 6038.0911 - val_acc: 0.0000e+00\n",
            "Epoch 265/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4906.4300 - acc: 0.0000e+00 - val_loss: 5606.6177 - val_acc: 0.0000e+00\n",
            "Epoch 266/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 5125.3030 - acc: 0.0000e+00 - val_loss: 5699.4986 - val_acc: 0.0000e+00\n",
            "Epoch 267/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 5466.1175 - acc: 0.0000e+00 - val_loss: 5931.2132 - val_acc: 0.0000e+00\n",
            "Epoch 268/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4746.1770 - acc: 0.0000e+00 - val_loss: 7525.5039 - val_acc: 0.0000e+00\n",
            "Epoch 269/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4838.8469 - acc: 0.0000e+00 - val_loss: 8297.1436 - val_acc: 0.0000e+00\n",
            "Epoch 270/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4813.1964 - acc: 0.0000e+00 - val_loss: 9042.9777 - val_acc: 0.0000e+00\n",
            "Epoch 271/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 5376.3415 - acc: 0.0000e+00 - val_loss: 9216.4954 - val_acc: 0.0000e+00\n",
            "Epoch 272/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4856.5894 - acc: 0.0000e+00 - val_loss: 8685.0446 - val_acc: 0.0000e+00\n",
            "Epoch 273/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4902.2176 - acc: 0.0000e+00 - val_loss: 8924.0128 - val_acc: 0.0000e+00\n",
            "Epoch 274/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 5194.4833 - acc: 0.0000e+00 - val_loss: 8699.0266 - val_acc: 0.0000e+00\n",
            "Epoch 275/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4822.6679 - acc: 0.0000e+00 - val_loss: 6968.7337 - val_acc: 0.0000e+00\n",
            "Epoch 276/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4913.0087 - acc: 0.0000e+00 - val_loss: 6098.2547 - val_acc: 0.0000e+00\n",
            "Epoch 277/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4501.5355 - acc: 0.0000e+00 - val_loss: 5713.2183 - val_acc: 0.0000e+00\n",
            "Epoch 278/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 5138.8932 - acc: 0.0000e+00 - val_loss: 5822.4004 - val_acc: 0.0000e+00\n",
            "Epoch 279/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4856.0888 - acc: 0.0000e+00 - val_loss: 6278.6198 - val_acc: 0.0000e+00\n",
            "Epoch 280/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 5287.6277 - acc: 0.0000e+00 - val_loss: 5866.2164 - val_acc: 0.0000e+00\n",
            "Epoch 281/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 5010.8172 - acc: 0.0000e+00 - val_loss: 5652.2477 - val_acc: 0.0000e+00\n",
            "Epoch 282/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 5259.8810 - acc: 0.0000e+00 - val_loss: 5614.5827 - val_acc: 0.0000e+00\n",
            "Epoch 283/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 5124.3146 - acc: 0.0000e+00 - val_loss: 5963.7976 - val_acc: 0.0000e+00\n",
            "Epoch 284/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4788.7845 - acc: 0.0000e+00 - val_loss: 5737.8140 - val_acc: 0.0000e+00\n",
            "Epoch 285/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4676.0516 - acc: 0.0000e+00 - val_loss: 6009.0726 - val_acc: 0.0000e+00\n",
            "Epoch 286/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4388.7723 - acc: 0.0000e+00 - val_loss: 4979.7547 - val_acc: 0.0000e+00\n",
            "Epoch 287/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4306.5512 - acc: 0.0000e+00 - val_loss: 7007.9566 - val_acc: 0.0000e+00\n",
            "Epoch 288/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4531.3714 - acc: 0.0000e+00 - val_loss: 6770.8431 - val_acc: 0.0000e+00\n",
            "Epoch 289/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 5884.1765 - acc: 0.0000e+00 - val_loss: 6048.5346 - val_acc: 0.0000e+00\n",
            "Epoch 290/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4837.1422 - acc: 0.0000e+00 - val_loss: 5626.3240 - val_acc: 0.0000e+00\n",
            "Epoch 291/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 5074.8662 - acc: 0.0000e+00 - val_loss: 5626.6375 - val_acc: 0.0000e+00\n",
            "Epoch 292/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4855.1329 - acc: 0.0000e+00 - val_loss: 5527.5279 - val_acc: 0.0000e+00\n",
            "Epoch 293/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4954.9930 - acc: 0.0000e+00 - val_loss: 5367.3919 - val_acc: 0.0000e+00\n",
            "Epoch 294/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4534.7489 - acc: 0.0000e+00 - val_loss: 5349.7633 - val_acc: 0.0000e+00\n",
            "Epoch 295/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 5025.0196 - acc: 0.0000e+00 - val_loss: 5171.9254 - val_acc: 0.0000e+00\n",
            "Epoch 296/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4480.0832 - acc: 0.0000e+00 - val_loss: 5014.5635 - val_acc: 0.0000e+00\n",
            "Epoch 297/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 5070.2825 - acc: 0.0000e+00 - val_loss: 4959.1091 - val_acc: 0.0000e+00\n",
            "Epoch 298/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4802.2011 - acc: 0.0000e+00 - val_loss: 4906.5120 - val_acc: 0.0000e+00\n",
            "Epoch 299/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 4862.1305 - acc: 0.0000e+00 - val_loss: 4907.8556 - val_acc: 0.0000e+00\n",
            "Epoch 300/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4534.4209 - acc: 0.0000e+00 - val_loss: 4917.4770 - val_acc: 0.0000e+00\n",
            "Epoch 301/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4814.0270 - acc: 0.0000e+00 - val_loss: 4923.7708 - val_acc: 0.0000e+00\n",
            "Epoch 302/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 5037.5509 - acc: 0.0000e+00 - val_loss: 4965.6415 - val_acc: 0.0000e+00\n",
            "Epoch 303/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4942.2739 - acc: 0.0000e+00 - val_loss: 5007.9071 - val_acc: 0.0000e+00\n",
            "Epoch 304/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 5134.7333 - acc: 0.0000e+00 - val_loss: 5017.6633 - val_acc: 0.0000e+00\n",
            "Epoch 305/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 5314.8115 - acc: 0.0000e+00 - val_loss: 4979.3803 - val_acc: 0.0000e+00\n",
            "Epoch 306/1500\n",
            "348/348 [==============================] - 0s 112us/sample - loss: 5034.8866 - acc: 0.0000e+00 - val_loss: 4996.5429 - val_acc: 0.0000e+00\n",
            "Epoch 307/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 5520.6489 - acc: 0.0000e+00 - val_loss: 4996.3454 - val_acc: 0.0000e+00\n",
            "Epoch 308/1500\n",
            "348/348 [==============================] - 0s 121us/sample - loss: 4739.2311 - acc: 0.0000e+00 - val_loss: 4995.9627 - val_acc: 0.0000e+00\n",
            "Epoch 309/1500\n",
            "348/348 [==============================] - 0s 110us/sample - loss: 4804.2630 - acc: 0.0000e+00 - val_loss: 4927.5706 - val_acc: 0.0000e+00\n",
            "Epoch 310/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4956.5648 - acc: 0.0000e+00 - val_loss: 4848.4591 - val_acc: 0.0000e+00\n",
            "Epoch 311/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4644.4841 - acc: 0.0000e+00 - val_loss: 4844.1649 - val_acc: 0.0000e+00\n",
            "Epoch 312/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4933.7050 - acc: 0.0000e+00 - val_loss: 4830.3104 - val_acc: 0.0000e+00\n",
            "Epoch 313/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4562.3272 - acc: 0.0000e+00 - val_loss: 4816.8556 - val_acc: 0.0000e+00\n",
            "Epoch 314/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 4826.2205 - acc: 0.0000e+00 - val_loss: 4814.4209 - val_acc: 0.0000e+00\n",
            "Epoch 315/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4701.9815 - acc: 0.0000e+00 - val_loss: 4819.3772 - val_acc: 0.0000e+00\n",
            "Epoch 316/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4509.1656 - acc: 0.0000e+00 - val_loss: 4825.2552 - val_acc: 0.0000e+00\n",
            "Epoch 317/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4865.8983 - acc: 0.0000e+00 - val_loss: 4806.9825 - val_acc: 0.0000e+00\n",
            "Epoch 318/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4495.1265 - acc: 0.0000e+00 - val_loss: 4796.6590 - val_acc: 0.0000e+00\n",
            "Epoch 319/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 5327.4858 - acc: 0.0000e+00 - val_loss: 4793.7970 - val_acc: 0.0000e+00\n",
            "Epoch 320/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4599.6191 - acc: 0.0000e+00 - val_loss: 4791.8606 - val_acc: 0.0000e+00\n",
            "Epoch 321/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4793.0523 - acc: 0.0000e+00 - val_loss: 4791.1440 - val_acc: 0.0000e+00\n",
            "Epoch 322/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 5527.9802 - acc: 0.0000e+00 - val_loss: 4786.1941 - val_acc: 0.0000e+00\n",
            "Epoch 323/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4974.4602 - acc: 0.0000e+00 - val_loss: 4779.0849 - val_acc: 0.0000e+00\n",
            "Epoch 324/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 4946.6843 - acc: 0.0000e+00 - val_loss: 4781.4091 - val_acc: 0.0000e+00\n",
            "Epoch 325/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4440.6059 - acc: 0.0000e+00 - val_loss: 4781.6924 - val_acc: 0.0000e+00\n",
            "Epoch 326/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4599.8690 - acc: 0.0000e+00 - val_loss: 4841.5208 - val_acc: 0.0000e+00\n",
            "Epoch 327/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4659.4446 - acc: 0.0000e+00 - val_loss: 4830.5017 - val_acc: 0.0000e+00\n",
            "Epoch 328/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 5503.4525 - acc: 0.0000e+00 - val_loss: 4955.8532 - val_acc: 0.0000e+00\n",
            "Epoch 329/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 4892.1765 - acc: 0.0000e+00 - val_loss: 4930.1023 - val_acc: 0.0000e+00\n",
            "Epoch 330/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4777.4642 - acc: 0.0000e+00 - val_loss: 4888.3511 - val_acc: 0.0000e+00\n",
            "Epoch 331/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4735.7454 - acc: 0.0000e+00 - val_loss: 5111.5649 - val_acc: 0.0000e+00\n",
            "Epoch 332/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 5073.9242 - acc: 0.0000e+00 - val_loss: 5212.4324 - val_acc: 0.0000e+00\n",
            "Epoch 333/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4399.7463 - acc: 0.0000e+00 - val_loss: 6352.6135 - val_acc: 0.0000e+00\n",
            "Epoch 334/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 5667.8272 - acc: 0.0000e+00 - val_loss: 6487.7069 - val_acc: 0.0000e+00\n",
            "Epoch 335/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 5095.3569 - acc: 0.0000e+00 - val_loss: 6016.9181 - val_acc: 0.0000e+00\n",
            "Epoch 336/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 5048.4210 - acc: 0.0000e+00 - val_loss: 5788.9206 - val_acc: 0.0000e+00\n",
            "Epoch 337/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 5285.2501 - acc: 0.0000e+00 - val_loss: 5788.2366 - val_acc: 0.0000e+00\n",
            "Epoch 338/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 5293.6388 - acc: 0.0000e+00 - val_loss: 5638.1783 - val_acc: 0.0000e+00\n",
            "Epoch 339/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4446.2911 - acc: 0.0000e+00 - val_loss: 5564.4683 - val_acc: 0.0000e+00\n",
            "Epoch 340/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4884.0053 - acc: 0.0000e+00 - val_loss: 5566.6797 - val_acc: 0.0000e+00\n",
            "Epoch 341/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4629.0782 - acc: 0.0000e+00 - val_loss: 5461.5997 - val_acc: 0.0000e+00\n",
            "Epoch 342/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4927.4747 - acc: 0.0000e+00 - val_loss: 5326.0208 - val_acc: 0.0000e+00\n",
            "Epoch 343/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 4391.7620 - acc: 0.0000e+00 - val_loss: 5242.2096 - val_acc: 0.0000e+00\n",
            "Epoch 344/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4955.7690 - acc: 0.0000e+00 - val_loss: 5251.6185 - val_acc: 0.0000e+00\n",
            "Epoch 345/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4897.2562 - acc: 0.0000e+00 - val_loss: 5098.7749 - val_acc: 0.0000e+00\n",
            "Epoch 346/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4592.7083 - acc: 0.0000e+00 - val_loss: 5170.3276 - val_acc: 0.0000e+00\n",
            "Epoch 347/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 5022.5750 - acc: 0.0000e+00 - val_loss: 5173.2947 - val_acc: 0.0000e+00\n",
            "Epoch 348/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 5524.8858 - acc: 0.0000e+00 - val_loss: 5208.1074 - val_acc: 0.0000e+00\n",
            "Epoch 349/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4792.9296 - acc: 0.0000e+00 - val_loss: 5083.2554 - val_acc: 0.0000e+00\n",
            "Epoch 350/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 4431.2022 - acc: 0.0000e+00 - val_loss: 5065.2258 - val_acc: 0.0000e+00\n",
            "Epoch 351/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4544.7643 - acc: 0.0000e+00 - val_loss: 4958.4821 - val_acc: 0.0000e+00\n",
            "Epoch 352/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4818.3733 - acc: 0.0000e+00 - val_loss: 4881.1057 - val_acc: 0.0000e+00\n",
            "Epoch 353/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 4451.3836 - acc: 0.0000e+00 - val_loss: 4863.3061 - val_acc: 0.0000e+00\n",
            "Epoch 354/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4797.5570 - acc: 0.0000e+00 - val_loss: 4827.6652 - val_acc: 0.0000e+00\n",
            "Epoch 355/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4689.0216 - acc: 0.0000e+00 - val_loss: 4821.2446 - val_acc: 0.0000e+00\n",
            "Epoch 356/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4668.3780 - acc: 0.0000e+00 - val_loss: 4809.1287 - val_acc: 0.0000e+00\n",
            "Epoch 357/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4699.1965 - acc: 0.0000e+00 - val_loss: 4794.9313 - val_acc: 0.0000e+00\n",
            "Epoch 358/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4619.3910 - acc: 0.0000e+00 - val_loss: 4787.9917 - val_acc: 0.0000e+00\n",
            "Epoch 359/1500\n",
            "348/348 [==============================] - 0s 114us/sample - loss: 4423.6638 - acc: 0.0000e+00 - val_loss: 4786.7617 - val_acc: 0.0000e+00\n",
            "Epoch 360/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4491.3962 - acc: 0.0000e+00 - val_loss: 4785.0016 - val_acc: 0.0000e+00\n",
            "Epoch 361/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 4819.6641 - acc: 0.0000e+00 - val_loss: 4779.4420 - val_acc: 0.0000e+00\n",
            "Epoch 362/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4778.5493 - acc: 0.0000e+00 - val_loss: 4770.0040 - val_acc: 0.0000e+00\n",
            "Epoch 363/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4661.6738 - acc: 0.0000e+00 - val_loss: 4760.7855 - val_acc: 0.0000e+00\n",
            "Epoch 364/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4563.9433 - acc: 0.0000e+00 - val_loss: 4768.3255 - val_acc: 0.0000e+00\n",
            "Epoch 365/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4555.5889 - acc: 0.0000e+00 - val_loss: 4783.9868 - val_acc: 0.0000e+00\n",
            "Epoch 366/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4582.7597 - acc: 0.0000e+00 - val_loss: 4760.0874 - val_acc: 0.0000e+00\n",
            "Epoch 367/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4786.2249 - acc: 0.0000e+00 - val_loss: 4749.3158 - val_acc: 0.0000e+00\n",
            "Epoch 368/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 5243.9872 - acc: 0.0000e+00 - val_loss: 4743.9568 - val_acc: 0.0000e+00\n",
            "Epoch 369/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 5178.0195 - acc: 0.0000e+00 - val_loss: 4730.8644 - val_acc: 0.0000e+00\n",
            "Epoch 370/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4862.4540 - acc: 0.0000e+00 - val_loss: 4724.0673 - val_acc: 0.0000e+00\n",
            "Epoch 371/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4456.0022 - acc: 0.0000e+00 - val_loss: 4727.9298 - val_acc: 0.0000e+00\n",
            "Epoch 372/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4576.1555 - acc: 0.0000e+00 - val_loss: 4722.3403 - val_acc: 0.0000e+00\n",
            "Epoch 373/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4734.4761 - acc: 0.0000e+00 - val_loss: 4716.2195 - val_acc: 0.0000e+00\n",
            "Epoch 374/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 5355.5788 - acc: 0.0000e+00 - val_loss: 4711.1472 - val_acc: 0.0000e+00\n",
            "Epoch 375/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4717.7364 - acc: 0.0000e+00 - val_loss: 4707.9844 - val_acc: 0.0000e+00\n",
            "Epoch 376/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4327.0814 - acc: 0.0000e+00 - val_loss: 4701.2442 - val_acc: 0.0000e+00\n",
            "Epoch 377/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4593.9612 - acc: 0.0000e+00 - val_loss: 4705.2504 - val_acc: 0.0000e+00\n",
            "Epoch 378/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4754.7208 - acc: 0.0000e+00 - val_loss: 4694.7527 - val_acc: 0.0000e+00\n",
            "Epoch 379/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4413.7353 - acc: 0.0000e+00 - val_loss: 4691.1940 - val_acc: 0.0000e+00\n",
            "Epoch 380/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4457.5315 - acc: 0.0000e+00 - val_loss: 4689.8444 - val_acc: 0.0000e+00\n",
            "Epoch 381/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 5041.3185 - acc: 0.0000e+00 - val_loss: 4680.9594 - val_acc: 0.0000e+00\n",
            "Epoch 382/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4318.6851 - acc: 0.0000e+00 - val_loss: 4675.9465 - val_acc: 0.0000e+00\n",
            "Epoch 383/1500\n",
            "348/348 [==============================] - 0s 112us/sample - loss: 4338.0903 - acc: 0.0000e+00 - val_loss: 4675.2653 - val_acc: 0.0000e+00\n",
            "Epoch 384/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 4495.0063 - acc: 0.0000e+00 - val_loss: 4670.2201 - val_acc: 0.0000e+00\n",
            "Epoch 385/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4519.6849 - acc: 0.0000e+00 - val_loss: 4671.5522 - val_acc: 0.0000e+00\n",
            "Epoch 386/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 4302.0246 - acc: 0.0000e+00 - val_loss: 4700.4822 - val_acc: 0.0000e+00\n",
            "Epoch 387/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4750.5036 - acc: 0.0000e+00 - val_loss: 4695.2819 - val_acc: 0.0000e+00\n",
            "Epoch 388/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4613.3142 - acc: 0.0000e+00 - val_loss: 4659.8544 - val_acc: 0.0000e+00\n",
            "Epoch 389/1500\n",
            "348/348 [==============================] - 0s 125us/sample - loss: 4839.6546 - acc: 0.0000e+00 - val_loss: 4653.5029 - val_acc: 0.0000e+00\n",
            "Epoch 390/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4302.2163 - acc: 0.0000e+00 - val_loss: 4645.6982 - val_acc: 0.0000e+00\n",
            "Epoch 391/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 6100.6686 - acc: 0.0000e+00 - val_loss: 4633.6953 - val_acc: 0.0000e+00\n",
            "Epoch 392/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 4567.7084 - acc: 0.0000e+00 - val_loss: 4627.1746 - val_acc: 0.0000e+00\n",
            "Epoch 393/1500\n",
            "348/348 [==============================] - 0s 124us/sample - loss: 4342.6881 - acc: 0.0000e+00 - val_loss: 4625.2641 - val_acc: 0.0000e+00\n",
            "Epoch 394/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 5137.9252 - acc: 0.0000e+00 - val_loss: 4622.7634 - val_acc: 0.0000e+00\n",
            "Epoch 395/1500\n",
            "348/348 [==============================] - 0s 111us/sample - loss: 4347.8765 - acc: 0.0000e+00 - val_loss: 4620.8873 - val_acc: 0.0000e+00\n",
            "Epoch 396/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4586.4608 - acc: 0.0000e+00 - val_loss: 4615.9664 - val_acc: 0.0000e+00\n",
            "Epoch 397/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4555.2635 - acc: 0.0000e+00 - val_loss: 4607.7416 - val_acc: 0.0000e+00\n",
            "Epoch 398/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4463.3108 - acc: 0.0000e+00 - val_loss: 4613.9976 - val_acc: 0.0000e+00\n",
            "Epoch 399/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4524.6892 - acc: 0.0000e+00 - val_loss: 4610.9718 - val_acc: 0.0000e+00\n",
            "Epoch 400/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4909.9893 - acc: 0.0000e+00 - val_loss: 4595.2929 - val_acc: 0.0000e+00\n",
            "Epoch 401/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 4516.5713 - acc: 0.0000e+00 - val_loss: 4599.9817 - val_acc: 0.0000e+00\n",
            "Epoch 402/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4693.7039 - acc: 0.0000e+00 - val_loss: 4605.1636 - val_acc: 0.0000e+00\n",
            "Epoch 403/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4505.6665 - acc: 0.0000e+00 - val_loss: 4593.3590 - val_acc: 0.0000e+00\n",
            "Epoch 404/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4339.6130 - acc: 0.0000e+00 - val_loss: 4580.4454 - val_acc: 0.0000e+00\n",
            "Epoch 405/1500\n",
            "348/348 [==============================] - 0s 83us/sample - loss: 4404.4650 - acc: 0.0000e+00 - val_loss: 4574.4817 - val_acc: 0.0000e+00\n",
            "Epoch 406/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4430.6182 - acc: 0.0000e+00 - val_loss: 4567.3698 - val_acc: 0.0000e+00\n",
            "Epoch 407/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4250.0700 - acc: 0.0000e+00 - val_loss: 4565.1414 - val_acc: 0.0000e+00\n",
            "Epoch 408/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4814.7558 - acc: 0.0000e+00 - val_loss: 4559.6832 - val_acc: 0.0000e+00\n",
            "Epoch 409/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4271.1677 - acc: 0.0000e+00 - val_loss: 4556.6333 - val_acc: 0.0000e+00\n",
            "Epoch 410/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4790.0933 - acc: 0.0000e+00 - val_loss: 4550.3589 - val_acc: 0.0000e+00\n",
            "Epoch 411/1500\n",
            "348/348 [==============================] - 0s 114us/sample - loss: 4491.2644 - acc: 0.0000e+00 - val_loss: 4543.7197 - val_acc: 0.0000e+00\n",
            "Epoch 412/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 4485.4948 - acc: 0.0000e+00 - val_loss: 4539.5375 - val_acc: 0.0000e+00\n",
            "Epoch 413/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4613.7848 - acc: 0.0000e+00 - val_loss: 4542.4744 - val_acc: 0.0000e+00\n",
            "Epoch 414/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4767.8192 - acc: 0.0000e+00 - val_loss: 4531.1003 - val_acc: 0.0000e+00\n",
            "Epoch 415/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4610.4773 - acc: 0.0000e+00 - val_loss: 4540.4882 - val_acc: 0.0000e+00\n",
            "Epoch 416/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4771.1550 - acc: 0.0000e+00 - val_loss: 4520.0588 - val_acc: 0.0000e+00\n",
            "Epoch 417/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4262.3187 - acc: 0.0000e+00 - val_loss: 4514.3322 - val_acc: 0.0000e+00\n",
            "Epoch 418/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4114.5070 - acc: 0.0000e+00 - val_loss: 4523.6937 - val_acc: 0.0000e+00\n",
            "Epoch 419/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4721.0531 - acc: 0.0000e+00 - val_loss: 4506.6249 - val_acc: 0.0000e+00\n",
            "Epoch 420/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 4487.0319 - acc: 0.0000e+00 - val_loss: 4503.0816 - val_acc: 0.0000e+00\n",
            "Epoch 421/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4353.1260 - acc: 0.0000e+00 - val_loss: 4496.8688 - val_acc: 0.0000e+00\n",
            "Epoch 422/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 4626.6672 - acc: 0.0000e+00 - val_loss: 4497.9319 - val_acc: 0.0000e+00\n",
            "Epoch 423/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4110.7615 - acc: 0.0000e+00 - val_loss: 4489.9392 - val_acc: 0.0000e+00\n",
            "Epoch 424/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4498.0108 - acc: 0.0000e+00 - val_loss: 4484.4002 - val_acc: 0.0000e+00\n",
            "Epoch 425/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 5565.6612 - acc: 0.0000e+00 - val_loss: 4480.4722 - val_acc: 0.0000e+00\n",
            "Epoch 426/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4854.9163 - acc: 0.0000e+00 - val_loss: 4483.8244 - val_acc: 0.0000e+00\n",
            "Epoch 427/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4401.6617 - acc: 0.0000e+00 - val_loss: 4469.9366 - val_acc: 0.0000e+00\n",
            "Epoch 428/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 4720.3571 - acc: 0.0000e+00 - val_loss: 4469.1780 - val_acc: 0.0000e+00\n",
            "Epoch 429/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4232.0028 - acc: 0.0000e+00 - val_loss: 4470.2103 - val_acc: 0.0000e+00\n",
            "Epoch 430/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3934.1458 - acc: 0.0000e+00 - val_loss: 4468.9068 - val_acc: 0.0000e+00\n",
            "Epoch 431/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 4260.2850 - acc: 0.0000e+00 - val_loss: 4469.8746 - val_acc: 0.0000e+00\n",
            "Epoch 432/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4740.5732 - acc: 0.0000e+00 - val_loss: 4466.3767 - val_acc: 0.0000e+00\n",
            "Epoch 433/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4496.5994 - acc: 0.0000e+00 - val_loss: 4469.6353 - val_acc: 0.0000e+00\n",
            "Epoch 434/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 4749.3400 - acc: 0.0000e+00 - val_loss: 4462.4387 - val_acc: 0.0000e+00\n",
            "Epoch 435/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 3986.2463 - acc: 0.0000e+00 - val_loss: 4456.6385 - val_acc: 0.0000e+00\n",
            "Epoch 436/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 5108.8953 - acc: 0.0000e+00 - val_loss: 4480.6708 - val_acc: 0.0000e+00\n",
            "Epoch 437/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4777.9039 - acc: 0.0000e+00 - val_loss: 4458.8311 - val_acc: 0.0000e+00\n",
            "Epoch 438/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4623.9703 - acc: 0.0000e+00 - val_loss: 4448.7741 - val_acc: 0.0000e+00\n",
            "Epoch 439/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4612.1299 - acc: 0.0000e+00 - val_loss: 4463.3865 - val_acc: 0.0000e+00\n",
            "Epoch 440/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4295.4246 - acc: 0.0000e+00 - val_loss: 4483.1012 - val_acc: 0.0000e+00\n",
            "Epoch 441/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3985.1636 - acc: 0.0000e+00 - val_loss: 4491.7171 - val_acc: 0.0000e+00\n",
            "Epoch 442/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4810.1919 - acc: 0.0000e+00 - val_loss: 4534.6984 - val_acc: 0.0000e+00\n",
            "Epoch 443/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4012.5949 - acc: 0.0000e+00 - val_loss: 4569.0546 - val_acc: 0.0000e+00\n",
            "Epoch 444/1500\n",
            "348/348 [==============================] - 0s 113us/sample - loss: 4492.2062 - acc: 0.0000e+00 - val_loss: 4621.7116 - val_acc: 0.0000e+00\n",
            "Epoch 445/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4355.2401 - acc: 0.0000e+00 - val_loss: 4782.0718 - val_acc: 0.0000e+00\n",
            "Epoch 446/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4487.6823 - acc: 0.0000e+00 - val_loss: 4903.7607 - val_acc: 0.0000e+00\n",
            "Epoch 447/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 4286.8922 - acc: 0.0000e+00 - val_loss: 5328.0734 - val_acc: 0.0000e+00\n",
            "Epoch 448/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4652.3653 - acc: 0.0000e+00 - val_loss: 6738.0682 - val_acc: 0.0000e+00\n",
            "Epoch 449/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4173.9219 - acc: 0.0000e+00 - val_loss: 8367.3544 - val_acc: 0.0000e+00\n",
            "Epoch 450/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 5082.3121 - acc: 0.0000e+00 - val_loss: 7863.5569 - val_acc: 0.0000e+00\n",
            "Epoch 451/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4688.0030 - acc: 0.0000e+00 - val_loss: 7307.6660 - val_acc: 0.0000e+00\n",
            "Epoch 452/1500\n",
            "348/348 [==============================] - 0s 84us/sample - loss: 4291.3627 - acc: 0.0000e+00 - val_loss: 6712.1057 - val_acc: 0.0000e+00\n",
            "Epoch 453/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4310.5437 - acc: 0.0000e+00 - val_loss: 6431.9150 - val_acc: 0.0000e+00\n",
            "Epoch 454/1500\n",
            "348/348 [==============================] - 0s 117us/sample - loss: 4620.3731 - acc: 0.0000e+00 - val_loss: 6467.7048 - val_acc: 0.0000e+00\n",
            "Epoch 455/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4457.4398 - acc: 0.0000e+00 - val_loss: 6410.1724 - val_acc: 0.0000e+00\n",
            "Epoch 456/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4326.0902 - acc: 0.0000e+00 - val_loss: 6145.9092 - val_acc: 0.0000e+00\n",
            "Epoch 457/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4251.8775 - acc: 0.0000e+00 - val_loss: 5913.6076 - val_acc: 0.0000e+00\n",
            "Epoch 458/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4582.5385 - acc: 0.0000e+00 - val_loss: 5841.5811 - val_acc: 0.0000e+00\n",
            "Epoch 459/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4442.7551 - acc: 0.0000e+00 - val_loss: 5658.2705 - val_acc: 0.0000e+00\n",
            "Epoch 460/1500\n",
            "348/348 [==============================] - 0s 83us/sample - loss: 4257.5390 - acc: 0.0000e+00 - val_loss: 5766.3482 - val_acc: 0.0000e+00\n",
            "Epoch 461/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4422.8488 - acc: 0.0000e+00 - val_loss: 6004.1845 - val_acc: 0.0000e+00\n",
            "Epoch 462/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4133.2498 - acc: 0.0000e+00 - val_loss: 6278.8616 - val_acc: 0.0000e+00\n",
            "Epoch 463/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4583.4632 - acc: 0.0000e+00 - val_loss: 6340.6081 - val_acc: 0.0000e+00\n",
            "Epoch 464/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4665.6269 - acc: 0.0000e+00 - val_loss: 6172.6765 - val_acc: 0.0000e+00\n",
            "Epoch 465/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4080.3343 - acc: 0.0000e+00 - val_loss: 6044.2031 - val_acc: 0.0000e+00\n",
            "Epoch 466/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4830.9705 - acc: 0.0000e+00 - val_loss: 5931.9026 - val_acc: 0.0000e+00\n",
            "Epoch 467/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 5211.8805 - acc: 0.0000e+00 - val_loss: 5921.5116 - val_acc: 0.0000e+00\n",
            "Epoch 468/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4636.0197 - acc: 0.0000e+00 - val_loss: 5721.8314 - val_acc: 0.0000e+00\n",
            "Epoch 469/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4431.7451 - acc: 0.0000e+00 - val_loss: 5489.8042 - val_acc: 0.0000e+00\n",
            "Epoch 470/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4124.1405 - acc: 0.0000e+00 - val_loss: 5314.7128 - val_acc: 0.0000e+00\n",
            "Epoch 471/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4350.1399 - acc: 0.0000e+00 - val_loss: 5100.9066 - val_acc: 0.0000e+00\n",
            "Epoch 472/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 3986.0013 - acc: 0.0000e+00 - val_loss: 4910.8167 - val_acc: 0.0000e+00\n",
            "Epoch 473/1500\n",
            "348/348 [==============================] - 0s 116us/sample - loss: 4394.9091 - acc: 0.0000e+00 - val_loss: 4830.5691 - val_acc: 0.0000e+00\n",
            "Epoch 474/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4733.9392 - acc: 0.0000e+00 - val_loss: 4538.2387 - val_acc: 0.0000e+00\n",
            "Epoch 475/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4160.9764 - acc: 0.0000e+00 - val_loss: 4497.5278 - val_acc: 0.0000e+00\n",
            "Epoch 476/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4511.7912 - acc: 0.0000e+00 - val_loss: 4494.4013 - val_acc: 0.0000e+00\n",
            "Epoch 477/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 4429.5015 - acc: 0.0000e+00 - val_loss: 4475.2790 - val_acc: 0.0000e+00\n",
            "Epoch 478/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4960.0548 - acc: 0.0000e+00 - val_loss: 4484.6308 - val_acc: 0.0000e+00\n",
            "Epoch 479/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4408.7055 - acc: 0.0000e+00 - val_loss: 4482.0966 - val_acc: 0.0000e+00\n",
            "Epoch 480/1500\n",
            "348/348 [==============================] - 0s 109us/sample - loss: 5446.0284 - acc: 0.0000e+00 - val_loss: 4465.0551 - val_acc: 0.0000e+00\n",
            "Epoch 481/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4001.6670 - acc: 0.0000e+00 - val_loss: 4474.6850 - val_acc: 0.0000e+00\n",
            "Epoch 482/1500\n",
            "348/348 [==============================] - 0s 121us/sample - loss: 4247.2176 - acc: 0.0000e+00 - val_loss: 4484.6614 - val_acc: 0.0000e+00\n",
            "Epoch 483/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4491.0595 - acc: 0.0000e+00 - val_loss: 4485.9782 - val_acc: 0.0000e+00\n",
            "Epoch 484/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4442.8205 - acc: 0.0000e+00 - val_loss: 4547.9386 - val_acc: 0.0000e+00\n",
            "Epoch 485/1500\n",
            "348/348 [==============================] - 0s 110us/sample - loss: 4740.6094 - acc: 0.0000e+00 - val_loss: 4579.9847 - val_acc: 0.0000e+00\n",
            "Epoch 486/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4652.2532 - acc: 0.0000e+00 - val_loss: 4514.8013 - val_acc: 0.0000e+00\n",
            "Epoch 487/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4230.9362 - acc: 0.0000e+00 - val_loss: 4493.5702 - val_acc: 0.0000e+00\n",
            "Epoch 488/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4507.4686 - acc: 0.0000e+00 - val_loss: 4491.5208 - val_acc: 0.0000e+00\n",
            "Epoch 489/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4430.1647 - acc: 0.0000e+00 - val_loss: 4471.0375 - val_acc: 0.0000e+00\n",
            "Epoch 490/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4238.2717 - acc: 0.0000e+00 - val_loss: 4417.3475 - val_acc: 0.0000e+00\n",
            "Epoch 491/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3938.9882 - acc: 0.0000e+00 - val_loss: 4403.1693 - val_acc: 0.0000e+00\n",
            "Epoch 492/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4136.0379 - acc: 0.0000e+00 - val_loss: 4397.0463 - val_acc: 0.0000e+00\n",
            "Epoch 493/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 5159.4881 - acc: 0.0000e+00 - val_loss: 4403.9738 - val_acc: 0.0000e+00\n",
            "Epoch 494/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4267.7426 - acc: 0.0000e+00 - val_loss: 4409.7760 - val_acc: 0.0000e+00\n",
            "Epoch 495/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4607.9872 - acc: 0.0000e+00 - val_loss: 4400.7417 - val_acc: 0.0000e+00\n",
            "Epoch 496/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4178.0111 - acc: 0.0000e+00 - val_loss: 4426.7488 - val_acc: 0.0000e+00\n",
            "Epoch 497/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 4320.2967 - acc: 0.0000e+00 - val_loss: 4431.8245 - val_acc: 0.0000e+00\n",
            "Epoch 498/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4933.9962 - acc: 0.0000e+00 - val_loss: 4438.4096 - val_acc: 0.0000e+00\n",
            "Epoch 499/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4333.4275 - acc: 0.0000e+00 - val_loss: 4380.8447 - val_acc: 0.0000e+00\n",
            "Epoch 500/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4037.9768 - acc: 0.0000e+00 - val_loss: 4367.9137 - val_acc: 0.0000e+00\n",
            "Epoch 501/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 4269.6213 - acc: 0.0000e+00 - val_loss: 4355.2737 - val_acc: 0.0000e+00\n",
            "Epoch 502/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4648.1465 - acc: 0.0000e+00 - val_loss: 4351.1402 - val_acc: 0.0000e+00\n",
            "Epoch 503/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3943.2987 - acc: 0.0000e+00 - val_loss: 4346.7816 - val_acc: 0.0000e+00\n",
            "Epoch 504/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 4232.2301 - acc: 0.0000e+00 - val_loss: 4358.2026 - val_acc: 0.0000e+00\n",
            "Epoch 505/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3798.9287 - acc: 0.0000e+00 - val_loss: 4367.3514 - val_acc: 0.0000e+00\n",
            "Epoch 506/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4624.6792 - acc: 0.0000e+00 - val_loss: 4359.4450 - val_acc: 0.0000e+00\n",
            "Epoch 507/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4517.3213 - acc: 0.0000e+00 - val_loss: 4352.0525 - val_acc: 0.0000e+00\n",
            "Epoch 508/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4345.2488 - acc: 0.0000e+00 - val_loss: 4331.0573 - val_acc: 0.0000e+00\n",
            "Epoch 509/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4527.9304 - acc: 0.0000e+00 - val_loss: 4320.3721 - val_acc: 0.0000e+00\n",
            "Epoch 510/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4566.0147 - acc: 0.0000e+00 - val_loss: 4324.2145 - val_acc: 0.0000e+00\n",
            "Epoch 511/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4957.8007 - acc: 0.0000e+00 - val_loss: 4315.1410 - val_acc: 0.0000e+00\n",
            "Epoch 512/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3840.1346 - acc: 0.0000e+00 - val_loss: 4319.5411 - val_acc: 0.0000e+00\n",
            "Epoch 513/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4283.9707 - acc: 0.0000e+00 - val_loss: 4332.9044 - val_acc: 0.0000e+00\n",
            "Epoch 514/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4099.2093 - acc: 0.0000e+00 - val_loss: 4303.8933 - val_acc: 0.0000e+00\n",
            "Epoch 515/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4174.3374 - acc: 0.0000e+00 - val_loss: 4296.2786 - val_acc: 0.0000e+00\n",
            "Epoch 516/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4087.4480 - acc: 0.0000e+00 - val_loss: 4290.9017 - val_acc: 0.0000e+00\n",
            "Epoch 517/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3803.2713 - acc: 0.0000e+00 - val_loss: 4293.3963 - val_acc: 0.0000e+00\n",
            "Epoch 518/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4439.4510 - acc: 0.0000e+00 - val_loss: 4288.1003 - val_acc: 0.0000e+00\n",
            "Epoch 519/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4666.4177 - acc: 0.0000e+00 - val_loss: 4278.2153 - val_acc: 0.0000e+00\n",
            "Epoch 520/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4311.3269 - acc: 0.0000e+00 - val_loss: 4281.0100 - val_acc: 0.0000e+00\n",
            "Epoch 521/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4316.2490 - acc: 0.0000e+00 - val_loss: 4276.7024 - val_acc: 0.0000e+00\n",
            "Epoch 522/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4473.8343 - acc: 0.0000e+00 - val_loss: 4280.2051 - val_acc: 0.0000e+00\n",
            "Epoch 523/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4107.6434 - acc: 0.0000e+00 - val_loss: 4271.6394 - val_acc: 0.0000e+00\n",
            "Epoch 524/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4042.7448 - acc: 0.0000e+00 - val_loss: 4266.4871 - val_acc: 0.0000e+00\n",
            "Epoch 525/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4826.0991 - acc: 0.0000e+00 - val_loss: 4258.3202 - val_acc: 0.0000e+00\n",
            "Epoch 526/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 5030.0873 - acc: 0.0000e+00 - val_loss: 4270.2293 - val_acc: 0.0000e+00\n",
            "Epoch 527/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3930.2998 - acc: 0.0000e+00 - val_loss: 4252.3733 - val_acc: 0.0000e+00\n",
            "Epoch 528/1500\n",
            "348/348 [==============================] - 0s 110us/sample - loss: 4600.7678 - acc: 0.0000e+00 - val_loss: 4248.9104 - val_acc: 0.0000e+00\n",
            "Epoch 529/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 4903.5119 - acc: 0.0000e+00 - val_loss: 4279.3994 - val_acc: 0.0000e+00\n",
            "Epoch 530/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3992.4282 - acc: 0.0000e+00 - val_loss: 4273.6421 - val_acc: 0.0000e+00\n",
            "Epoch 531/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4083.2123 - acc: 0.0000e+00 - val_loss: 4248.3445 - val_acc: 0.0000e+00\n",
            "Epoch 532/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4545.8979 - acc: 0.0000e+00 - val_loss: 4240.3999 - val_acc: 0.0000e+00\n",
            "Epoch 533/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4325.2418 - acc: 0.0000e+00 - val_loss: 4242.2833 - val_acc: 0.0000e+00\n",
            "Epoch 534/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4090.9902 - acc: 0.0000e+00 - val_loss: 4244.6059 - val_acc: 0.0000e+00\n",
            "Epoch 535/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4200.5637 - acc: 0.0000e+00 - val_loss: 4264.9048 - val_acc: 0.0000e+00\n",
            "Epoch 536/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4339.3453 - acc: 0.0000e+00 - val_loss: 4282.9557 - val_acc: 0.0000e+00\n",
            "Epoch 537/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4459.5837 - acc: 0.0000e+00 - val_loss: 4280.7699 - val_acc: 0.0000e+00\n",
            "Epoch 538/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4286.3111 - acc: 0.0000e+00 - val_loss: 4234.4710 - val_acc: 0.0000e+00\n",
            "Epoch 539/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4077.1772 - acc: 0.0000e+00 - val_loss: 4233.6762 - val_acc: 0.0000e+00\n",
            "Epoch 540/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4651.3867 - acc: 0.0000e+00 - val_loss: 4237.6950 - val_acc: 0.0000e+00\n",
            "Epoch 541/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3977.8911 - acc: 0.0000e+00 - val_loss: 4214.8785 - val_acc: 0.0000e+00\n",
            "Epoch 542/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3888.8562 - acc: 0.0000e+00 - val_loss: 4209.1691 - val_acc: 0.0000e+00\n",
            "Epoch 543/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4121.1238 - acc: 0.0000e+00 - val_loss: 4206.7392 - val_acc: 0.0000e+00\n",
            "Epoch 544/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4313.7934 - acc: 0.0000e+00 - val_loss: 4193.7373 - val_acc: 0.0000e+00\n",
            "Epoch 545/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3765.7932 - acc: 0.0000e+00 - val_loss: 4201.5205 - val_acc: 0.0000e+00\n",
            "Epoch 546/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4812.2517 - acc: 0.0000e+00 - val_loss: 4188.0524 - val_acc: 0.0000e+00\n",
            "Epoch 547/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 4230.9010 - acc: 0.0000e+00 - val_loss: 4187.0902 - val_acc: 0.0000e+00\n",
            "Epoch 548/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4539.3455 - acc: 0.0000e+00 - val_loss: 4179.6885 - val_acc: 0.0000e+00\n",
            "Epoch 549/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4485.2745 - acc: 0.0000e+00 - val_loss: 4188.2771 - val_acc: 0.0000e+00\n",
            "Epoch 550/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3550.1141 - acc: 0.0000e+00 - val_loss: 4189.5813 - val_acc: 0.0000e+00\n",
            "Epoch 551/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4220.3382 - acc: 0.0000e+00 - val_loss: 4189.6250 - val_acc: 0.0000e+00\n",
            "Epoch 552/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4226.3908 - acc: 0.0000e+00 - val_loss: 4180.6651 - val_acc: 0.0000e+00\n",
            "Epoch 553/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4261.0843 - acc: 0.0000e+00 - val_loss: 4177.2930 - val_acc: 0.0000e+00\n",
            "Epoch 554/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4835.5939 - acc: 0.0000e+00 - val_loss: 4196.6805 - val_acc: 0.0000e+00\n",
            "Epoch 555/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3672.9235 - acc: 0.0000e+00 - val_loss: 4192.7838 - val_acc: 0.0000e+00\n",
            "Epoch 556/1500\n",
            "348/348 [==============================] - 0s 110us/sample - loss: 3904.1869 - acc: 0.0000e+00 - val_loss: 4183.8670 - val_acc: 0.0000e+00\n",
            "Epoch 557/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 3948.8519 - acc: 0.0000e+00 - val_loss: 4227.3486 - val_acc: 0.0000e+00\n",
            "Epoch 558/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4494.9772 - acc: 0.0000e+00 - val_loss: 4237.5984 - val_acc: 0.0000e+00\n",
            "Epoch 559/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4167.3989 - acc: 0.0000e+00 - val_loss: 4231.5443 - val_acc: 0.0000e+00\n",
            "Epoch 560/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4150.4230 - acc: 0.0000e+00 - val_loss: 4318.8835 - val_acc: 0.0000e+00\n",
            "Epoch 561/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4852.3163 - acc: 0.0000e+00 - val_loss: 4503.2903 - val_acc: 0.0000e+00\n",
            "Epoch 562/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3761.7840 - acc: 0.0000e+00 - val_loss: 4367.6006 - val_acc: 0.0000e+00\n",
            "Epoch 563/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4374.0335 - acc: 0.0000e+00 - val_loss: 4260.9584 - val_acc: 0.0000e+00\n",
            "Epoch 564/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4613.5480 - acc: 0.0000e+00 - val_loss: 4190.0299 - val_acc: 0.0000e+00\n",
            "Epoch 565/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4082.6397 - acc: 0.0000e+00 - val_loss: 4217.1614 - val_acc: 0.0000e+00\n",
            "Epoch 566/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4700.8429 - acc: 0.0000e+00 - val_loss: 4226.5683 - val_acc: 0.0000e+00\n",
            "Epoch 567/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4221.8055 - acc: 0.0000e+00 - val_loss: 4246.3776 - val_acc: 0.0000e+00\n",
            "Epoch 568/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4387.1394 - acc: 0.0000e+00 - val_loss: 4163.1690 - val_acc: 0.0000e+00\n",
            "Epoch 569/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4340.1711 - acc: 0.0000e+00 - val_loss: 4169.7101 - val_acc: 0.0000e+00\n",
            "Epoch 570/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3705.2556 - acc: 0.0000e+00 - val_loss: 4165.4568 - val_acc: 0.0000e+00\n",
            "Epoch 571/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4057.1980 - acc: 0.0000e+00 - val_loss: 4167.8172 - val_acc: 0.0000e+00\n",
            "Epoch 572/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3827.6387 - acc: 0.0000e+00 - val_loss: 4174.0448 - val_acc: 0.0000e+00\n",
            "Epoch 573/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3945.2960 - acc: 0.0000e+00 - val_loss: 4153.5260 - val_acc: 0.0000e+00\n",
            "Epoch 574/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4332.8884 - acc: 0.0000e+00 - val_loss: 4134.6783 - val_acc: 0.0000e+00\n",
            "Epoch 575/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 4389.9650 - acc: 0.0000e+00 - val_loss: 4143.0586 - val_acc: 0.0000e+00\n",
            "Epoch 576/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4306.8481 - acc: 0.0000e+00 - val_loss: 4119.9068 - val_acc: 0.0000e+00\n",
            "Epoch 577/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 4334.8789 - acc: 0.0000e+00 - val_loss: 4122.0582 - val_acc: 0.0000e+00\n",
            "Epoch 578/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 4095.9602 - acc: 0.0000e+00 - val_loss: 4127.1803 - val_acc: 0.0000e+00\n",
            "Epoch 579/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4391.3740 - acc: 0.0000e+00 - val_loss: 4113.7702 - val_acc: 0.0000e+00\n",
            "Epoch 580/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 5119.9718 - acc: 0.0000e+00 - val_loss: 4107.3879 - val_acc: 0.0000e+00\n",
            "Epoch 581/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4447.4706 - acc: 0.0000e+00 - val_loss: 4110.8565 - val_acc: 0.0000e+00\n",
            "Epoch 582/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4244.3893 - acc: 0.0000e+00 - val_loss: 4158.6597 - val_acc: 0.0000e+00\n",
            "Epoch 583/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4043.6659 - acc: 0.0000e+00 - val_loss: 4230.5158 - val_acc: 0.0000e+00\n",
            "Epoch 584/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3709.8288 - acc: 0.0000e+00 - val_loss: 4257.4530 - val_acc: 0.0000e+00\n",
            "Epoch 585/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4189.0976 - acc: 0.0000e+00 - val_loss: 4287.3954 - val_acc: 0.0000e+00\n",
            "Epoch 586/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4105.9601 - acc: 0.0000e+00 - val_loss: 4293.2602 - val_acc: 0.0000e+00\n",
            "Epoch 587/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4014.3379 - acc: 0.0000e+00 - val_loss: 4209.2163 - val_acc: 0.0000e+00\n",
            "Epoch 588/1500\n",
            "348/348 [==============================] - 0s 84us/sample - loss: 4278.6382 - acc: 0.0000e+00 - val_loss: 4107.1066 - val_acc: 0.0000e+00\n",
            "Epoch 589/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3994.0525 - acc: 0.0000e+00 - val_loss: 4095.6560 - val_acc: 0.0000e+00\n",
            "Epoch 590/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4287.1014 - acc: 0.0000e+00 - val_loss: 4108.6961 - val_acc: 0.0000e+00\n",
            "Epoch 591/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4065.5141 - acc: 0.0000e+00 - val_loss: 4087.8068 - val_acc: 0.0000e+00\n",
            "Epoch 592/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 4512.9770 - acc: 0.0000e+00 - val_loss: 4085.3554 - val_acc: 0.0000e+00\n",
            "Epoch 593/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3837.3706 - acc: 0.0000e+00 - val_loss: 4085.9623 - val_acc: 0.0000e+00\n",
            "Epoch 594/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3677.1254 - acc: 0.0000e+00 - val_loss: 4081.8369 - val_acc: 0.0000e+00\n",
            "Epoch 595/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4037.9788 - acc: 0.0000e+00 - val_loss: 4082.7600 - val_acc: 0.0000e+00\n",
            "Epoch 596/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4935.7521 - acc: 0.0000e+00 - val_loss: 4075.8548 - val_acc: 0.0000e+00\n",
            "Epoch 597/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3956.6617 - acc: 0.0000e+00 - val_loss: 4082.3174 - val_acc: 0.0000e+00\n",
            "Epoch 598/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4090.5850 - acc: 0.0000e+00 - val_loss: 4086.1657 - val_acc: 0.0000e+00\n",
            "Epoch 599/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4276.4691 - acc: 0.0000e+00 - val_loss: 4108.8470 - val_acc: 0.0000e+00\n",
            "Epoch 600/1500\n",
            "348/348 [==============================] - 0s 115us/sample - loss: 4235.5963 - acc: 0.0000e+00 - val_loss: 4127.4156 - val_acc: 0.0000e+00\n",
            "Epoch 601/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4285.0728 - acc: 0.0000e+00 - val_loss: 4140.3942 - val_acc: 0.0000e+00\n",
            "Epoch 602/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4556.7956 - acc: 0.0000e+00 - val_loss: 4361.5425 - val_acc: 0.0000e+00\n",
            "Epoch 603/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4191.0614 - acc: 0.0000e+00 - val_loss: 4446.8411 - val_acc: 0.0000e+00\n",
            "Epoch 604/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4312.2408 - acc: 0.0000e+00 - val_loss: 4344.4259 - val_acc: 0.0000e+00\n",
            "Epoch 605/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4656.8934 - acc: 0.0000e+00 - val_loss: 4336.8630 - val_acc: 0.0000e+00\n",
            "Epoch 606/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3668.7530 - acc: 0.0000e+00 - val_loss: 4166.9146 - val_acc: 0.0000e+00\n",
            "Epoch 607/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4395.1861 - acc: 0.0000e+00 - val_loss: 4200.6292 - val_acc: 0.0000e+00\n",
            "Epoch 608/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4415.0548 - acc: 0.0000e+00 - val_loss: 4163.4256 - val_acc: 0.0000e+00\n",
            "Epoch 609/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4398.2650 - acc: 0.0000e+00 - val_loss: 4142.6308 - val_acc: 0.0000e+00\n",
            "Epoch 610/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3874.4739 - acc: 0.0000e+00 - val_loss: 4118.2908 - val_acc: 0.0000e+00\n",
            "Epoch 611/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4437.9192 - acc: 0.0000e+00 - val_loss: 4061.8956 - val_acc: 0.0000e+00\n",
            "Epoch 612/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3998.3557 - acc: 0.0000e+00 - val_loss: 4055.5805 - val_acc: 0.0000e+00\n",
            "Epoch 613/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3797.8840 - acc: 0.0000e+00 - val_loss: 4079.5147 - val_acc: 0.0000e+00\n",
            "Epoch 614/1500\n",
            "348/348 [==============================] - 0s 117us/sample - loss: 3730.8850 - acc: 0.0000e+00 - val_loss: 4076.3936 - val_acc: 0.0000e+00\n",
            "Epoch 615/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4726.5292 - acc: 0.0000e+00 - val_loss: 4093.8829 - val_acc: 0.0000e+00\n",
            "Epoch 616/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4260.8093 - acc: 0.0000e+00 - val_loss: 4126.8149 - val_acc: 0.0000e+00\n",
            "Epoch 617/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 4536.5476 - acc: 0.0000e+00 - val_loss: 4079.1171 - val_acc: 0.0000e+00\n",
            "Epoch 618/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3770.0731 - acc: 0.0000e+00 - val_loss: 4052.1488 - val_acc: 0.0000e+00\n",
            "Epoch 619/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3698.5818 - acc: 0.0000e+00 - val_loss: 4059.9471 - val_acc: 0.0000e+00\n",
            "Epoch 620/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4034.2818 - acc: 0.0000e+00 - val_loss: 4055.9000 - val_acc: 0.0000e+00\n",
            "Epoch 621/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3937.1912 - acc: 0.0000e+00 - val_loss: 4049.2915 - val_acc: 0.0000e+00\n",
            "Epoch 622/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 3588.1633 - acc: 0.0000e+00 - val_loss: 4050.1429 - val_acc: 0.0000e+00\n",
            "Epoch 623/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3735.3926 - acc: 0.0000e+00 - val_loss: 4065.4604 - val_acc: 0.0000e+00\n",
            "Epoch 624/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3855.0066 - acc: 0.0000e+00 - val_loss: 4084.7706 - val_acc: 0.0000e+00\n",
            "Epoch 625/1500\n",
            "348/348 [==============================] - 0s 115us/sample - loss: 4311.7766 - acc: 0.0000e+00 - val_loss: 4046.7154 - val_acc: 0.0000e+00\n",
            "Epoch 626/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 4125.3903 - acc: 0.0000e+00 - val_loss: 4065.9457 - val_acc: 0.0000e+00\n",
            "Epoch 627/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4032.8049 - acc: 0.0000e+00 - val_loss: 4077.2123 - val_acc: 0.0000e+00\n",
            "Epoch 628/1500\n",
            "348/348 [==============================] - 0s 112us/sample - loss: 3659.3884 - acc: 0.0000e+00 - val_loss: 4099.8411 - val_acc: 0.0000e+00\n",
            "Epoch 629/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 4358.6257 - acc: 0.0000e+00 - val_loss: 4102.7387 - val_acc: 0.0000e+00\n",
            "Epoch 630/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 3879.0666 - acc: 0.0000e+00 - val_loss: 4158.8528 - val_acc: 0.0000e+00\n",
            "Epoch 631/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4590.2187 - acc: 0.0000e+00 - val_loss: 4079.5067 - val_acc: 0.0000e+00\n",
            "Epoch 632/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3688.7296 - acc: 0.0000e+00 - val_loss: 4059.0340 - val_acc: 0.0000e+00\n",
            "Epoch 633/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3528.0778 - acc: 0.0000e+00 - val_loss: 4035.6911 - val_acc: 0.0000e+00\n",
            "Epoch 634/1500\n",
            "348/348 [==============================] - 0s 111us/sample - loss: 4634.7017 - acc: 0.0000e+00 - val_loss: 4034.9715 - val_acc: 0.0000e+00\n",
            "Epoch 635/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3980.1876 - acc: 0.0000e+00 - val_loss: 4036.0711 - val_acc: 0.0000e+00\n",
            "Epoch 636/1500\n",
            "348/348 [==============================] - 0s 112us/sample - loss: 4179.1111 - acc: 0.0000e+00 - val_loss: 4034.7476 - val_acc: 0.0000e+00\n",
            "Epoch 637/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 4352.9635 - acc: 0.0000e+00 - val_loss: 4065.9884 - val_acc: 0.0000e+00\n",
            "Epoch 638/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3632.1951 - acc: 0.0000e+00 - val_loss: 4057.0161 - val_acc: 0.0000e+00\n",
            "Epoch 639/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4452.2510 - acc: 0.0000e+00 - val_loss: 4119.0876 - val_acc: 0.0000e+00\n",
            "Epoch 640/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 3620.5350 - acc: 0.0000e+00 - val_loss: 4068.4965 - val_acc: 0.0000e+00\n",
            "Epoch 641/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4177.1653 - acc: 0.0000e+00 - val_loss: 4035.5594 - val_acc: 0.0000e+00\n",
            "Epoch 642/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3662.6176 - acc: 0.0000e+00 - val_loss: 4093.6433 - val_acc: 0.0000e+00\n",
            "Epoch 643/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4413.9347 - acc: 0.0000e+00 - val_loss: 4077.7737 - val_acc: 0.0000e+00\n",
            "Epoch 644/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 4065.2403 - acc: 0.0000e+00 - val_loss: 4088.5552 - val_acc: 0.0000e+00\n",
            "Epoch 645/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3604.9500 - acc: 0.0000e+00 - val_loss: 4052.8329 - val_acc: 0.0000e+00\n",
            "Epoch 646/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4252.6348 - acc: 0.0000e+00 - val_loss: 4039.3565 - val_acc: 0.0000e+00\n",
            "Epoch 647/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 4137.3990 - acc: 0.0000e+00 - val_loss: 4109.1581 - val_acc: 0.0000e+00\n",
            "Epoch 648/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3632.0848 - acc: 0.0000e+00 - val_loss: 4287.9343 - val_acc: 0.0000e+00\n",
            "Epoch 649/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 4560.8016 - acc: 0.0000e+00 - val_loss: 4178.4646 - val_acc: 0.0000e+00\n",
            "Epoch 650/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3577.8576 - acc: 0.0000e+00 - val_loss: 4116.7266 - val_acc: 0.0000e+00\n",
            "Epoch 651/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3701.1295 - acc: 0.0000e+00 - val_loss: 4066.0462 - val_acc: 0.0000e+00\n",
            "Epoch 652/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4012.7047 - acc: 0.0000e+00 - val_loss: 4064.2438 - val_acc: 0.0000e+00\n",
            "Epoch 653/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 3505.0697 - acc: 0.0000e+00 - val_loss: 4045.9819 - val_acc: 0.0000e+00\n",
            "Epoch 654/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4052.1629 - acc: 0.0000e+00 - val_loss: 4020.6929 - val_acc: 0.0000e+00\n",
            "Epoch 655/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4112.7114 - acc: 0.0000e+00 - val_loss: 4018.1665 - val_acc: 0.0000e+00\n",
            "Epoch 656/1500\n",
            "348/348 [==============================] - 0s 111us/sample - loss: 4949.8484 - acc: 0.0000e+00 - val_loss: 4037.7793 - val_acc: 0.0000e+00\n",
            "Epoch 657/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4432.4150 - acc: 0.0000e+00 - val_loss: 4082.1819 - val_acc: 0.0000e+00\n",
            "Epoch 658/1500\n",
            "348/348 [==============================] - 0s 84us/sample - loss: 3620.4967 - acc: 0.0000e+00 - val_loss: 4028.9771 - val_acc: 0.0000e+00\n",
            "Epoch 659/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 3930.0387 - acc: 0.0000e+00 - val_loss: 4013.8394 - val_acc: 0.0000e+00\n",
            "Epoch 660/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3865.3388 - acc: 0.0000e+00 - val_loss: 4011.3461 - val_acc: 0.0000e+00\n",
            "Epoch 661/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4507.9571 - acc: 0.0000e+00 - val_loss: 4016.5795 - val_acc: 0.0000e+00\n",
            "Epoch 662/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3644.4451 - acc: 0.0000e+00 - val_loss: 4071.9692 - val_acc: 0.0000e+00\n",
            "Epoch 663/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3932.5988 - acc: 0.0000e+00 - val_loss: 4105.6137 - val_acc: 0.0000e+00\n",
            "Epoch 664/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3858.9695 - acc: 0.0000e+00 - val_loss: 4085.5739 - val_acc: 0.0000e+00\n",
            "Epoch 665/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4836.3337 - acc: 0.0000e+00 - val_loss: 4020.2158 - val_acc: 0.0000e+00\n",
            "Epoch 666/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3960.3875 - acc: 0.0000e+00 - val_loss: 4024.1752 - val_acc: 0.0000e+00\n",
            "Epoch 667/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 4358.1879 - acc: 0.0000e+00 - val_loss: 4010.4001 - val_acc: 0.0000e+00\n",
            "Epoch 668/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3638.7449 - acc: 0.0000e+00 - val_loss: 4007.3340 - val_acc: 0.0000e+00\n",
            "Epoch 669/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3827.2651 - acc: 0.0000e+00 - val_loss: 4013.6448 - val_acc: 0.0000e+00\n",
            "Epoch 670/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4185.2906 - acc: 0.0000e+00 - val_loss: 4026.0419 - val_acc: 0.0000e+00\n",
            "Epoch 671/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3751.9254 - acc: 0.0000e+00 - val_loss: 4012.1132 - val_acc: 0.0000e+00\n",
            "Epoch 672/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4443.1184 - acc: 0.0000e+00 - val_loss: 4003.7417 - val_acc: 0.0000e+00\n",
            "Epoch 673/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4517.6020 - acc: 0.0000e+00 - val_loss: 3999.5885 - val_acc: 0.0000e+00\n",
            "Epoch 674/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3614.5653 - acc: 0.0000e+00 - val_loss: 4000.0992 - val_acc: 0.0000e+00\n",
            "Epoch 675/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3783.6057 - acc: 0.0000e+00 - val_loss: 4010.2986 - val_acc: 0.0000e+00\n",
            "Epoch 676/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4025.1101 - acc: 0.0000e+00 - val_loss: 4020.5713 - val_acc: 0.0000e+00\n",
            "Epoch 677/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4262.8128 - acc: 0.0000e+00 - val_loss: 4026.5008 - val_acc: 0.0000e+00\n",
            "Epoch 678/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4124.3482 - acc: 0.0000e+00 - val_loss: 4023.9651 - val_acc: 0.0000e+00\n",
            "Epoch 679/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3522.8053 - acc: 0.0000e+00 - val_loss: 4015.0542 - val_acc: 0.0000e+00\n",
            "Epoch 680/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 3731.9066 - acc: 0.0000e+00 - val_loss: 4032.2844 - val_acc: 0.0000e+00\n",
            "Epoch 681/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4079.3713 - acc: 0.0000e+00 - val_loss: 4108.0148 - val_acc: 0.0000e+00\n",
            "Epoch 682/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 4607.4069 - acc: 0.0000e+00 - val_loss: 4136.3482 - val_acc: 0.0000e+00\n",
            "Epoch 683/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4016.7174 - acc: 0.0000e+00 - val_loss: 4092.2302 - val_acc: 0.0000e+00\n",
            "Epoch 684/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3772.4000 - acc: 0.0000e+00 - val_loss: 4131.4725 - val_acc: 0.0000e+00\n",
            "Epoch 685/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3979.8540 - acc: 0.0000e+00 - val_loss: 4142.6647 - val_acc: 0.0000e+00\n",
            "Epoch 686/1500\n",
            "348/348 [==============================] - 0s 112us/sample - loss: 3759.8548 - acc: 0.0000e+00 - val_loss: 4074.8926 - val_acc: 0.0000e+00\n",
            "Epoch 687/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3484.5913 - acc: 0.0000e+00 - val_loss: 4054.2454 - val_acc: 0.0000e+00\n",
            "Epoch 688/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 3843.1680 - acc: 0.0000e+00 - val_loss: 4065.3600 - val_acc: 0.0000e+00\n",
            "Epoch 689/1500\n",
            "348/348 [==============================] - 0s 116us/sample - loss: 3457.3012 - acc: 0.0000e+00 - val_loss: 4059.2581 - val_acc: 0.0000e+00\n",
            "Epoch 690/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4119.6177 - acc: 0.0000e+00 - val_loss: 4053.1536 - val_acc: 0.0000e+00\n",
            "Epoch 691/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3951.2094 - acc: 0.0000e+00 - val_loss: 4038.2091 - val_acc: 0.0000e+00\n",
            "Epoch 692/1500\n",
            "348/348 [==============================] - 0s 84us/sample - loss: 3744.8439 - acc: 0.0000e+00 - val_loss: 4021.0614 - val_acc: 0.0000e+00\n",
            "Epoch 693/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4400.6734 - acc: 0.0000e+00 - val_loss: 4019.6526 - val_acc: 0.0000e+00\n",
            "Epoch 694/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3658.6785 - acc: 0.0000e+00 - val_loss: 4013.4769 - val_acc: 0.0000e+00\n",
            "Epoch 695/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4036.7210 - acc: 0.0000e+00 - val_loss: 4010.8108 - val_acc: 0.0000e+00\n",
            "Epoch 696/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4447.6813 - acc: 0.0000e+00 - val_loss: 3999.8977 - val_acc: 0.0000e+00\n",
            "Epoch 697/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3848.9192 - acc: 0.0000e+00 - val_loss: 3994.1174 - val_acc: 0.0000e+00\n",
            "Epoch 698/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4080.8403 - acc: 0.0000e+00 - val_loss: 3991.2934 - val_acc: 0.0000e+00\n",
            "Epoch 699/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3855.1012 - acc: 0.0000e+00 - val_loss: 3991.0173 - val_acc: 0.0000e+00\n",
            "Epoch 700/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4057.6796 - acc: 0.0000e+00 - val_loss: 3985.9241 - val_acc: 0.0000e+00\n",
            "Epoch 701/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4272.9328 - acc: 0.0000e+00 - val_loss: 4001.5635 - val_acc: 0.0000e+00\n",
            "Epoch 702/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3908.7213 - acc: 0.0000e+00 - val_loss: 4018.0087 - val_acc: 0.0000e+00\n",
            "Epoch 703/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4117.8748 - acc: 0.0000e+00 - val_loss: 4021.2565 - val_acc: 0.0000e+00\n",
            "Epoch 704/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4480.2157 - acc: 0.0000e+00 - val_loss: 4128.4101 - val_acc: 0.0000e+00\n",
            "Epoch 705/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 4370.7742 - acc: 0.0000e+00 - val_loss: 4150.6857 - val_acc: 0.0000e+00\n",
            "Epoch 706/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4509.6442 - acc: 0.0000e+00 - val_loss: 4335.4527 - val_acc: 0.0000e+00\n",
            "Epoch 707/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3877.1366 - acc: 0.0000e+00 - val_loss: 4653.0030 - val_acc: 0.0000e+00\n",
            "Epoch 708/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4056.6098 - acc: 0.0000e+00 - val_loss: 4699.4005 - val_acc: 0.0000e+00\n",
            "Epoch 709/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3939.3778 - acc: 0.0000e+00 - val_loss: 4609.4873 - val_acc: 0.0000e+00\n",
            "Epoch 710/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3830.7222 - acc: 0.0000e+00 - val_loss: 4349.6239 - val_acc: 0.0000e+00\n",
            "Epoch 711/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3679.1736 - acc: 0.0000e+00 - val_loss: 4166.1734 - val_acc: 0.0000e+00\n",
            "Epoch 712/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3807.1474 - acc: 0.0000e+00 - val_loss: 4109.9493 - val_acc: 0.0000e+00\n",
            "Epoch 713/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3587.0382 - acc: 0.0000e+00 - val_loss: 4065.3650 - val_acc: 0.0000e+00\n",
            "Epoch 714/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4577.7744 - acc: 0.0000e+00 - val_loss: 4061.7793 - val_acc: 0.0000e+00\n",
            "Epoch 715/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4164.3226 - acc: 0.0000e+00 - val_loss: 4021.6914 - val_acc: 0.0000e+00\n",
            "Epoch 716/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4141.6575 - acc: 0.0000e+00 - val_loss: 4023.9963 - val_acc: 0.0000e+00\n",
            "Epoch 717/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4507.6774 - acc: 0.0000e+00 - val_loss: 4042.2184 - val_acc: 0.0000e+00\n",
            "Epoch 718/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3722.5587 - acc: 0.0000e+00 - val_loss: 4140.2355 - val_acc: 0.0000e+00\n",
            "Epoch 719/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4896.0011 - acc: 0.0000e+00 - val_loss: 4089.5574 - val_acc: 0.0000e+00\n",
            "Epoch 720/1500\n",
            "348/348 [==============================] - 0s 109us/sample - loss: 3641.8349 - acc: 0.0000e+00 - val_loss: 4168.3150 - val_acc: 0.0000e+00\n",
            "Epoch 721/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3943.7964 - acc: 0.0000e+00 - val_loss: 4280.6088 - val_acc: 0.0000e+00\n",
            "Epoch 722/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3922.8092 - acc: 0.0000e+00 - val_loss: 4281.1036 - val_acc: 0.0000e+00\n",
            "Epoch 723/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 3724.4331 - acc: 0.0000e+00 - val_loss: 4245.2208 - val_acc: 0.0000e+00\n",
            "Epoch 724/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3951.0684 - acc: 0.0000e+00 - val_loss: 4322.5372 - val_acc: 0.0000e+00\n",
            "Epoch 725/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3883.8704 - acc: 0.0000e+00 - val_loss: 4403.0023 - val_acc: 0.0000e+00\n",
            "Epoch 726/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4329.7675 - acc: 0.0000e+00 - val_loss: 4446.0644 - val_acc: 0.0000e+00\n",
            "Epoch 727/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3851.5479 - acc: 0.0000e+00 - val_loss: 4410.1943 - val_acc: 0.0000e+00\n",
            "Epoch 728/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4281.4971 - acc: 0.0000e+00 - val_loss: 4372.1146 - val_acc: 0.0000e+00\n",
            "Epoch 729/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3962.8929 - acc: 0.0000e+00 - val_loss: 4471.1475 - val_acc: 0.0000e+00\n",
            "Epoch 730/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3939.1772 - acc: 0.0000e+00 - val_loss: 4531.0121 - val_acc: 0.0000e+00\n",
            "Epoch 731/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 4265.2301 - acc: 0.0000e+00 - val_loss: 4627.7992 - val_acc: 0.0000e+00\n",
            "Epoch 732/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3993.1875 - acc: 0.0000e+00 - val_loss: 4683.3329 - val_acc: 0.0000e+00\n",
            "Epoch 733/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 3900.3685 - acc: 0.0000e+00 - val_loss: 5111.8666 - val_acc: 0.0000e+00\n",
            "Epoch 734/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3610.0961 - acc: 0.0000e+00 - val_loss: 4819.8174 - val_acc: 0.0000e+00\n",
            "Epoch 735/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3609.9975 - acc: 0.0000e+00 - val_loss: 4301.0177 - val_acc: 0.0000e+00\n",
            "Epoch 736/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4195.9169 - acc: 0.0000e+00 - val_loss: 4090.5917 - val_acc: 0.0000e+00\n",
            "Epoch 737/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4245.2455 - acc: 0.0000e+00 - val_loss: 3996.7483 - val_acc: 0.0000e+00\n",
            "Epoch 738/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4651.4628 - acc: 0.0000e+00 - val_loss: 3968.4078 - val_acc: 0.0000e+00\n",
            "Epoch 739/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 3872.6479 - acc: 0.0000e+00 - val_loss: 4014.5285 - val_acc: 0.0000e+00\n",
            "Epoch 740/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3656.0193 - acc: 0.0000e+00 - val_loss: 3978.9162 - val_acc: 0.0000e+00\n",
            "Epoch 741/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4486.9253 - acc: 0.0000e+00 - val_loss: 4096.9178 - val_acc: 0.0000e+00\n",
            "Epoch 742/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 3593.3562 - acc: 0.0000e+00 - val_loss: 4257.9420 - val_acc: 0.0000e+00\n",
            "Epoch 743/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4863.5557 - acc: 0.0000e+00 - val_loss: 4290.0925 - val_acc: 0.0000e+00\n",
            "Epoch 744/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4300.9819 - acc: 0.0000e+00 - val_loss: 4271.3944 - val_acc: 0.0000e+00\n",
            "Epoch 745/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4037.9390 - acc: 0.0000e+00 - val_loss: 4169.4217 - val_acc: 0.0000e+00\n",
            "Epoch 746/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4073.9600 - acc: 0.0000e+00 - val_loss: 4074.7584 - val_acc: 0.0000e+00\n",
            "Epoch 747/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3906.2907 - acc: 0.0000e+00 - val_loss: 4006.8680 - val_acc: 0.0000e+00\n",
            "Epoch 748/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3972.7008 - acc: 0.0000e+00 - val_loss: 3986.6176 - val_acc: 0.0000e+00\n",
            "Epoch 749/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4650.9524 - acc: 0.0000e+00 - val_loss: 3964.3358 - val_acc: 0.0000e+00\n",
            "Epoch 750/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4179.0225 - acc: 0.0000e+00 - val_loss: 3969.3768 - val_acc: 0.0000e+00\n",
            "Epoch 751/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4301.2532 - acc: 0.0000e+00 - val_loss: 3960.6748 - val_acc: 0.0000e+00\n",
            "Epoch 752/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4162.9747 - acc: 0.0000e+00 - val_loss: 3961.6087 - val_acc: 0.0000e+00\n",
            "Epoch 753/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3999.9482 - acc: 0.0000e+00 - val_loss: 4026.5968 - val_acc: 0.0000e+00\n",
            "Epoch 754/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3897.5853 - acc: 0.0000e+00 - val_loss: 4148.5253 - val_acc: 0.0000e+00\n",
            "Epoch 755/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4242.9974 - acc: 0.0000e+00 - val_loss: 4160.3909 - val_acc: 0.0000e+00\n",
            "Epoch 756/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3934.3041 - acc: 0.0000e+00 - val_loss: 4027.1721 - val_acc: 0.0000e+00\n",
            "Epoch 757/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4321.9318 - acc: 0.0000e+00 - val_loss: 4101.7582 - val_acc: 0.0000e+00\n",
            "Epoch 758/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3868.1187 - acc: 0.0000e+00 - val_loss: 4032.5547 - val_acc: 0.0000e+00\n",
            "Epoch 759/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3787.8188 - acc: 0.0000e+00 - val_loss: 4017.3331 - val_acc: 0.0000e+00\n",
            "Epoch 760/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4393.5879 - acc: 0.0000e+00 - val_loss: 3966.6428 - val_acc: 0.0000e+00\n",
            "Epoch 761/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3824.3511 - acc: 0.0000e+00 - val_loss: 4025.9051 - val_acc: 0.0000e+00\n",
            "Epoch 762/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4037.9048 - acc: 0.0000e+00 - val_loss: 4178.5409 - val_acc: 0.0000e+00\n",
            "Epoch 763/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4019.5660 - acc: 0.0000e+00 - val_loss: 4364.9097 - val_acc: 0.0000e+00\n",
            "Epoch 764/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 3979.1760 - acc: 0.0000e+00 - val_loss: 4243.6020 - val_acc: 0.0000e+00\n",
            "Epoch 765/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4365.7625 - acc: 0.0000e+00 - val_loss: 4241.1292 - val_acc: 0.0000e+00\n",
            "Epoch 766/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4202.5231 - acc: 0.0000e+00 - val_loss: 4369.7505 - val_acc: 0.0000e+00\n",
            "Epoch 767/1500\n",
            "348/348 [==============================] - 0s 112us/sample - loss: 3927.9079 - acc: 0.0000e+00 - val_loss: 4337.1963 - val_acc: 0.0000e+00\n",
            "Epoch 768/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3732.1876 - acc: 0.0000e+00 - val_loss: 4303.7911 - val_acc: 0.0000e+00\n",
            "Epoch 769/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4153.9736 - acc: 0.0000e+00 - val_loss: 4218.3225 - val_acc: 0.0000e+00\n",
            "Epoch 770/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3885.7761 - acc: 0.0000e+00 - val_loss: 4183.2335 - val_acc: 0.0000e+00\n",
            "Epoch 771/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4427.0969 - acc: 0.0000e+00 - val_loss: 4170.6204 - val_acc: 0.0000e+00\n",
            "Epoch 772/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4067.9580 - acc: 0.0000e+00 - val_loss: 4082.7341 - val_acc: 0.0000e+00\n",
            "Epoch 773/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3916.5100 - acc: 0.0000e+00 - val_loss: 4032.1253 - val_acc: 0.0000e+00\n",
            "Epoch 774/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4225.7705 - acc: 0.0000e+00 - val_loss: 3981.1600 - val_acc: 0.0000e+00\n",
            "Epoch 775/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4506.1441 - acc: 0.0000e+00 - val_loss: 3984.1819 - val_acc: 0.0000e+00\n",
            "Epoch 776/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4060.8849 - acc: 0.0000e+00 - val_loss: 4006.3508 - val_acc: 0.0000e+00\n",
            "Epoch 777/1500\n",
            "348/348 [==============================] - 0s 109us/sample - loss: 4045.1771 - acc: 0.0000e+00 - val_loss: 4042.6683 - val_acc: 0.0000e+00\n",
            "Epoch 778/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 3950.8514 - acc: 0.0000e+00 - val_loss: 4057.6048 - val_acc: 0.0000e+00\n",
            "Epoch 779/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3622.4822 - acc: 0.0000e+00 - val_loss: 4047.0175 - val_acc: 0.0000e+00\n",
            "Epoch 780/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4389.2456 - acc: 0.0000e+00 - val_loss: 4080.3458 - val_acc: 0.0000e+00\n",
            "Epoch 781/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4305.4903 - acc: 0.0000e+00 - val_loss: 4038.7329 - val_acc: 0.0000e+00\n",
            "Epoch 782/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4057.5257 - acc: 0.0000e+00 - val_loss: 4009.1916 - val_acc: 0.0000e+00\n",
            "Epoch 783/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4218.9115 - acc: 0.0000e+00 - val_loss: 4002.2936 - val_acc: 0.0000e+00\n",
            "Epoch 784/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3909.4932 - acc: 0.0000e+00 - val_loss: 3991.5344 - val_acc: 0.0000e+00\n",
            "Epoch 785/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3809.9601 - acc: 0.0000e+00 - val_loss: 3970.8015 - val_acc: 0.0000e+00\n",
            "Epoch 786/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4806.0206 - acc: 0.0000e+00 - val_loss: 3949.1072 - val_acc: 0.0000e+00\n",
            "Epoch 787/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4054.0144 - acc: 0.0000e+00 - val_loss: 3948.6199 - val_acc: 0.0000e+00\n",
            "Epoch 788/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4092.7476 - acc: 0.0000e+00 - val_loss: 3964.8011 - val_acc: 0.0000e+00\n",
            "Epoch 789/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3932.2839 - acc: 0.0000e+00 - val_loss: 3998.1850 - val_acc: 0.0000e+00\n",
            "Epoch 790/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 4024.0073 - acc: 0.0000e+00 - val_loss: 4016.2512 - val_acc: 0.0000e+00\n",
            "Epoch 791/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4100.3905 - acc: 0.0000e+00 - val_loss: 4015.5931 - val_acc: 0.0000e+00\n",
            "Epoch 792/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4366.7181 - acc: 0.0000e+00 - val_loss: 3972.4817 - val_acc: 0.0000e+00\n",
            "Epoch 793/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 3918.7748 - acc: 0.0000e+00 - val_loss: 3984.5402 - val_acc: 0.0000e+00\n",
            "Epoch 794/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3717.4193 - acc: 0.0000e+00 - val_loss: 4082.2092 - val_acc: 0.0000e+00\n",
            "Epoch 795/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3710.5987 - acc: 0.0000e+00 - val_loss: 4136.6395 - val_acc: 0.0000e+00\n",
            "Epoch 796/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4081.0809 - acc: 0.0000e+00 - val_loss: 4043.4220 - val_acc: 0.0000e+00\n",
            "Epoch 797/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4033.0239 - acc: 0.0000e+00 - val_loss: 4044.9453 - val_acc: 0.0000e+00\n",
            "Epoch 798/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3765.2238 - acc: 0.0000e+00 - val_loss: 4010.2317 - val_acc: 0.0000e+00\n",
            "Epoch 799/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3944.9057 - acc: 0.0000e+00 - val_loss: 3948.2117 - val_acc: 0.0000e+00\n",
            "Epoch 800/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 3618.5827 - acc: 0.0000e+00 - val_loss: 3961.2812 - val_acc: 0.0000e+00\n",
            "Epoch 801/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4162.7362 - acc: 0.0000e+00 - val_loss: 3950.5052 - val_acc: 0.0000e+00\n",
            "Epoch 802/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4170.0590 - acc: 0.0000e+00 - val_loss: 3959.5585 - val_acc: 0.0000e+00\n",
            "Epoch 803/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4532.3921 - acc: 0.0000e+00 - val_loss: 3967.0657 - val_acc: 0.0000e+00\n",
            "Epoch 804/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3875.3479 - acc: 0.0000e+00 - val_loss: 3965.3649 - val_acc: 0.0000e+00\n",
            "Epoch 805/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4367.9513 - acc: 0.0000e+00 - val_loss: 3980.9232 - val_acc: 0.0000e+00\n",
            "Epoch 806/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 3683.7284 - acc: 0.0000e+00 - val_loss: 3982.1038 - val_acc: 0.0000e+00\n",
            "Epoch 807/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 3758.0411 - acc: 0.0000e+00 - val_loss: 3983.2321 - val_acc: 0.0000e+00\n",
            "Epoch 808/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3942.4985 - acc: 0.0000e+00 - val_loss: 3983.0734 - val_acc: 0.0000e+00\n",
            "Epoch 809/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4363.3884 - acc: 0.0000e+00 - val_loss: 3973.4221 - val_acc: 0.0000e+00\n",
            "Epoch 810/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4204.0519 - acc: 0.0000e+00 - val_loss: 3953.1468 - val_acc: 0.0000e+00\n",
            "Epoch 811/1500\n",
            "348/348 [==============================] - 0s 116us/sample - loss: 3769.2291 - acc: 0.0000e+00 - val_loss: 3961.7254 - val_acc: 0.0000e+00\n",
            "Epoch 812/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3980.6450 - acc: 0.0000e+00 - val_loss: 3970.8890 - val_acc: 0.0000e+00\n",
            "Epoch 813/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4859.7702 - acc: 0.0000e+00 - val_loss: 3944.9430 - val_acc: 0.0000e+00\n",
            "Epoch 814/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4644.3657 - acc: 0.0000e+00 - val_loss: 3942.8663 - val_acc: 0.0000e+00\n",
            "Epoch 815/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4069.1532 - acc: 0.0000e+00 - val_loss: 3980.7011 - val_acc: 0.0000e+00\n",
            "Epoch 816/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4706.4776 - acc: 0.0000e+00 - val_loss: 3988.1233 - val_acc: 0.0000e+00\n",
            "Epoch 817/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4225.4387 - acc: 0.0000e+00 - val_loss: 3976.3951 - val_acc: 0.0000e+00\n",
            "Epoch 818/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4159.6036 - acc: 0.0000e+00 - val_loss: 3999.9341 - val_acc: 0.0000e+00\n",
            "Epoch 819/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3591.1590 - acc: 0.0000e+00 - val_loss: 4047.3101 - val_acc: 0.0000e+00\n",
            "Epoch 820/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4503.2730 - acc: 0.0000e+00 - val_loss: 4140.7098 - val_acc: 0.0000e+00\n",
            "Epoch 821/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3865.5503 - acc: 0.0000e+00 - val_loss: 4144.0807 - val_acc: 0.0000e+00\n",
            "Epoch 822/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3991.3070 - acc: 0.0000e+00 - val_loss: 4126.9573 - val_acc: 0.0000e+00\n",
            "Epoch 823/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3907.4940 - acc: 0.0000e+00 - val_loss: 4077.7791 - val_acc: 0.0000e+00\n",
            "Epoch 824/1500\n",
            "348/348 [==============================] - 0s 112us/sample - loss: 3818.1581 - acc: 0.0000e+00 - val_loss: 4085.3815 - val_acc: 0.0000e+00\n",
            "Epoch 825/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3924.0907 - acc: 0.0000e+00 - val_loss: 4089.8922 - val_acc: 0.0000e+00\n",
            "Epoch 826/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3845.0818 - acc: 0.0000e+00 - val_loss: 4055.3582 - val_acc: 0.0000e+00\n",
            "Epoch 827/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3556.3980 - acc: 0.0000e+00 - val_loss: 3979.4719 - val_acc: 0.0000e+00\n",
            "Epoch 828/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3705.1267 - acc: 0.0000e+00 - val_loss: 3955.5499 - val_acc: 0.0000e+00\n",
            "Epoch 829/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3535.2159 - acc: 0.0000e+00 - val_loss: 3953.1102 - val_acc: 0.0000e+00\n",
            "Epoch 830/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4579.4439 - acc: 0.0000e+00 - val_loss: 3973.1040 - val_acc: 0.0000e+00\n",
            "Epoch 831/1500\n",
            "348/348 [==============================] - 0s 83us/sample - loss: 4155.7967 - acc: 0.0000e+00 - val_loss: 4049.3102 - val_acc: 0.0000e+00\n",
            "Epoch 832/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3638.2927 - acc: 0.0000e+00 - val_loss: 4025.7165 - val_acc: 0.0000e+00\n",
            "Epoch 833/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 3519.2685 - acc: 0.0000e+00 - val_loss: 3939.2226 - val_acc: 0.0000e+00\n",
            "Epoch 834/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3479.7731 - acc: 0.0000e+00 - val_loss: 3945.9496 - val_acc: 0.0000e+00\n",
            "Epoch 835/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4096.7239 - acc: 0.0000e+00 - val_loss: 3969.2133 - val_acc: 0.0000e+00\n",
            "Epoch 836/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4096.6045 - acc: 0.0000e+00 - val_loss: 3944.7302 - val_acc: 0.0000e+00\n",
            "Epoch 837/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3841.7280 - acc: 0.0000e+00 - val_loss: 3937.7141 - val_acc: 0.0000e+00\n",
            "Epoch 838/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4200.2767 - acc: 0.0000e+00 - val_loss: 3963.6503 - val_acc: 0.0000e+00\n",
            "Epoch 839/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3930.4500 - acc: 0.0000e+00 - val_loss: 3987.3609 - val_acc: 0.0000e+00\n",
            "Epoch 840/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3934.0857 - acc: 0.0000e+00 - val_loss: 3978.5911 - val_acc: 0.0000e+00\n",
            "Epoch 841/1500\n",
            "348/348 [==============================] - 0s 116us/sample - loss: 3944.9676 - acc: 0.0000e+00 - val_loss: 3935.6069 - val_acc: 0.0000e+00\n",
            "Epoch 842/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3823.1599 - acc: 0.0000e+00 - val_loss: 3944.6536 - val_acc: 0.0000e+00\n",
            "Epoch 843/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4373.0369 - acc: 0.0000e+00 - val_loss: 3938.9406 - val_acc: 0.0000e+00\n",
            "Epoch 844/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4438.5050 - acc: 0.0000e+00 - val_loss: 3933.8689 - val_acc: 0.0000e+00\n",
            "Epoch 845/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3685.0745 - acc: 0.0000e+00 - val_loss: 3932.6906 - val_acc: 0.0000e+00\n",
            "Epoch 846/1500\n",
            "348/348 [==============================] - 0s 118us/sample - loss: 4010.0233 - acc: 0.0000e+00 - val_loss: 3937.4701 - val_acc: 0.0000e+00\n",
            "Epoch 847/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3743.3967 - acc: 0.0000e+00 - val_loss: 3932.1209 - val_acc: 0.0000e+00\n",
            "Epoch 848/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4567.6046 - acc: 0.0000e+00 - val_loss: 3956.7568 - val_acc: 0.0000e+00\n",
            "Epoch 849/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4070.0607 - acc: 0.0000e+00 - val_loss: 3979.0677 - val_acc: 0.0000e+00\n",
            "Epoch 850/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4016.0195 - acc: 0.0000e+00 - val_loss: 4005.5085 - val_acc: 0.0000e+00\n",
            "Epoch 851/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3824.9929 - acc: 0.0000e+00 - val_loss: 4008.4851 - val_acc: 0.0000e+00\n",
            "Epoch 852/1500\n",
            "348/348 [==============================] - 0s 113us/sample - loss: 4152.9761 - acc: 0.0000e+00 - val_loss: 4019.1995 - val_acc: 0.0000e+00\n",
            "Epoch 853/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4116.3891 - acc: 0.0000e+00 - val_loss: 3993.7880 - val_acc: 0.0000e+00\n",
            "Epoch 854/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 3859.0520 - acc: 0.0000e+00 - val_loss: 3981.5574 - val_acc: 0.0000e+00\n",
            "Epoch 855/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3719.3090 - acc: 0.0000e+00 - val_loss: 3981.3319 - val_acc: 0.0000e+00\n",
            "Epoch 856/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 4316.1043 - acc: 0.0000e+00 - val_loss: 3956.8090 - val_acc: 0.0000e+00\n",
            "Epoch 857/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3613.6392 - acc: 0.0000e+00 - val_loss: 3965.5267 - val_acc: 0.0000e+00\n",
            "Epoch 858/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 4591.7428 - acc: 0.0000e+00 - val_loss: 4022.3996 - val_acc: 0.0000e+00\n",
            "Epoch 859/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3978.1033 - acc: 0.0000e+00 - val_loss: 3987.7887 - val_acc: 0.0000e+00\n",
            "Epoch 860/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4112.2706 - acc: 0.0000e+00 - val_loss: 3968.3409 - val_acc: 0.0000e+00\n",
            "Epoch 861/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 3713.7108 - acc: 0.0000e+00 - val_loss: 3957.8870 - val_acc: 0.0000e+00\n",
            "Epoch 862/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4118.3690 - acc: 0.0000e+00 - val_loss: 3951.7775 - val_acc: 0.0000e+00\n",
            "Epoch 863/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4178.1097 - acc: 0.0000e+00 - val_loss: 3935.2841 - val_acc: 0.0000e+00\n",
            "Epoch 864/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4031.2038 - acc: 0.0000e+00 - val_loss: 3932.5435 - val_acc: 0.0000e+00\n",
            "Epoch 865/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4520.1685 - acc: 0.0000e+00 - val_loss: 3933.1377 - val_acc: 0.0000e+00\n",
            "Epoch 866/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 4035.4434 - acc: 0.0000e+00 - val_loss: 3944.3464 - val_acc: 0.0000e+00\n",
            "Epoch 867/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3848.3426 - acc: 0.0000e+00 - val_loss: 3951.9285 - val_acc: 0.0000e+00\n",
            "Epoch 868/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 3798.7975 - acc: 0.0000e+00 - val_loss: 3976.6130 - val_acc: 0.0000e+00\n",
            "Epoch 869/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3538.9761 - acc: 0.0000e+00 - val_loss: 4020.9780 - val_acc: 0.0000e+00\n",
            "Epoch 870/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3756.8268 - acc: 0.0000e+00 - val_loss: 3993.4307 - val_acc: 0.0000e+00\n",
            "Epoch 871/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4057.9841 - acc: 0.0000e+00 - val_loss: 3968.7310 - val_acc: 0.0000e+00\n",
            "Epoch 872/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 3893.2150 - acc: 0.0000e+00 - val_loss: 3947.5220 - val_acc: 0.0000e+00\n",
            "Epoch 873/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3742.0262 - acc: 0.0000e+00 - val_loss: 3945.2837 - val_acc: 0.0000e+00\n",
            "Epoch 874/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4777.6271 - acc: 0.0000e+00 - val_loss: 3939.6805 - val_acc: 0.0000e+00\n",
            "Epoch 875/1500\n",
            "348/348 [==============================] - 0s 82us/sample - loss: 4278.4152 - acc: 0.0000e+00 - val_loss: 3943.7035 - val_acc: 0.0000e+00\n",
            "Epoch 876/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4285.3514 - acc: 0.0000e+00 - val_loss: 3941.6368 - val_acc: 0.0000e+00\n",
            "Epoch 877/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3936.9304 - acc: 0.0000e+00 - val_loss: 3950.0241 - val_acc: 0.0000e+00\n",
            "Epoch 878/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3906.0229 - acc: 0.0000e+00 - val_loss: 4005.3144 - val_acc: 0.0000e+00\n",
            "Epoch 879/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3553.6266 - acc: 0.0000e+00 - val_loss: 4018.6840 - val_acc: 0.0000e+00\n",
            "Epoch 880/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3782.9963 - acc: 0.0000e+00 - val_loss: 4071.3455 - val_acc: 0.0000e+00\n",
            "Epoch 881/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4061.5968 - acc: 0.0000e+00 - val_loss: 4043.3381 - val_acc: 0.0000e+00\n",
            "Epoch 882/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4209.1175 - acc: 0.0000e+00 - val_loss: 4026.8755 - val_acc: 0.0000e+00\n",
            "Epoch 883/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3994.2822 - acc: 0.0000e+00 - val_loss: 3999.8756 - val_acc: 0.0000e+00\n",
            "Epoch 884/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4156.9150 - acc: 0.0000e+00 - val_loss: 3976.8785 - val_acc: 0.0000e+00\n",
            "Epoch 885/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4153.1876 - acc: 0.0000e+00 - val_loss: 3999.1543 - val_acc: 0.0000e+00\n",
            "Epoch 886/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 3757.0880 - acc: 0.0000e+00 - val_loss: 3989.1074 - val_acc: 0.0000e+00\n",
            "Epoch 887/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3780.6297 - acc: 0.0000e+00 - val_loss: 3986.7206 - val_acc: 0.0000e+00\n",
            "Epoch 888/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4183.0555 - acc: 0.0000e+00 - val_loss: 3988.7089 - val_acc: 0.0000e+00\n",
            "Epoch 889/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4580.8970 - acc: 0.0000e+00 - val_loss: 4053.0405 - val_acc: 0.0000e+00\n",
            "Epoch 890/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3670.1694 - acc: 0.0000e+00 - val_loss: 4065.0109 - val_acc: 0.0000e+00\n",
            "Epoch 891/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4007.1652 - acc: 0.0000e+00 - val_loss: 4022.8381 - val_acc: 0.0000e+00\n",
            "Epoch 892/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4031.5496 - acc: 0.0000e+00 - val_loss: 4023.3642 - val_acc: 0.0000e+00\n",
            "Epoch 893/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3673.6712 - acc: 0.0000e+00 - val_loss: 4034.2087 - val_acc: 0.0000e+00\n",
            "Epoch 894/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3810.6101 - acc: 0.0000e+00 - val_loss: 4030.2361 - val_acc: 0.0000e+00\n",
            "Epoch 895/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3916.2179 - acc: 0.0000e+00 - val_loss: 4032.7592 - val_acc: 0.0000e+00\n",
            "Epoch 896/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 3954.5934 - acc: 0.0000e+00 - val_loss: 3987.0438 - val_acc: 0.0000e+00\n",
            "Epoch 897/1500\n",
            "348/348 [==============================] - 0s 83us/sample - loss: 4361.5852 - acc: 0.0000e+00 - val_loss: 3955.7831 - val_acc: 0.0000e+00\n",
            "Epoch 898/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3884.4230 - acc: 0.0000e+00 - val_loss: 3953.6158 - val_acc: 0.0000e+00\n",
            "Epoch 899/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3612.1516 - acc: 0.0000e+00 - val_loss: 3953.8368 - val_acc: 0.0000e+00\n",
            "Epoch 900/1500\n",
            "348/348 [==============================] - 0s 84us/sample - loss: 3904.5497 - acc: 0.0000e+00 - val_loss: 3946.7231 - val_acc: 0.0000e+00\n",
            "Epoch 901/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 4854.5429 - acc: 0.0000e+00 - val_loss: 3932.7992 - val_acc: 0.0000e+00\n",
            "Epoch 902/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3982.3192 - acc: 0.0000e+00 - val_loss: 3928.5975 - val_acc: 0.0000e+00\n",
            "Epoch 903/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3857.5067 - acc: 0.0000e+00 - val_loss: 3932.0932 - val_acc: 0.0000e+00\n",
            "Epoch 904/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3895.5835 - acc: 0.0000e+00 - val_loss: 3927.1109 - val_acc: 0.0000e+00\n",
            "Epoch 905/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 3912.3600 - acc: 0.0000e+00 - val_loss: 3925.4883 - val_acc: 0.0000e+00\n",
            "Epoch 906/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4670.3425 - acc: 0.0000e+00 - val_loss: 3922.5993 - val_acc: 0.0000e+00\n",
            "Epoch 907/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3655.9954 - acc: 0.0000e+00 - val_loss: 3920.9711 - val_acc: 0.0000e+00\n",
            "Epoch 908/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3938.4868 - acc: 0.0000e+00 - val_loss: 3923.5880 - val_acc: 0.0000e+00\n",
            "Epoch 909/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4368.2131 - acc: 0.0000e+00 - val_loss: 3921.8951 - val_acc: 0.0000e+00\n",
            "Epoch 910/1500\n",
            "348/348 [==============================] - 0s 83us/sample - loss: 4284.9928 - acc: 0.0000e+00 - val_loss: 3918.8136 - val_acc: 0.0000e+00\n",
            "Epoch 911/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4234.6283 - acc: 0.0000e+00 - val_loss: 3917.6612 - val_acc: 0.0000e+00\n",
            "Epoch 912/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 3792.2934 - acc: 0.0000e+00 - val_loss: 3918.3080 - val_acc: 0.0000e+00\n",
            "Epoch 913/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4138.8045 - acc: 0.0000e+00 - val_loss: 3920.3723 - val_acc: 0.0000e+00\n",
            "Epoch 914/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4497.8168 - acc: 0.0000e+00 - val_loss: 3925.0169 - val_acc: 0.0000e+00\n",
            "Epoch 915/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 4054.1625 - acc: 0.0000e+00 - val_loss: 3924.2548 - val_acc: 0.0000e+00\n",
            "Epoch 916/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4037.8233 - acc: 0.0000e+00 - val_loss: 3929.2896 - val_acc: 0.0000e+00\n",
            "Epoch 917/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 5057.7964 - acc: 0.0000e+00 - val_loss: 3920.0915 - val_acc: 0.0000e+00\n",
            "Epoch 918/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3781.6671 - acc: 0.0000e+00 - val_loss: 3914.7611 - val_acc: 0.0000e+00\n",
            "Epoch 919/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 3561.7565 - acc: 0.0000e+00 - val_loss: 3916.2950 - val_acc: 0.0000e+00\n",
            "Epoch 920/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3566.1530 - acc: 0.0000e+00 - val_loss: 3921.9186 - val_acc: 0.0000e+00\n",
            "Epoch 921/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4191.9032 - acc: 0.0000e+00 - val_loss: 3919.5413 - val_acc: 0.0000e+00\n",
            "Epoch 922/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3930.7459 - acc: 0.0000e+00 - val_loss: 3917.1760 - val_acc: 0.0000e+00\n",
            "Epoch 923/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3880.9927 - acc: 0.0000e+00 - val_loss: 3927.0478 - val_acc: 0.0000e+00\n",
            "Epoch 924/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 4167.5097 - acc: 0.0000e+00 - val_loss: 3921.3888 - val_acc: 0.0000e+00\n",
            "Epoch 925/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3606.6565 - acc: 0.0000e+00 - val_loss: 3923.5850 - val_acc: 0.0000e+00\n",
            "Epoch 926/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4475.0762 - acc: 0.0000e+00 - val_loss: 3916.9998 - val_acc: 0.0000e+00\n",
            "Epoch 927/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4266.3846 - acc: 0.0000e+00 - val_loss: 3923.9855 - val_acc: 0.0000e+00\n",
            "Epoch 928/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 3598.8451 - acc: 0.0000e+00 - val_loss: 3917.4313 - val_acc: 0.0000e+00\n",
            "Epoch 929/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3960.6361 - acc: 0.0000e+00 - val_loss: 3918.3058 - val_acc: 0.0000e+00\n",
            "Epoch 930/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 3562.9017 - acc: 0.0000e+00 - val_loss: 3916.6383 - val_acc: 0.0000e+00\n",
            "Epoch 931/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3821.1031 - acc: 0.0000e+00 - val_loss: 3917.3098 - val_acc: 0.0000e+00\n",
            "Epoch 932/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 5022.3705 - acc: 0.0000e+00 - val_loss: 3927.6933 - val_acc: 0.0000e+00\n",
            "Epoch 933/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3927.7621 - acc: 0.0000e+00 - val_loss: 3938.5313 - val_acc: 0.0000e+00\n",
            "Epoch 934/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3789.1795 - acc: 0.0000e+00 - val_loss: 3953.2753 - val_acc: 0.0000e+00\n",
            "Epoch 935/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 3717.7587 - acc: 0.0000e+00 - val_loss: 3969.9659 - val_acc: 0.0000e+00\n",
            "Epoch 936/1500\n",
            "348/348 [==============================] - 0s 117us/sample - loss: 3622.7560 - acc: 0.0000e+00 - val_loss: 3949.6580 - val_acc: 0.0000e+00\n",
            "Epoch 937/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4014.4078 - acc: 0.0000e+00 - val_loss: 3938.9007 - val_acc: 0.0000e+00\n",
            "Epoch 938/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3447.5845 - acc: 0.0000e+00 - val_loss: 3937.1572 - val_acc: 0.0000e+00\n",
            "Epoch 939/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 4469.1892 - acc: 0.0000e+00 - val_loss: 3936.9153 - val_acc: 0.0000e+00\n",
            "Epoch 940/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4771.0750 - acc: 0.0000e+00 - val_loss: 3929.1780 - val_acc: 0.0000e+00\n",
            "Epoch 941/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 4427.5524 - acc: 0.0000e+00 - val_loss: 3920.4791 - val_acc: 0.0000e+00\n",
            "Epoch 942/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4112.7317 - acc: 0.0000e+00 - val_loss: 3923.6523 - val_acc: 0.0000e+00\n",
            "Epoch 943/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3669.6649 - acc: 0.0000e+00 - val_loss: 3917.6230 - val_acc: 0.0000e+00\n",
            "Epoch 944/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4104.7137 - acc: 0.0000e+00 - val_loss: 3917.7289 - val_acc: 0.0000e+00\n",
            "Epoch 945/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 3832.8718 - acc: 0.0000e+00 - val_loss: 3925.0593 - val_acc: 0.0000e+00\n",
            "Epoch 946/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3805.3245 - acc: 0.0000e+00 - val_loss: 3926.3827 - val_acc: 0.0000e+00\n",
            "Epoch 947/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3894.1286 - acc: 0.0000e+00 - val_loss: 3933.2952 - val_acc: 0.0000e+00\n",
            "Epoch 948/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4008.5609 - acc: 0.0000e+00 - val_loss: 3933.6002 - val_acc: 0.0000e+00\n",
            "Epoch 949/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3749.9736 - acc: 0.0000e+00 - val_loss: 3929.8828 - val_acc: 0.0000e+00\n",
            "Epoch 950/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 3802.5977 - acc: 0.0000e+00 - val_loss: 3920.3958 - val_acc: 0.0000e+00\n",
            "Epoch 951/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4719.5510 - acc: 0.0000e+00 - val_loss: 3915.9014 - val_acc: 0.0000e+00\n",
            "Epoch 952/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4485.3222 - acc: 0.0000e+00 - val_loss: 3914.7628 - val_acc: 0.0000e+00\n",
            "Epoch 953/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3762.9962 - acc: 0.0000e+00 - val_loss: 3915.4174 - val_acc: 0.0000e+00\n",
            "Epoch 954/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3866.7550 - acc: 0.0000e+00 - val_loss: 3914.4492 - val_acc: 0.0000e+00\n",
            "Epoch 955/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4094.7712 - acc: 0.0000e+00 - val_loss: 3922.1239 - val_acc: 0.0000e+00\n",
            "Epoch 956/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4100.3659 - acc: 0.0000e+00 - val_loss: 3914.9572 - val_acc: 0.0000e+00\n",
            "Epoch 957/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 5213.8183 - acc: 0.0000e+00 - val_loss: 3910.3192 - val_acc: 0.0000e+00\n",
            "Epoch 958/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3881.6471 - acc: 0.0000e+00 - val_loss: 3912.7067 - val_acc: 0.0000e+00\n",
            "Epoch 959/1500\n",
            "348/348 [==============================] - 0s 110us/sample - loss: 3840.2877 - acc: 0.0000e+00 - val_loss: 3911.5859 - val_acc: 0.0000e+00\n",
            "Epoch 960/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4010.5359 - acc: 0.0000e+00 - val_loss: 3913.7329 - val_acc: 0.0000e+00\n",
            "Epoch 961/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 3748.3170 - acc: 0.0000e+00 - val_loss: 3917.4563 - val_acc: 0.0000e+00\n",
            "Epoch 962/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 4683.5903 - acc: 0.0000e+00 - val_loss: 3922.1416 - val_acc: 0.0000e+00\n",
            "Epoch 963/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3655.0203 - acc: 0.0000e+00 - val_loss: 3920.7077 - val_acc: 0.0000e+00\n",
            "Epoch 964/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3646.5810 - acc: 0.0000e+00 - val_loss: 3918.8475 - val_acc: 0.0000e+00\n",
            "Epoch 965/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3392.0777 - acc: 0.0000e+00 - val_loss: 3921.4628 - val_acc: 0.0000e+00\n",
            "Epoch 966/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 3528.4847 - acc: 0.0000e+00 - val_loss: 3919.0700 - val_acc: 0.0000e+00\n",
            "Epoch 967/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3701.6232 - acc: 0.0000e+00 - val_loss: 3921.7797 - val_acc: 0.0000e+00\n",
            "Epoch 968/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4423.9623 - acc: 0.0000e+00 - val_loss: 3920.0254 - val_acc: 0.0000e+00\n",
            "Epoch 969/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3676.1889 - acc: 0.0000e+00 - val_loss: 3919.4706 - val_acc: 0.0000e+00\n",
            "Epoch 970/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 3795.8876 - acc: 0.0000e+00 - val_loss: 3920.7284 - val_acc: 0.0000e+00\n",
            "Epoch 971/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4735.7779 - acc: 0.0000e+00 - val_loss: 3918.3571 - val_acc: 0.0000e+00\n",
            "Epoch 972/1500\n",
            "348/348 [==============================] - 0s 119us/sample - loss: 3618.2903 - acc: 0.0000e+00 - val_loss: 3918.1509 - val_acc: 0.0000e+00\n",
            "Epoch 973/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 4132.4955 - acc: 0.0000e+00 - val_loss: 3912.8081 - val_acc: 0.0000e+00\n",
            "Epoch 974/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3841.6132 - acc: 0.0000e+00 - val_loss: 3912.1768 - val_acc: 0.0000e+00\n",
            "Epoch 975/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 3933.3028 - acc: 0.0000e+00 - val_loss: 3912.3079 - val_acc: 0.0000e+00\n",
            "Epoch 976/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 4209.7771 - acc: 0.0000e+00 - val_loss: 3917.5299 - val_acc: 0.0000e+00\n",
            "Epoch 977/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4177.9214 - acc: 0.0000e+00 - val_loss: 3924.3091 - val_acc: 0.0000e+00\n",
            "Epoch 978/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 3934.3969 - acc: 0.0000e+00 - val_loss: 3929.9669 - val_acc: 0.0000e+00\n",
            "Epoch 979/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3899.3893 - acc: 0.0000e+00 - val_loss: 3943.8372 - val_acc: 0.0000e+00\n",
            "Epoch 980/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4732.0679 - acc: 0.0000e+00 - val_loss: 3973.8448 - val_acc: 0.0000e+00\n",
            "Epoch 981/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 4115.6774 - acc: 0.0000e+00 - val_loss: 3948.2100 - val_acc: 0.0000e+00\n",
            "Epoch 982/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4224.6287 - acc: 0.0000e+00 - val_loss: 3942.8578 - val_acc: 0.0000e+00\n",
            "Epoch 983/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4095.2097 - acc: 0.0000e+00 - val_loss: 3942.0448 - val_acc: 0.0000e+00\n",
            "Epoch 984/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3874.5191 - acc: 0.0000e+00 - val_loss: 3952.4148 - val_acc: 0.0000e+00\n",
            "Epoch 985/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3884.9414 - acc: 0.0000e+00 - val_loss: 3981.8476 - val_acc: 0.0000e+00\n",
            "Epoch 986/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4572.0489 - acc: 0.0000e+00 - val_loss: 3953.0957 - val_acc: 0.0000e+00\n",
            "Epoch 987/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 4462.5604 - acc: 0.0000e+00 - val_loss: 3945.1401 - val_acc: 0.0000e+00\n",
            "Epoch 988/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3577.5056 - acc: 0.0000e+00 - val_loss: 3953.7935 - val_acc: 0.0000e+00\n",
            "Epoch 989/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4016.1725 - acc: 0.0000e+00 - val_loss: 3955.8987 - val_acc: 0.0000e+00\n",
            "Epoch 990/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3850.9999 - acc: 0.0000e+00 - val_loss: 3955.7705 - val_acc: 0.0000e+00\n",
            "Epoch 991/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 3925.4518 - acc: 0.0000e+00 - val_loss: 3942.9633 - val_acc: 0.0000e+00\n",
            "Epoch 992/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4134.3888 - acc: 0.0000e+00 - val_loss: 3935.3208 - val_acc: 0.0000e+00\n",
            "Epoch 993/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3570.9362 - acc: 0.0000e+00 - val_loss: 3923.4721 - val_acc: 0.0000e+00\n",
            "Epoch 994/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 3669.6738 - acc: 0.0000e+00 - val_loss: 3918.9729 - val_acc: 0.0000e+00\n",
            "Epoch 995/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3997.1949 - acc: 0.0000e+00 - val_loss: 3912.7421 - val_acc: 0.0000e+00\n",
            "Epoch 996/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3584.3481 - acc: 0.0000e+00 - val_loss: 3912.7372 - val_acc: 0.0000e+00\n",
            "Epoch 997/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3535.2649 - acc: 0.0000e+00 - val_loss: 3912.0386 - val_acc: 0.0000e+00\n",
            "Epoch 998/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3719.7178 - acc: 0.0000e+00 - val_loss: 3910.2646 - val_acc: 0.0000e+00\n",
            "Epoch 999/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4059.9007 - acc: 0.0000e+00 - val_loss: 3912.2371 - val_acc: 0.0000e+00\n",
            "Epoch 1000/1500\n",
            "348/348 [==============================] - 0s 110us/sample - loss: 4517.5510 - acc: 0.0000e+00 - val_loss: 3917.7461 - val_acc: 0.0000e+00\n",
            "Epoch 1001/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3708.3087 - acc: 0.0000e+00 - val_loss: 3906.9567 - val_acc: 0.0000e+00\n",
            "Epoch 1002/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4414.0224 - acc: 0.0000e+00 - val_loss: 3905.5788 - val_acc: 0.0000e+00\n",
            "Epoch 1003/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3769.8292 - acc: 0.0000e+00 - val_loss: 3905.8142 - val_acc: 0.0000e+00\n",
            "Epoch 1004/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3690.0242 - acc: 0.0000e+00 - val_loss: 3908.5351 - val_acc: 0.0000e+00\n",
            "Epoch 1005/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 4174.3056 - acc: 0.0000e+00 - val_loss: 3905.2448 - val_acc: 0.0000e+00\n",
            "Epoch 1006/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4591.8615 - acc: 0.0000e+00 - val_loss: 3907.2067 - val_acc: 0.0000e+00\n",
            "Epoch 1007/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4139.2913 - acc: 0.0000e+00 - val_loss: 3906.5292 - val_acc: 0.0000e+00\n",
            "Epoch 1008/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3414.5324 - acc: 0.0000e+00 - val_loss: 3906.5983 - val_acc: 0.0000e+00\n",
            "Epoch 1009/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4150.1132 - acc: 0.0000e+00 - val_loss: 3906.3567 - val_acc: 0.0000e+00\n",
            "Epoch 1010/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4871.7124 - acc: 0.0000e+00 - val_loss: 3910.6880 - val_acc: 0.0000e+00\n",
            "Epoch 1011/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4140.8305 - acc: 0.0000e+00 - val_loss: 3907.5106 - val_acc: 0.0000e+00\n",
            "Epoch 1012/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4414.9518 - acc: 0.0000e+00 - val_loss: 3905.1161 - val_acc: 0.0000e+00\n",
            "Epoch 1013/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 3691.4678 - acc: 0.0000e+00 - val_loss: 3904.8566 - val_acc: 0.0000e+00\n",
            "Epoch 1014/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3970.0131 - acc: 0.0000e+00 - val_loss: 3909.0344 - val_acc: 0.0000e+00\n",
            "Epoch 1015/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4246.4317 - acc: 0.0000e+00 - val_loss: 3917.5804 - val_acc: 0.0000e+00\n",
            "Epoch 1016/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3953.6792 - acc: 0.0000e+00 - val_loss: 3926.7278 - val_acc: 0.0000e+00\n",
            "Epoch 1017/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4179.8560 - acc: 0.0000e+00 - val_loss: 3932.6524 - val_acc: 0.0000e+00\n",
            "Epoch 1018/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4292.2112 - acc: 0.0000e+00 - val_loss: 3932.5543 - val_acc: 0.0000e+00\n",
            "Epoch 1019/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3496.7272 - acc: 0.0000e+00 - val_loss: 3932.9930 - val_acc: 0.0000e+00\n",
            "Epoch 1020/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 3786.2247 - acc: 0.0000e+00 - val_loss: 3954.2527 - val_acc: 0.0000e+00\n",
            "Epoch 1021/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 4031.4759 - acc: 0.0000e+00 - val_loss: 3945.2672 - val_acc: 0.0000e+00\n",
            "Epoch 1022/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4866.3508 - acc: 0.0000e+00 - val_loss: 3933.3943 - val_acc: 0.0000e+00\n",
            "Epoch 1023/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 3964.5755 - acc: 0.0000e+00 - val_loss: 3940.7238 - val_acc: 0.0000e+00\n",
            "Epoch 1024/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 4362.3865 - acc: 0.0000e+00 - val_loss: 3936.6833 - val_acc: 0.0000e+00\n",
            "Epoch 1025/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3607.0402 - acc: 0.0000e+00 - val_loss: 3940.1251 - val_acc: 0.0000e+00\n",
            "Epoch 1026/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4040.1075 - acc: 0.0000e+00 - val_loss: 3934.0986 - val_acc: 0.0000e+00\n",
            "Epoch 1027/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3599.9453 - acc: 0.0000e+00 - val_loss: 3931.7068 - val_acc: 0.0000e+00\n",
            "Epoch 1028/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4068.3844 - acc: 0.0000e+00 - val_loss: 3923.0429 - val_acc: 0.0000e+00\n",
            "Epoch 1029/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3514.1039 - acc: 0.0000e+00 - val_loss: 3926.2816 - val_acc: 0.0000e+00\n",
            "Epoch 1030/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3709.3598 - acc: 0.0000e+00 - val_loss: 3918.0949 - val_acc: 0.0000e+00\n",
            "Epoch 1031/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 3666.0331 - acc: 0.0000e+00 - val_loss: 3913.9366 - val_acc: 0.0000e+00\n",
            "Epoch 1032/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3640.7449 - acc: 0.0000e+00 - val_loss: 3914.8071 - val_acc: 0.0000e+00\n",
            "Epoch 1033/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4322.6008 - acc: 0.0000e+00 - val_loss: 3909.8536 - val_acc: 0.0000e+00\n",
            "Epoch 1034/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 3685.9008 - acc: 0.0000e+00 - val_loss: 3907.3823 - val_acc: 0.0000e+00\n",
            "Epoch 1035/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4088.3652 - acc: 0.0000e+00 - val_loss: 3912.2265 - val_acc: 0.0000e+00\n",
            "Epoch 1036/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4341.1975 - acc: 0.0000e+00 - val_loss: 3907.9178 - val_acc: 0.0000e+00\n",
            "Epoch 1037/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 3997.7709 - acc: 0.0000e+00 - val_loss: 3903.9743 - val_acc: 0.0000e+00\n",
            "Epoch 1038/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4372.0496 - acc: 0.0000e+00 - val_loss: 3903.7679 - val_acc: 0.0000e+00\n",
            "Epoch 1039/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 3919.7306 - acc: 0.0000e+00 - val_loss: 3902.3440 - val_acc: 0.0000e+00\n",
            "Epoch 1040/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3559.1488 - acc: 0.0000e+00 - val_loss: 3904.9746 - val_acc: 0.0000e+00\n",
            "Epoch 1041/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3521.9425 - acc: 0.0000e+00 - val_loss: 3906.7281 - val_acc: 0.0000e+00\n",
            "Epoch 1042/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 3760.8340 - acc: 0.0000e+00 - val_loss: 3905.3435 - val_acc: 0.0000e+00\n",
            "Epoch 1043/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3993.6072 - acc: 0.0000e+00 - val_loss: 3904.5916 - val_acc: 0.0000e+00\n",
            "Epoch 1044/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3871.0058 - acc: 0.0000e+00 - val_loss: 3904.7531 - val_acc: 0.0000e+00\n",
            "Epoch 1045/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3905.3379 - acc: 0.0000e+00 - val_loss: 3907.9882 - val_acc: 0.0000e+00\n",
            "Epoch 1046/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 3998.9996 - acc: 0.0000e+00 - val_loss: 3905.8074 - val_acc: 0.0000e+00\n",
            "Epoch 1047/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4064.0160 - acc: 0.0000e+00 - val_loss: 3903.8707 - val_acc: 0.0000e+00\n",
            "Epoch 1048/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3894.0462 - acc: 0.0000e+00 - val_loss: 3906.7825 - val_acc: 0.0000e+00\n",
            "Epoch 1049/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 3843.4611 - acc: 0.0000e+00 - val_loss: 3900.8841 - val_acc: 0.0000e+00\n",
            "Epoch 1050/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4219.4534 - acc: 0.0000e+00 - val_loss: 3900.8965 - val_acc: 0.0000e+00\n",
            "Epoch 1051/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3701.1945 - acc: 0.0000e+00 - val_loss: 3901.0696 - val_acc: 0.0000e+00\n",
            "Epoch 1052/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 3827.4107 - acc: 0.0000e+00 - val_loss: 3901.7508 - val_acc: 0.0000e+00\n",
            "Epoch 1053/1500\n",
            "348/348 [==============================] - 0s 109us/sample - loss: 3703.9059 - acc: 0.0000e+00 - val_loss: 3903.4345 - val_acc: 0.0000e+00\n",
            "Epoch 1054/1500\n",
            "348/348 [==============================] - 0s 109us/sample - loss: 4755.6773 - acc: 0.0000e+00 - val_loss: 3902.9744 - val_acc: 0.0000e+00\n",
            "Epoch 1055/1500\n",
            "348/348 [==============================] - 0s 111us/sample - loss: 4440.4009 - acc: 0.0000e+00 - val_loss: 3900.9828 - val_acc: 0.0000e+00\n",
            "Epoch 1056/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 3920.2043 - acc: 0.0000e+00 - val_loss: 3900.8413 - val_acc: 0.0000e+00\n",
            "Epoch 1057/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4177.0511 - acc: 0.0000e+00 - val_loss: 3900.5385 - val_acc: 0.0000e+00\n",
            "Epoch 1058/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4245.6115 - acc: 0.0000e+00 - val_loss: 3900.0776 - val_acc: 0.0000e+00\n",
            "Epoch 1059/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4409.0359 - acc: 0.0000e+00 - val_loss: 3902.2351 - val_acc: 0.0000e+00\n",
            "Epoch 1060/1500\n",
            "348/348 [==============================] - 0s 111us/sample - loss: 4263.3795 - acc: 0.0000e+00 - val_loss: 3904.6987 - val_acc: 0.0000e+00\n",
            "Epoch 1061/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3841.6727 - acc: 0.0000e+00 - val_loss: 3900.7570 - val_acc: 0.0000e+00\n",
            "Epoch 1062/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3773.9712 - acc: 0.0000e+00 - val_loss: 3903.1120 - val_acc: 0.0000e+00\n",
            "Epoch 1063/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4085.0234 - acc: 0.0000e+00 - val_loss: 3897.8598 - val_acc: 0.0000e+00\n",
            "Epoch 1064/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4200.1905 - acc: 0.0000e+00 - val_loss: 3899.5633 - val_acc: 0.0000e+00\n",
            "Epoch 1065/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 3615.4240 - acc: 0.0000e+00 - val_loss: 3896.4081 - val_acc: 0.0000e+00\n",
            "Epoch 1066/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4155.3888 - acc: 0.0000e+00 - val_loss: 3897.8435 - val_acc: 0.0000e+00\n",
            "Epoch 1067/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3994.1607 - acc: 0.0000e+00 - val_loss: 3898.7142 - val_acc: 0.0000e+00\n",
            "Epoch 1068/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3674.1212 - acc: 0.0000e+00 - val_loss: 3903.8295 - val_acc: 0.0000e+00\n",
            "Epoch 1069/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3861.0789 - acc: 0.0000e+00 - val_loss: 3904.9752 - val_acc: 0.0000e+00\n",
            "Epoch 1070/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4030.3810 - acc: 0.0000e+00 - val_loss: 3898.2009 - val_acc: 0.0000e+00\n",
            "Epoch 1071/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4582.4692 - acc: 0.0000e+00 - val_loss: 3905.1301 - val_acc: 0.0000e+00\n",
            "Epoch 1072/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 3743.3578 - acc: 0.0000e+00 - val_loss: 3902.5852 - val_acc: 0.0000e+00\n",
            "Epoch 1073/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 4132.1205 - acc: 0.0000e+00 - val_loss: 3897.8463 - val_acc: 0.0000e+00\n",
            "Epoch 1074/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 4067.4679 - acc: 0.0000e+00 - val_loss: 3895.4299 - val_acc: 0.0000e+00\n",
            "Epoch 1075/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4239.8024 - acc: 0.0000e+00 - val_loss: 3894.7906 - val_acc: 0.0000e+00\n",
            "Epoch 1076/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3724.0291 - acc: 0.0000e+00 - val_loss: 3894.6508 - val_acc: 0.0000e+00\n",
            "Epoch 1077/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4012.7859 - acc: 0.0000e+00 - val_loss: 3902.4016 - val_acc: 0.0000e+00\n",
            "Epoch 1078/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 3775.3934 - acc: 0.0000e+00 - val_loss: 3902.4009 - val_acc: 0.0000e+00\n",
            "Epoch 1079/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 4551.3194 - acc: 0.0000e+00 - val_loss: 3895.5624 - val_acc: 0.0000e+00\n",
            "Epoch 1080/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4384.7714 - acc: 0.0000e+00 - val_loss: 3898.0493 - val_acc: 0.0000e+00\n",
            "Epoch 1081/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4455.5775 - acc: 0.0000e+00 - val_loss: 3900.4790 - val_acc: 0.0000e+00\n",
            "Epoch 1082/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3878.6183 - acc: 0.0000e+00 - val_loss: 3900.4066 - val_acc: 0.0000e+00\n",
            "Epoch 1083/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4066.4567 - acc: 0.0000e+00 - val_loss: 3897.5056 - val_acc: 0.0000e+00\n",
            "Epoch 1084/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3766.6092 - acc: 0.0000e+00 - val_loss: 3897.0018 - val_acc: 0.0000e+00\n",
            "Epoch 1085/1500\n",
            "348/348 [==============================] - 0s 109us/sample - loss: 4433.5481 - acc: 0.0000e+00 - val_loss: 3896.4312 - val_acc: 0.0000e+00\n",
            "Epoch 1086/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 4331.9494 - acc: 0.0000e+00 - val_loss: 3899.3217 - val_acc: 0.0000e+00\n",
            "Epoch 1087/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4924.3522 - acc: 0.0000e+00 - val_loss: 3895.5900 - val_acc: 0.0000e+00\n",
            "Epoch 1088/1500\n",
            "348/348 [==============================] - 0s 117us/sample - loss: 3570.4113 - acc: 0.0000e+00 - val_loss: 3894.6463 - val_acc: 0.0000e+00\n",
            "Epoch 1089/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4037.3345 - acc: 0.0000e+00 - val_loss: 3896.0945 - val_acc: 0.0000e+00\n",
            "Epoch 1090/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3856.3061 - acc: 0.0000e+00 - val_loss: 3901.0209 - val_acc: 0.0000e+00\n",
            "Epoch 1091/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 4854.1576 - acc: 0.0000e+00 - val_loss: 3901.2365 - val_acc: 0.0000e+00\n",
            "Epoch 1092/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3956.8072 - acc: 0.0000e+00 - val_loss: 3897.3754 - val_acc: 0.0000e+00\n",
            "Epoch 1093/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3868.1557 - acc: 0.0000e+00 - val_loss: 3900.8143 - val_acc: 0.0000e+00\n",
            "Epoch 1094/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3973.7088 - acc: 0.0000e+00 - val_loss: 3897.4986 - val_acc: 0.0000e+00\n",
            "Epoch 1095/1500\n",
            "348/348 [==============================] - 0s 119us/sample - loss: 5097.5598 - acc: 0.0000e+00 - val_loss: 3895.3108 - val_acc: 0.0000e+00\n",
            "Epoch 1096/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4225.7602 - acc: 0.0000e+00 - val_loss: 3896.2384 - val_acc: 0.0000e+00\n",
            "Epoch 1097/1500\n",
            "348/348 [==============================] - 0s 109us/sample - loss: 3574.4390 - acc: 0.0000e+00 - val_loss: 3893.9886 - val_acc: 0.0000e+00\n",
            "Epoch 1098/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 3702.8499 - acc: 0.0000e+00 - val_loss: 3894.9377 - val_acc: 0.0000e+00\n",
            "Epoch 1099/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3925.3571 - acc: 0.0000e+00 - val_loss: 3896.0807 - val_acc: 0.0000e+00\n",
            "Epoch 1100/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3605.4057 - acc: 0.0000e+00 - val_loss: 3895.3545 - val_acc: 0.0000e+00\n",
            "Epoch 1101/1500\n",
            "348/348 [==============================] - 0s 117us/sample - loss: 3626.0323 - acc: 0.0000e+00 - val_loss: 3895.4216 - val_acc: 0.0000e+00\n",
            "Epoch 1102/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3749.3620 - acc: 0.0000e+00 - val_loss: 3896.0478 - val_acc: 0.0000e+00\n",
            "Epoch 1103/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 3774.2554 - acc: 0.0000e+00 - val_loss: 3896.1197 - val_acc: 0.0000e+00\n",
            "Epoch 1104/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4402.2841 - acc: 0.0000e+00 - val_loss: 3896.9381 - val_acc: 0.0000e+00\n",
            "Epoch 1105/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4078.0784 - acc: 0.0000e+00 - val_loss: 3902.2899 - val_acc: 0.0000e+00\n",
            "Epoch 1106/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3880.0035 - acc: 0.0000e+00 - val_loss: 3895.0318 - val_acc: 0.0000e+00\n",
            "Epoch 1107/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 3719.5293 - acc: 0.0000e+00 - val_loss: 3897.2081 - val_acc: 0.0000e+00\n",
            "Epoch 1108/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3644.6587 - acc: 0.0000e+00 - val_loss: 3902.0127 - val_acc: 0.0000e+00\n",
            "Epoch 1109/1500\n",
            "348/348 [==============================] - 0s 113us/sample - loss: 4038.5231 - acc: 0.0000e+00 - val_loss: 3895.9080 - val_acc: 0.0000e+00\n",
            "Epoch 1110/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4480.4842 - acc: 0.0000e+00 - val_loss: 3894.1298 - val_acc: 0.0000e+00\n",
            "Epoch 1111/1500\n",
            "348/348 [==============================] - 0s 112us/sample - loss: 3797.5693 - acc: 0.0000e+00 - val_loss: 3894.8325 - val_acc: 0.0000e+00\n",
            "Epoch 1112/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3647.8495 - acc: 0.0000e+00 - val_loss: 3899.6508 - val_acc: 0.0000e+00\n",
            "Epoch 1113/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3863.2383 - acc: 0.0000e+00 - val_loss: 3898.6833 - val_acc: 0.0000e+00\n",
            "Epoch 1114/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3793.9604 - acc: 0.0000e+00 - val_loss: 3895.3684 - val_acc: 0.0000e+00\n",
            "Epoch 1115/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4159.5449 - acc: 0.0000e+00 - val_loss: 3897.2494 - val_acc: 0.0000e+00\n",
            "Epoch 1116/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 3851.4886 - acc: 0.0000e+00 - val_loss: 3898.6957 - val_acc: 0.0000e+00\n",
            "Epoch 1117/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4372.3377 - acc: 0.0000e+00 - val_loss: 3894.1608 - val_acc: 0.0000e+00\n",
            "Epoch 1118/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3937.8330 - acc: 0.0000e+00 - val_loss: 3893.7687 - val_acc: 0.0000e+00\n",
            "Epoch 1119/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3674.4643 - acc: 0.0000e+00 - val_loss: 3892.0731 - val_acc: 0.0000e+00\n",
            "Epoch 1120/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4437.5757 - acc: 0.0000e+00 - val_loss: 3892.0035 - val_acc: 0.0000e+00\n",
            "Epoch 1121/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3856.4957 - acc: 0.0000e+00 - val_loss: 3891.7144 - val_acc: 0.0000e+00\n",
            "Epoch 1122/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4010.7976 - acc: 0.0000e+00 - val_loss: 3892.8739 - val_acc: 0.0000e+00\n",
            "Epoch 1123/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3994.4312 - acc: 0.0000e+00 - val_loss: 3893.6165 - val_acc: 0.0000e+00\n",
            "Epoch 1124/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3856.1144 - acc: 0.0000e+00 - val_loss: 3896.4417 - val_acc: 0.0000e+00\n",
            "Epoch 1125/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 3495.0194 - acc: 0.0000e+00 - val_loss: 3896.6379 - val_acc: 0.0000e+00\n",
            "Epoch 1126/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3978.7598 - acc: 0.0000e+00 - val_loss: 3898.7540 - val_acc: 0.0000e+00\n",
            "Epoch 1127/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3777.6182 - acc: 0.0000e+00 - val_loss: 3896.5833 - val_acc: 0.0000e+00\n",
            "Epoch 1128/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 4452.2407 - acc: 0.0000e+00 - val_loss: 3900.7133 - val_acc: 0.0000e+00\n",
            "Epoch 1129/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3895.1028 - acc: 0.0000e+00 - val_loss: 3895.6692 - val_acc: 0.0000e+00\n",
            "Epoch 1130/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3351.6265 - acc: 0.0000e+00 - val_loss: 3896.6478 - val_acc: 0.0000e+00\n",
            "Epoch 1131/1500\n",
            "348/348 [==============================] - 0s 110us/sample - loss: 3626.7341 - acc: 0.0000e+00 - val_loss: 3896.0441 - val_acc: 0.0000e+00\n",
            "Epoch 1132/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 3652.8658 - acc: 0.0000e+00 - val_loss: 3893.7899 - val_acc: 0.0000e+00\n",
            "Epoch 1133/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4126.4502 - acc: 0.0000e+00 - val_loss: 3893.4960 - val_acc: 0.0000e+00\n",
            "Epoch 1134/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3421.0347 - acc: 0.0000e+00 - val_loss: 3891.9573 - val_acc: 0.0000e+00\n",
            "Epoch 1135/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3854.2948 - acc: 0.0000e+00 - val_loss: 3894.7462 - val_acc: 0.0000e+00\n",
            "Epoch 1136/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3578.1252 - acc: 0.0000e+00 - val_loss: 3893.3878 - val_acc: 0.0000e+00\n",
            "Epoch 1137/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 3778.1377 - acc: 0.0000e+00 - val_loss: 3892.1093 - val_acc: 0.0000e+00\n",
            "Epoch 1138/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4299.4635 - acc: 0.0000e+00 - val_loss: 3894.3957 - val_acc: 0.0000e+00\n",
            "Epoch 1139/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3742.6428 - acc: 0.0000e+00 - val_loss: 3897.4793 - val_acc: 0.0000e+00\n",
            "Epoch 1140/1500\n",
            "348/348 [==============================] - 0s 116us/sample - loss: 3941.9908 - acc: 0.0000e+00 - val_loss: 3895.3924 - val_acc: 0.0000e+00\n",
            "Epoch 1141/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 3714.4459 - acc: 0.0000e+00 - val_loss: 3891.0347 - val_acc: 0.0000e+00\n",
            "Epoch 1142/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3594.5261 - acc: 0.0000e+00 - val_loss: 3891.8879 - val_acc: 0.0000e+00\n",
            "Epoch 1143/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3750.6645 - acc: 0.0000e+00 - val_loss: 3893.1750 - val_acc: 0.0000e+00\n",
            "Epoch 1144/1500\n",
            "348/348 [==============================] - 0s 125us/sample - loss: 4815.7636 - acc: 0.0000e+00 - val_loss: 3892.5268 - val_acc: 0.0000e+00\n",
            "Epoch 1145/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4229.4229 - acc: 0.0000e+00 - val_loss: 3887.8511 - val_acc: 0.0000e+00\n",
            "Epoch 1146/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 3866.8609 - acc: 0.0000e+00 - val_loss: 3890.0305 - val_acc: 0.0000e+00\n",
            "Epoch 1147/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4010.7627 - acc: 0.0000e+00 - val_loss: 3888.3851 - val_acc: 0.0000e+00\n",
            "Epoch 1148/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4262.5283 - acc: 0.0000e+00 - val_loss: 3890.6410 - val_acc: 0.0000e+00\n",
            "Epoch 1149/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4316.4588 - acc: 0.0000e+00 - val_loss: 3890.8304 - val_acc: 0.0000e+00\n",
            "Epoch 1150/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3865.8798 - acc: 0.0000e+00 - val_loss: 3891.6054 - val_acc: 0.0000e+00\n",
            "Epoch 1151/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 3534.7656 - acc: 0.0000e+00 - val_loss: 3892.9381 - val_acc: 0.0000e+00\n",
            "Epoch 1152/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3711.9848 - acc: 0.0000e+00 - val_loss: 3899.2846 - val_acc: 0.0000e+00\n",
            "Epoch 1153/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4479.9511 - acc: 0.0000e+00 - val_loss: 3892.8628 - val_acc: 0.0000e+00\n",
            "Epoch 1154/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3701.5621 - acc: 0.0000e+00 - val_loss: 3899.6213 - val_acc: 0.0000e+00\n",
            "Epoch 1155/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4284.9973 - acc: 0.0000e+00 - val_loss: 3898.4990 - val_acc: 0.0000e+00\n",
            "Epoch 1156/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3523.9527 - acc: 0.0000e+00 - val_loss: 3899.8093 - val_acc: 0.0000e+00\n",
            "Epoch 1157/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3581.9410 - acc: 0.0000e+00 - val_loss: 3896.4996 - val_acc: 0.0000e+00\n",
            "Epoch 1158/1500\n",
            "348/348 [==============================] - 0s 110us/sample - loss: 3581.2631 - acc: 0.0000e+00 - val_loss: 3892.9192 - val_acc: 0.0000e+00\n",
            "Epoch 1159/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3789.0303 - acc: 0.0000e+00 - val_loss: 3890.9088 - val_acc: 0.0000e+00\n",
            "Epoch 1160/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3992.7728 - acc: 0.0000e+00 - val_loss: 3896.2317 - val_acc: 0.0000e+00\n",
            "Epoch 1161/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4055.6720 - acc: 0.0000e+00 - val_loss: 3889.3597 - val_acc: 0.0000e+00\n",
            "Epoch 1162/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3514.0815 - acc: 0.0000e+00 - val_loss: 3890.7213 - val_acc: 0.0000e+00\n",
            "Epoch 1163/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3767.2606 - acc: 0.0000e+00 - val_loss: 3891.7308 - val_acc: 0.0000e+00\n",
            "Epoch 1164/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4500.6598 - acc: 0.0000e+00 - val_loss: 3896.5982 - val_acc: 0.0000e+00\n",
            "Epoch 1165/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4335.9728 - acc: 0.0000e+00 - val_loss: 3888.7543 - val_acc: 0.0000e+00\n",
            "Epoch 1166/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 4375.5427 - acc: 0.0000e+00 - val_loss: 3886.8700 - val_acc: 0.0000e+00\n",
            "Epoch 1167/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4105.7998 - acc: 0.0000e+00 - val_loss: 3885.1735 - val_acc: 0.0000e+00\n",
            "Epoch 1168/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4124.5488 - acc: 0.0000e+00 - val_loss: 3884.5175 - val_acc: 0.0000e+00\n",
            "Epoch 1169/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3641.7295 - acc: 0.0000e+00 - val_loss: 3887.8648 - val_acc: 0.0000e+00\n",
            "Epoch 1170/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3494.0635 - acc: 0.0000e+00 - val_loss: 3896.8940 - val_acc: 0.0000e+00\n",
            "Epoch 1171/1500\n",
            "348/348 [==============================] - 0s 110us/sample - loss: 3741.5933 - acc: 0.0000e+00 - val_loss: 3901.3756 - val_acc: 0.0000e+00\n",
            "Epoch 1172/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 5142.2436 - acc: 0.0000e+00 - val_loss: 3898.5644 - val_acc: 0.0000e+00\n",
            "Epoch 1173/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4130.1040 - acc: 0.0000e+00 - val_loss: 3887.2607 - val_acc: 0.0000e+00\n",
            "Epoch 1174/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4053.9305 - acc: 0.0000e+00 - val_loss: 3886.3251 - val_acc: 0.0000e+00\n",
            "Epoch 1175/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4100.7057 - acc: 0.0000e+00 - val_loss: 3886.3778 - val_acc: 0.0000e+00\n",
            "Epoch 1176/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4172.6400 - acc: 0.0000e+00 - val_loss: 3890.8455 - val_acc: 0.0000e+00\n",
            "Epoch 1177/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4023.4803 - acc: 0.0000e+00 - val_loss: 3887.2318 - val_acc: 0.0000e+00\n",
            "Epoch 1178/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3775.5601 - acc: 0.0000e+00 - val_loss: 3890.5427 - val_acc: 0.0000e+00\n",
            "Epoch 1179/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4018.1980 - acc: 0.0000e+00 - val_loss: 3894.2607 - val_acc: 0.0000e+00\n",
            "Epoch 1180/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4598.6901 - acc: 0.0000e+00 - val_loss: 3912.0496 - val_acc: 0.0000e+00\n",
            "Epoch 1181/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4044.7633 - acc: 0.0000e+00 - val_loss: 3889.8953 - val_acc: 0.0000e+00\n",
            "Epoch 1182/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3972.9436 - acc: 0.0000e+00 - val_loss: 3885.0359 - val_acc: 0.0000e+00\n",
            "Epoch 1183/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4070.1685 - acc: 0.0000e+00 - val_loss: 3884.1480 - val_acc: 0.0000e+00\n",
            "Epoch 1184/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3903.9750 - acc: 0.0000e+00 - val_loss: 3891.1161 - val_acc: 0.0000e+00\n",
            "Epoch 1185/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4084.5255 - acc: 0.0000e+00 - val_loss: 3888.9326 - val_acc: 0.0000e+00\n",
            "Epoch 1186/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 3826.4574 - acc: 0.0000e+00 - val_loss: 3886.9382 - val_acc: 0.0000e+00\n",
            "Epoch 1187/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 3830.9096 - acc: 0.0000e+00 - val_loss: 3884.9751 - val_acc: 0.0000e+00\n",
            "Epoch 1188/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3947.6182 - acc: 0.0000e+00 - val_loss: 3884.4927 - val_acc: 0.0000e+00\n",
            "Epoch 1189/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3436.2394 - acc: 0.0000e+00 - val_loss: 3891.4397 - val_acc: 0.0000e+00\n",
            "Epoch 1190/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 3720.7456 - acc: 0.0000e+00 - val_loss: 3891.0077 - val_acc: 0.0000e+00\n",
            "Epoch 1191/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 3425.0052 - acc: 0.0000e+00 - val_loss: 3888.3311 - val_acc: 0.0000e+00\n",
            "Epoch 1192/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3703.9660 - acc: 0.0000e+00 - val_loss: 3888.2111 - val_acc: 0.0000e+00\n",
            "Epoch 1193/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 3863.1431 - acc: 0.0000e+00 - val_loss: 3889.1673 - val_acc: 0.0000e+00\n",
            "Epoch 1194/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4079.8271 - acc: 0.0000e+00 - val_loss: 3891.7457 - val_acc: 0.0000e+00\n",
            "Epoch 1195/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3963.4460 - acc: 0.0000e+00 - val_loss: 3896.8012 - val_acc: 0.0000e+00\n",
            "Epoch 1196/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 3818.4705 - acc: 0.0000e+00 - val_loss: 3893.6935 - val_acc: 0.0000e+00\n",
            "Epoch 1197/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4318.6597 - acc: 0.0000e+00 - val_loss: 3896.5222 - val_acc: 0.0000e+00\n",
            "Epoch 1198/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 3965.3107 - acc: 0.0000e+00 - val_loss: 3894.0060 - val_acc: 0.0000e+00\n",
            "Epoch 1199/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4111.8016 - acc: 0.0000e+00 - val_loss: 3893.7800 - val_acc: 0.0000e+00\n",
            "Epoch 1200/1500\n",
            "348/348 [==============================] - 0s 121us/sample - loss: 4091.2402 - acc: 0.0000e+00 - val_loss: 3887.2060 - val_acc: 0.0000e+00\n",
            "Epoch 1201/1500\n",
            "348/348 [==============================] - 0s 112us/sample - loss: 3664.6446 - acc: 0.0000e+00 - val_loss: 3892.5895 - val_acc: 0.0000e+00\n",
            "Epoch 1202/1500\n",
            "348/348 [==============================] - 0s 114us/sample - loss: 4571.8710 - acc: 0.0000e+00 - val_loss: 3885.4976 - val_acc: 0.0000e+00\n",
            "Epoch 1203/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 3381.8948 - acc: 0.0000e+00 - val_loss: 3886.0265 - val_acc: 0.0000e+00\n",
            "Epoch 1204/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3934.8853 - acc: 0.0000e+00 - val_loss: 3890.8943 - val_acc: 0.0000e+00\n",
            "Epoch 1205/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 4900.3628 - acc: 0.0000e+00 - val_loss: 3892.3280 - val_acc: 0.0000e+00\n",
            "Epoch 1206/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3972.3904 - acc: 0.0000e+00 - val_loss: 3888.1095 - val_acc: 0.0000e+00\n",
            "Epoch 1207/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3643.6427 - acc: 0.0000e+00 - val_loss: 3890.1213 - val_acc: 0.0000e+00\n",
            "Epoch 1208/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3585.5497 - acc: 0.0000e+00 - val_loss: 3893.3080 - val_acc: 0.0000e+00\n",
            "Epoch 1209/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3995.6393 - acc: 0.0000e+00 - val_loss: 3894.2668 - val_acc: 0.0000e+00\n",
            "Epoch 1210/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3657.4561 - acc: 0.0000e+00 - val_loss: 3895.7611 - val_acc: 0.0000e+00\n",
            "Epoch 1211/1500\n",
            "348/348 [==============================] - 0s 109us/sample - loss: 3776.3057 - acc: 0.0000e+00 - val_loss: 3900.5663 - val_acc: 0.0000e+00\n",
            "Epoch 1212/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3699.7215 - acc: 0.0000e+00 - val_loss: 3915.2168 - val_acc: 0.0000e+00\n",
            "Epoch 1213/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 3555.5015 - acc: 0.0000e+00 - val_loss: 3905.9348 - val_acc: 0.0000e+00\n",
            "Epoch 1214/1500\n",
            "348/348 [==============================] - 0s 118us/sample - loss: 3988.1373 - acc: 0.0000e+00 - val_loss: 3908.0829 - val_acc: 0.0000e+00\n",
            "Epoch 1215/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3509.7067 - acc: 0.0000e+00 - val_loss: 3904.0540 - val_acc: 0.0000e+00\n",
            "Epoch 1216/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4079.8970 - acc: 0.0000e+00 - val_loss: 3901.6617 - val_acc: 0.0000e+00\n",
            "Epoch 1217/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3837.4688 - acc: 0.0000e+00 - val_loss: 3893.9298 - val_acc: 0.0000e+00\n",
            "Epoch 1218/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3912.0597 - acc: 0.0000e+00 - val_loss: 3890.0314 - val_acc: 0.0000e+00\n",
            "Epoch 1219/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4453.4165 - acc: 0.0000e+00 - val_loss: 3887.5212 - val_acc: 0.0000e+00\n",
            "Epoch 1220/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3909.5975 - acc: 0.0000e+00 - val_loss: 3895.7596 - val_acc: 0.0000e+00\n",
            "Epoch 1221/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 3818.4444 - acc: 0.0000e+00 - val_loss: 3885.3613 - val_acc: 0.0000e+00\n",
            "Epoch 1222/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3833.3722 - acc: 0.0000e+00 - val_loss: 3884.7871 - val_acc: 0.0000e+00\n",
            "Epoch 1223/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3653.5110 - acc: 0.0000e+00 - val_loss: 3884.4526 - val_acc: 0.0000e+00\n",
            "Epoch 1224/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 3838.7671 - acc: 0.0000e+00 - val_loss: 3882.3814 - val_acc: 0.0000e+00\n",
            "Epoch 1225/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3823.1230 - acc: 0.0000e+00 - val_loss: 3882.5548 - val_acc: 0.0000e+00\n",
            "Epoch 1226/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4009.3778 - acc: 0.0000e+00 - val_loss: 3882.2056 - val_acc: 0.0000e+00\n",
            "Epoch 1227/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 3810.2176 - acc: 0.0000e+00 - val_loss: 3884.2495 - val_acc: 0.0000e+00\n",
            "Epoch 1228/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4526.7928 - acc: 0.0000e+00 - val_loss: 3882.0129 - val_acc: 0.0000e+00\n",
            "Epoch 1229/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3460.1114 - acc: 0.0000e+00 - val_loss: 3882.1761 - val_acc: 0.0000e+00\n",
            "Epoch 1230/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3513.5971 - acc: 0.0000e+00 - val_loss: 3882.8629 - val_acc: 0.0000e+00\n",
            "Epoch 1231/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3625.2178 - acc: 0.0000e+00 - val_loss: 3882.9907 - val_acc: 0.0000e+00\n",
            "Epoch 1232/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3948.3095 - acc: 0.0000e+00 - val_loss: 3886.6746 - val_acc: 0.0000e+00\n",
            "Epoch 1233/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3767.1125 - acc: 0.0000e+00 - val_loss: 3883.6777 - val_acc: 0.0000e+00\n",
            "Epoch 1234/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4781.4081 - acc: 0.0000e+00 - val_loss: 3881.1904 - val_acc: 0.0000e+00\n",
            "Epoch 1235/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4352.9416 - acc: 0.0000e+00 - val_loss: 3887.1886 - val_acc: 0.0000e+00\n",
            "Epoch 1236/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4004.3268 - acc: 0.0000e+00 - val_loss: 3881.2234 - val_acc: 0.0000e+00\n",
            "Epoch 1237/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4287.0217 - acc: 0.0000e+00 - val_loss: 3882.0034 - val_acc: 0.0000e+00\n",
            "Epoch 1238/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4598.3896 - acc: 0.0000e+00 - val_loss: 3879.9900 - val_acc: 0.0000e+00\n",
            "Epoch 1239/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4115.1567 - acc: 0.0000e+00 - val_loss: 3889.6552 - val_acc: 0.0000e+00\n",
            "Epoch 1240/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4116.9810 - acc: 0.0000e+00 - val_loss: 3883.6410 - val_acc: 0.0000e+00\n",
            "Epoch 1241/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3644.8437 - acc: 0.0000e+00 - val_loss: 3879.9223 - val_acc: 0.0000e+00\n",
            "Epoch 1242/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3913.5847 - acc: 0.0000e+00 - val_loss: 3882.1796 - val_acc: 0.0000e+00\n",
            "Epoch 1243/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4189.8500 - acc: 0.0000e+00 - val_loss: 3880.8071 - val_acc: 0.0000e+00\n",
            "Epoch 1244/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4162.0968 - acc: 0.0000e+00 - val_loss: 3880.0438 - val_acc: 0.0000e+00\n",
            "Epoch 1245/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 3896.0153 - acc: 0.0000e+00 - val_loss: 3879.6126 - val_acc: 0.0000e+00\n",
            "Epoch 1246/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 3370.5198 - acc: 0.0000e+00 - val_loss: 3883.5912 - val_acc: 0.0000e+00\n",
            "Epoch 1247/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 3972.2262 - acc: 0.0000e+00 - val_loss: 3881.8197 - val_acc: 0.0000e+00\n",
            "Epoch 1248/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 3743.8570 - acc: 0.0000e+00 - val_loss: 3885.1224 - val_acc: 0.0000e+00\n",
            "Epoch 1249/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4063.1042 - acc: 0.0000e+00 - val_loss: 3881.7885 - val_acc: 0.0000e+00\n",
            "Epoch 1250/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3965.6778 - acc: 0.0000e+00 - val_loss: 3888.9942 - val_acc: 0.0000e+00\n",
            "Epoch 1251/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 3970.0849 - acc: 0.0000e+00 - val_loss: 3882.4297 - val_acc: 0.0000e+00\n",
            "Epoch 1252/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4304.8541 - acc: 0.0000e+00 - val_loss: 3882.7821 - val_acc: 0.0000e+00\n",
            "Epoch 1253/1500\n",
            "348/348 [==============================] - 0s 115us/sample - loss: 4147.6968 - acc: 0.0000e+00 - val_loss: 3894.4811 - val_acc: 0.0000e+00\n",
            "Epoch 1254/1500\n",
            "348/348 [==============================] - 0s 109us/sample - loss: 4564.9280 - acc: 0.0000e+00 - val_loss: 3884.2676 - val_acc: 0.0000e+00\n",
            "Epoch 1255/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4240.8119 - acc: 0.0000e+00 - val_loss: 3890.1378 - val_acc: 0.0000e+00\n",
            "Epoch 1256/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3724.0502 - acc: 0.0000e+00 - val_loss: 3888.8616 - val_acc: 0.0000e+00\n",
            "Epoch 1257/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3640.7116 - acc: 0.0000e+00 - val_loss: 3890.1552 - val_acc: 0.0000e+00\n",
            "Epoch 1258/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3984.1830 - acc: 0.0000e+00 - val_loss: 3885.5710 - val_acc: 0.0000e+00\n",
            "Epoch 1259/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4085.3451 - acc: 0.0000e+00 - val_loss: 3887.5716 - val_acc: 0.0000e+00\n",
            "Epoch 1260/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 4083.0729 - acc: 0.0000e+00 - val_loss: 3884.0597 - val_acc: 0.0000e+00\n",
            "Epoch 1261/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4015.5242 - acc: 0.0000e+00 - val_loss: 3884.7376 - val_acc: 0.0000e+00\n",
            "Epoch 1262/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3876.3186 - acc: 0.0000e+00 - val_loss: 3886.7117 - val_acc: 0.0000e+00\n",
            "Epoch 1263/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4678.2400 - acc: 0.0000e+00 - val_loss: 3885.2418 - val_acc: 0.0000e+00\n",
            "Epoch 1264/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 4195.0842 - acc: 0.0000e+00 - val_loss: 3892.2484 - val_acc: 0.0000e+00\n",
            "Epoch 1265/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4534.8541 - acc: 0.0000e+00 - val_loss: 3887.8775 - val_acc: 0.0000e+00\n",
            "Epoch 1266/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 4002.8024 - acc: 0.0000e+00 - val_loss: 3894.2055 - val_acc: 0.0000e+00\n",
            "Epoch 1267/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 4003.5530 - acc: 0.0000e+00 - val_loss: 3894.9383 - val_acc: 0.0000e+00\n",
            "Epoch 1268/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3723.8394 - acc: 0.0000e+00 - val_loss: 3893.2761 - val_acc: 0.0000e+00\n",
            "Epoch 1269/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4203.0391 - acc: 0.0000e+00 - val_loss: 3888.0004 - val_acc: 0.0000e+00\n",
            "Epoch 1270/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 3795.2868 - acc: 0.0000e+00 - val_loss: 3886.5232 - val_acc: 0.0000e+00\n",
            "Epoch 1271/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3676.0059 - acc: 0.0000e+00 - val_loss: 3888.1615 - val_acc: 0.0000e+00\n",
            "Epoch 1272/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 4079.6969 - acc: 0.0000e+00 - val_loss: 3884.3445 - val_acc: 0.0000e+00\n",
            "Epoch 1273/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4392.9633 - acc: 0.0000e+00 - val_loss: 3881.8430 - val_acc: 0.0000e+00\n",
            "Epoch 1274/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4078.6033 - acc: 0.0000e+00 - val_loss: 3883.1055 - val_acc: 0.0000e+00\n",
            "Epoch 1275/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 3580.3155 - acc: 0.0000e+00 - val_loss: 3881.7487 - val_acc: 0.0000e+00\n",
            "Epoch 1276/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 3571.0401 - acc: 0.0000e+00 - val_loss: 3880.9626 - val_acc: 0.0000e+00\n",
            "Epoch 1277/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4077.6895 - acc: 0.0000e+00 - val_loss: 3879.5956 - val_acc: 0.0000e+00\n",
            "Epoch 1278/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3744.4748 - acc: 0.0000e+00 - val_loss: 3880.6413 - val_acc: 0.0000e+00\n",
            "Epoch 1279/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3612.9027 - acc: 0.0000e+00 - val_loss: 3882.1180 - val_acc: 0.0000e+00\n",
            "Epoch 1280/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3676.9332 - acc: 0.0000e+00 - val_loss: 3881.2549 - val_acc: 0.0000e+00\n",
            "Epoch 1281/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3855.7763 - acc: 0.0000e+00 - val_loss: 3884.3406 - val_acc: 0.0000e+00\n",
            "Epoch 1282/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 4291.1219 - acc: 0.0000e+00 - val_loss: 3882.9638 - val_acc: 0.0000e+00\n",
            "Epoch 1283/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3383.7620 - acc: 0.0000e+00 - val_loss: 3882.4708 - val_acc: 0.0000e+00\n",
            "Epoch 1284/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 4136.1355 - acc: 0.0000e+00 - val_loss: 3883.1500 - val_acc: 0.0000e+00\n",
            "Epoch 1285/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4409.8288 - acc: 0.0000e+00 - val_loss: 3879.1426 - val_acc: 0.0000e+00\n",
            "Epoch 1286/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3644.0447 - acc: 0.0000e+00 - val_loss: 3881.0018 - val_acc: 0.0000e+00\n",
            "Epoch 1287/1500\n",
            "348/348 [==============================] - 0s 113us/sample - loss: 3995.8065 - acc: 0.0000e+00 - val_loss: 3880.5169 - val_acc: 0.0000e+00\n",
            "Epoch 1288/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4068.1759 - acc: 0.0000e+00 - val_loss: 3880.9471 - val_acc: 0.0000e+00\n",
            "Epoch 1289/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3677.9520 - acc: 0.0000e+00 - val_loss: 3880.4198 - val_acc: 0.0000e+00\n",
            "Epoch 1290/1500\n",
            "348/348 [==============================] - 0s 114us/sample - loss: 4021.3168 - acc: 0.0000e+00 - val_loss: 3881.3618 - val_acc: 0.0000e+00\n",
            "Epoch 1291/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 3683.0688 - acc: 0.0000e+00 - val_loss: 3883.0657 - val_acc: 0.0000e+00\n",
            "Epoch 1292/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 3467.9673 - acc: 0.0000e+00 - val_loss: 3882.1417 - val_acc: 0.0000e+00\n",
            "Epoch 1293/1500\n",
            "348/348 [==============================] - 0s 113us/sample - loss: 4187.5496 - acc: 0.0000e+00 - val_loss: 3882.4664 - val_acc: 0.0000e+00\n",
            "Epoch 1294/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4237.4400 - acc: 0.0000e+00 - val_loss: 3883.9280 - val_acc: 0.0000e+00\n",
            "Epoch 1295/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4053.5286 - acc: 0.0000e+00 - val_loss: 3881.8770 - val_acc: 0.0000e+00\n",
            "Epoch 1296/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4144.7464 - acc: 0.0000e+00 - val_loss: 3881.7618 - val_acc: 0.0000e+00\n",
            "Epoch 1297/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3977.7666 - acc: 0.0000e+00 - val_loss: 3882.7146 - val_acc: 0.0000e+00\n",
            "Epoch 1298/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4230.2563 - acc: 0.0000e+00 - val_loss: 3884.0480 - val_acc: 0.0000e+00\n",
            "Epoch 1299/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 3590.0001 - acc: 0.0000e+00 - val_loss: 3886.0179 - val_acc: 0.0000e+00\n",
            "Epoch 1300/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4048.1667 - acc: 0.0000e+00 - val_loss: 3884.5647 - val_acc: 0.0000e+00\n",
            "Epoch 1301/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4062.8496 - acc: 0.0000e+00 - val_loss: 3883.2008 - val_acc: 0.0000e+00\n",
            "Epoch 1302/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3863.5254 - acc: 0.0000e+00 - val_loss: 3887.2321 - val_acc: 0.0000e+00\n",
            "Epoch 1303/1500\n",
            "348/348 [==============================] - 0s 107us/sample - loss: 3898.7372 - acc: 0.0000e+00 - val_loss: 3883.6651 - val_acc: 0.0000e+00\n",
            "Epoch 1304/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3873.5970 - acc: 0.0000e+00 - val_loss: 3883.8302 - val_acc: 0.0000e+00\n",
            "Epoch 1305/1500\n",
            "348/348 [==============================] - 0s 106us/sample - loss: 3338.7514 - acc: 0.0000e+00 - val_loss: 3880.8536 - val_acc: 0.0000e+00\n",
            "Epoch 1306/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4056.0454 - acc: 0.0000e+00 - val_loss: 3879.9433 - val_acc: 0.0000e+00\n",
            "Epoch 1307/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3899.5794 - acc: 0.0000e+00 - val_loss: 3881.0601 - val_acc: 0.0000e+00\n",
            "Epoch 1308/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3573.0741 - acc: 0.0000e+00 - val_loss: 3884.5613 - val_acc: 0.0000e+00\n",
            "Epoch 1309/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3977.2552 - acc: 0.0000e+00 - val_loss: 3878.2507 - val_acc: 0.0000e+00\n",
            "Epoch 1310/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4463.4877 - acc: 0.0000e+00 - val_loss: 3884.1599 - val_acc: 0.0000e+00\n",
            "Epoch 1311/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 4604.2525 - acc: 0.0000e+00 - val_loss: 3878.5196 - val_acc: 0.0000e+00\n",
            "Epoch 1312/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4796.8952 - acc: 0.0000e+00 - val_loss: 3879.4636 - val_acc: 0.0000e+00\n",
            "Epoch 1313/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4110.8260 - acc: 0.0000e+00 - val_loss: 3882.0421 - val_acc: 0.0000e+00\n",
            "Epoch 1314/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3348.7007 - acc: 0.0000e+00 - val_loss: 3885.2230 - val_acc: 0.0000e+00\n",
            "Epoch 1315/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3799.5205 - acc: 0.0000e+00 - val_loss: 3882.1690 - val_acc: 0.0000e+00\n",
            "Epoch 1316/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3870.9311 - acc: 0.0000e+00 - val_loss: 3881.4414 - val_acc: 0.0000e+00\n",
            "Epoch 1317/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3722.4997 - acc: 0.0000e+00 - val_loss: 3881.6227 - val_acc: 0.0000e+00\n",
            "Epoch 1318/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3811.1793 - acc: 0.0000e+00 - val_loss: 3879.9832 - val_acc: 0.0000e+00\n",
            "Epoch 1319/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3839.9338 - acc: 0.0000e+00 - val_loss: 3879.8585 - val_acc: 0.0000e+00\n",
            "Epoch 1320/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3952.8320 - acc: 0.0000e+00 - val_loss: 3880.2162 - val_acc: 0.0000e+00\n",
            "Epoch 1321/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3595.0762 - acc: 0.0000e+00 - val_loss: 3882.8538 - val_acc: 0.0000e+00\n",
            "Epoch 1322/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3944.5924 - acc: 0.0000e+00 - val_loss: 3883.1687 - val_acc: 0.0000e+00\n",
            "Epoch 1323/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4006.4120 - acc: 0.0000e+00 - val_loss: 3879.6319 - val_acc: 0.0000e+00\n",
            "Epoch 1324/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3913.8674 - acc: 0.0000e+00 - val_loss: 3877.7766 - val_acc: 0.0000e+00\n",
            "Epoch 1325/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3608.8710 - acc: 0.0000e+00 - val_loss: 3879.0624 - val_acc: 0.0000e+00\n",
            "Epoch 1326/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 3882.0574 - acc: 0.0000e+00 - val_loss: 3880.7932 - val_acc: 0.0000e+00\n",
            "Epoch 1327/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4089.2896 - acc: 0.0000e+00 - val_loss: 3884.7666 - val_acc: 0.0000e+00\n",
            "Epoch 1328/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4535.4290 - acc: 0.0000e+00 - val_loss: 3891.6490 - val_acc: 0.0000e+00\n",
            "Epoch 1329/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3580.8760 - acc: 0.0000e+00 - val_loss: 3882.8847 - val_acc: 0.0000e+00\n",
            "Epoch 1330/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3613.8112 - acc: 0.0000e+00 - val_loss: 3880.6424 - val_acc: 0.0000e+00\n",
            "Epoch 1331/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4379.4565 - acc: 0.0000e+00 - val_loss: 3883.0027 - val_acc: 0.0000e+00\n",
            "Epoch 1332/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4072.7364 - acc: 0.0000e+00 - val_loss: 3883.4008 - val_acc: 0.0000e+00\n",
            "Epoch 1333/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3792.4573 - acc: 0.0000e+00 - val_loss: 3885.8316 - val_acc: 0.0000e+00\n",
            "Epoch 1334/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3862.6519 - acc: 0.0000e+00 - val_loss: 3883.4217 - val_acc: 0.0000e+00\n",
            "Epoch 1335/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4892.0817 - acc: 0.0000e+00 - val_loss: 3885.1562 - val_acc: 0.0000e+00\n",
            "Epoch 1336/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4302.8206 - acc: 0.0000e+00 - val_loss: 3885.5714 - val_acc: 0.0000e+00\n",
            "Epoch 1337/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3851.8038 - acc: 0.0000e+00 - val_loss: 3884.0810 - val_acc: 0.0000e+00\n",
            "Epoch 1338/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3642.6373 - acc: 0.0000e+00 - val_loss: 3882.5555 - val_acc: 0.0000e+00\n",
            "Epoch 1339/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3694.8536 - acc: 0.0000e+00 - val_loss: 3882.8381 - val_acc: 0.0000e+00\n",
            "Epoch 1340/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4102.0635 - acc: 0.0000e+00 - val_loss: 3881.1328 - val_acc: 0.0000e+00\n",
            "Epoch 1341/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3681.9092 - acc: 0.0000e+00 - val_loss: 3880.0031 - val_acc: 0.0000e+00\n",
            "Epoch 1342/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 4641.8914 - acc: 0.0000e+00 - val_loss: 3879.1234 - val_acc: 0.0000e+00\n",
            "Epoch 1343/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3791.1055 - acc: 0.0000e+00 - val_loss: 3876.8615 - val_acc: 0.0000e+00\n",
            "Epoch 1344/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4097.6142 - acc: 0.0000e+00 - val_loss: 3881.9980 - val_acc: 0.0000e+00\n",
            "Epoch 1345/1500\n",
            "348/348 [==============================] - 0s 111us/sample - loss: 4301.5758 - acc: 0.0000e+00 - val_loss: 3878.6842 - val_acc: 0.0000e+00\n",
            "Epoch 1346/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3878.1860 - acc: 0.0000e+00 - val_loss: 3880.0780 - val_acc: 0.0000e+00\n",
            "Epoch 1347/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3756.9612 - acc: 0.0000e+00 - val_loss: 3878.1718 - val_acc: 0.0000e+00\n",
            "Epoch 1348/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4138.1451 - acc: 0.0000e+00 - val_loss: 3877.7620 - val_acc: 0.0000e+00\n",
            "Epoch 1349/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 3906.5158 - acc: 0.0000e+00 - val_loss: 3876.5998 - val_acc: 0.0000e+00\n",
            "Epoch 1350/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4382.5780 - acc: 0.0000e+00 - val_loss: 3875.9338 - val_acc: 0.0000e+00\n",
            "Epoch 1351/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3924.2878 - acc: 0.0000e+00 - val_loss: 3875.2308 - val_acc: 0.0000e+00\n",
            "Epoch 1352/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 4895.6207 - acc: 0.0000e+00 - val_loss: 3881.9102 - val_acc: 0.0000e+00\n",
            "Epoch 1353/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4199.4956 - acc: 0.0000e+00 - val_loss: 3876.3220 - val_acc: 0.0000e+00\n",
            "Epoch 1354/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3600.5067 - acc: 0.0000e+00 - val_loss: 3879.1121 - val_acc: 0.0000e+00\n",
            "Epoch 1355/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3749.0909 - acc: 0.0000e+00 - val_loss: 3878.2865 - val_acc: 0.0000e+00\n",
            "Epoch 1356/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3581.3480 - acc: 0.0000e+00 - val_loss: 3877.4727 - val_acc: 0.0000e+00\n",
            "Epoch 1357/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 3735.4280 - acc: 0.0000e+00 - val_loss: 3879.2059 - val_acc: 0.0000e+00\n",
            "Epoch 1358/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3753.1212 - acc: 0.0000e+00 - val_loss: 3881.8838 - val_acc: 0.0000e+00\n",
            "Epoch 1359/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 4006.5575 - acc: 0.0000e+00 - val_loss: 3880.1837 - val_acc: 0.0000e+00\n",
            "Epoch 1360/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3902.5833 - acc: 0.0000e+00 - val_loss: 3883.1156 - val_acc: 0.0000e+00\n",
            "Epoch 1361/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3471.1497 - acc: 0.0000e+00 - val_loss: 3879.3673 - val_acc: 0.0000e+00\n",
            "Epoch 1362/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3878.7685 - acc: 0.0000e+00 - val_loss: 3882.0036 - val_acc: 0.0000e+00\n",
            "Epoch 1363/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3822.9169 - acc: 0.0000e+00 - val_loss: 3879.5900 - val_acc: 0.0000e+00\n",
            "Epoch 1364/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3796.8995 - acc: 0.0000e+00 - val_loss: 3881.1876 - val_acc: 0.0000e+00\n",
            "Epoch 1365/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4322.5180 - acc: 0.0000e+00 - val_loss: 3878.6056 - val_acc: 0.0000e+00\n",
            "Epoch 1366/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4143.4111 - acc: 0.0000e+00 - val_loss: 3884.0461 - val_acc: 0.0000e+00\n",
            "Epoch 1367/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3683.4303 - acc: 0.0000e+00 - val_loss: 3879.9667 - val_acc: 0.0000e+00\n",
            "Epoch 1368/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4144.9777 - acc: 0.0000e+00 - val_loss: 3881.3130 - val_acc: 0.0000e+00\n",
            "Epoch 1369/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 3945.3571 - acc: 0.0000e+00 - val_loss: 3884.1528 - val_acc: 0.0000e+00\n",
            "Epoch 1370/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4238.2019 - acc: 0.0000e+00 - val_loss: 3879.2721 - val_acc: 0.0000e+00\n",
            "Epoch 1371/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3755.9945 - acc: 0.0000e+00 - val_loss: 3878.1142 - val_acc: 0.0000e+00\n",
            "Epoch 1372/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3649.2688 - acc: 0.0000e+00 - val_loss: 3877.9305 - val_acc: 0.0000e+00\n",
            "Epoch 1373/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4304.0383 - acc: 0.0000e+00 - val_loss: 3877.1763 - val_acc: 0.0000e+00\n",
            "Epoch 1374/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4055.6642 - acc: 0.0000e+00 - val_loss: 3879.4889 - val_acc: 0.0000e+00\n",
            "Epoch 1375/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3596.6323 - acc: 0.0000e+00 - val_loss: 3878.0544 - val_acc: 0.0000e+00\n",
            "Epoch 1376/1500\n",
            "348/348 [==============================] - 0s 109us/sample - loss: 4436.8594 - acc: 0.0000e+00 - val_loss: 3878.1300 - val_acc: 0.0000e+00\n",
            "Epoch 1377/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4072.7769 - acc: 0.0000e+00 - val_loss: 3876.6613 - val_acc: 0.0000e+00\n",
            "Epoch 1378/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3870.2765 - acc: 0.0000e+00 - val_loss: 3880.8205 - val_acc: 0.0000e+00\n",
            "Epoch 1379/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3986.8623 - acc: 0.0000e+00 - val_loss: 3880.6095 - val_acc: 0.0000e+00\n",
            "Epoch 1380/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3788.9723 - acc: 0.0000e+00 - val_loss: 3880.4724 - val_acc: 0.0000e+00\n",
            "Epoch 1381/1500\n",
            "348/348 [==============================] - 0s 110us/sample - loss: 5180.0628 - acc: 0.0000e+00 - val_loss: 3881.8417 - val_acc: 0.0000e+00\n",
            "Epoch 1382/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4593.3573 - acc: 0.0000e+00 - val_loss: 3878.6384 - val_acc: 0.0000e+00\n",
            "Epoch 1383/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 3825.1261 - acc: 0.0000e+00 - val_loss: 3874.0354 - val_acc: 0.0000e+00\n",
            "Epoch 1384/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 3672.6772 - acc: 0.0000e+00 - val_loss: 3877.8017 - val_acc: 0.0000e+00\n",
            "Epoch 1385/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4334.4220 - acc: 0.0000e+00 - val_loss: 3874.8067 - val_acc: 0.0000e+00\n",
            "Epoch 1386/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3606.2128 - acc: 0.0000e+00 - val_loss: 3875.4831 - val_acc: 0.0000e+00\n",
            "Epoch 1387/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 3672.8527 - acc: 0.0000e+00 - val_loss: 3878.1433 - val_acc: 0.0000e+00\n",
            "Epoch 1388/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3540.1732 - acc: 0.0000e+00 - val_loss: 3875.0783 - val_acc: 0.0000e+00\n",
            "Epoch 1389/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3842.5367 - acc: 0.0000e+00 - val_loss: 3877.9714 - val_acc: 0.0000e+00\n",
            "Epoch 1390/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4377.9164 - acc: 0.0000e+00 - val_loss: 3876.4643 - val_acc: 0.0000e+00\n",
            "Epoch 1391/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 3679.4939 - acc: 0.0000e+00 - val_loss: 3880.9872 - val_acc: 0.0000e+00\n",
            "Epoch 1392/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 3670.8957 - acc: 0.0000e+00 - val_loss: 3877.6003 - val_acc: 0.0000e+00\n",
            "Epoch 1393/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3586.2992 - acc: 0.0000e+00 - val_loss: 3880.2646 - val_acc: 0.0000e+00\n",
            "Epoch 1394/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3757.3065 - acc: 0.0000e+00 - val_loss: 3882.3055 - val_acc: 0.0000e+00\n",
            "Epoch 1395/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3919.3927 - acc: 0.0000e+00 - val_loss: 3877.3927 - val_acc: 0.0000e+00\n",
            "Epoch 1396/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3721.3176 - acc: 0.0000e+00 - val_loss: 3876.7648 - val_acc: 0.0000e+00\n",
            "Epoch 1397/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 3623.1508 - acc: 0.0000e+00 - val_loss: 3876.5331 - val_acc: 0.0000e+00\n",
            "Epoch 1398/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 3940.8691 - acc: 0.0000e+00 - val_loss: 3878.0366 - val_acc: 0.0000e+00\n",
            "Epoch 1399/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3592.0474 - acc: 0.0000e+00 - val_loss: 3878.1210 - val_acc: 0.0000e+00\n",
            "Epoch 1400/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3454.9752 - acc: 0.0000e+00 - val_loss: 3876.0076 - val_acc: 0.0000e+00\n",
            "Epoch 1401/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 4012.3999 - acc: 0.0000e+00 - val_loss: 3878.4449 - val_acc: 0.0000e+00\n",
            "Epoch 1402/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3956.2866 - acc: 0.0000e+00 - val_loss: 3886.4920 - val_acc: 0.0000e+00\n",
            "Epoch 1403/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4394.8412 - acc: 0.0000e+00 - val_loss: 3883.9603 - val_acc: 0.0000e+00\n",
            "Epoch 1404/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4128.4783 - acc: 0.0000e+00 - val_loss: 3875.1636 - val_acc: 0.0000e+00\n",
            "Epoch 1405/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3859.8872 - acc: 0.0000e+00 - val_loss: 3875.8641 - val_acc: 0.0000e+00\n",
            "Epoch 1406/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3484.5972 - acc: 0.0000e+00 - val_loss: 3879.6678 - val_acc: 0.0000e+00\n",
            "Epoch 1407/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3756.1005 - acc: 0.0000e+00 - val_loss: 3878.3605 - val_acc: 0.0000e+00\n",
            "Epoch 1408/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4050.2736 - acc: 0.0000e+00 - val_loss: 3880.7848 - val_acc: 0.0000e+00\n",
            "Epoch 1409/1500\n",
            "348/348 [==============================] - 0s 104us/sample - loss: 4452.8452 - acc: 0.0000e+00 - val_loss: 3879.9569 - val_acc: 0.0000e+00\n",
            "Epoch 1410/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4150.5582 - acc: 0.0000e+00 - val_loss: 3877.1831 - val_acc: 0.0000e+00\n",
            "Epoch 1411/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 4138.6054 - acc: 0.0000e+00 - val_loss: 3875.9432 - val_acc: 0.0000e+00\n",
            "Epoch 1412/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4353.4060 - acc: 0.0000e+00 - val_loss: 3880.8580 - val_acc: 0.0000e+00\n",
            "Epoch 1413/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3865.6013 - acc: 0.0000e+00 - val_loss: 3874.4824 - val_acc: 0.0000e+00\n",
            "Epoch 1414/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4134.5011 - acc: 0.0000e+00 - val_loss: 3875.4602 - val_acc: 0.0000e+00\n",
            "Epoch 1415/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 3789.5695 - acc: 0.0000e+00 - val_loss: 3875.9775 - val_acc: 0.0000e+00\n",
            "Epoch 1416/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4123.7945 - acc: 0.0000e+00 - val_loss: 3880.0877 - val_acc: 0.0000e+00\n",
            "Epoch 1417/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4289.0309 - acc: 0.0000e+00 - val_loss: 3874.4418 - val_acc: 0.0000e+00\n",
            "Epoch 1418/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4255.9641 - acc: 0.0000e+00 - val_loss: 3895.1647 - val_acc: 0.0000e+00\n",
            "Epoch 1419/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3493.7633 - acc: 0.0000e+00 - val_loss: 3879.4091 - val_acc: 0.0000e+00\n",
            "Epoch 1420/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4012.9440 - acc: 0.0000e+00 - val_loss: 3877.4271 - val_acc: 0.0000e+00\n",
            "Epoch 1421/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 3751.9847 - acc: 0.0000e+00 - val_loss: 3877.8738 - val_acc: 0.0000e+00\n",
            "Epoch 1422/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 4439.7129 - acc: 0.0000e+00 - val_loss: 3878.0348 - val_acc: 0.0000e+00\n",
            "Epoch 1423/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 5115.2144 - acc: 0.0000e+00 - val_loss: 3885.6253 - val_acc: 0.0000e+00\n",
            "Epoch 1424/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 3728.7791 - acc: 0.0000e+00 - val_loss: 3874.3040 - val_acc: 0.0000e+00\n",
            "Epoch 1425/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4147.0369 - acc: 0.0000e+00 - val_loss: 3875.8591 - val_acc: 0.0000e+00\n",
            "Epoch 1426/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 3864.6345 - acc: 0.0000e+00 - val_loss: 3874.2609 - val_acc: 0.0000e+00\n",
            "Epoch 1427/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4181.5878 - acc: 0.0000e+00 - val_loss: 3876.9556 - val_acc: 0.0000e+00\n",
            "Epoch 1428/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4148.2980 - acc: 0.0000e+00 - val_loss: 3874.1086 - val_acc: 0.0000e+00\n",
            "Epoch 1429/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 3946.7572 - acc: 0.0000e+00 - val_loss: 3875.0907 - val_acc: 0.0000e+00\n",
            "Epoch 1430/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 4153.4589 - acc: 0.0000e+00 - val_loss: 3874.9599 - val_acc: 0.0000e+00\n",
            "Epoch 1431/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 4223.2549 - acc: 0.0000e+00 - val_loss: 3887.7363 - val_acc: 0.0000e+00\n",
            "Epoch 1432/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4292.1791 - acc: 0.0000e+00 - val_loss: 3876.2267 - val_acc: 0.0000e+00\n",
            "Epoch 1433/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 3648.9591 - acc: 0.0000e+00 - val_loss: 3872.6634 - val_acc: 0.0000e+00\n",
            "Epoch 1434/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3707.2715 - acc: 0.0000e+00 - val_loss: 3876.0432 - val_acc: 0.0000e+00\n",
            "Epoch 1435/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3707.8383 - acc: 0.0000e+00 - val_loss: 3876.8485 - val_acc: 0.0000e+00\n",
            "Epoch 1436/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4016.9414 - acc: 0.0000e+00 - val_loss: 3873.0365 - val_acc: 0.0000e+00\n",
            "Epoch 1437/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4092.4689 - acc: 0.0000e+00 - val_loss: 3873.4125 - val_acc: 0.0000e+00\n",
            "Epoch 1438/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3800.3468 - acc: 0.0000e+00 - val_loss: 3872.8962 - val_acc: 0.0000e+00\n",
            "Epoch 1439/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3763.9111 - acc: 0.0000e+00 - val_loss: 3875.9566 - val_acc: 0.0000e+00\n",
            "Epoch 1440/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 3654.6442 - acc: 0.0000e+00 - val_loss: 3875.6470 - val_acc: 0.0000e+00\n",
            "Epoch 1441/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4179.0583 - acc: 0.0000e+00 - val_loss: 3875.6198 - val_acc: 0.0000e+00\n",
            "Epoch 1442/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4057.2910 - acc: 0.0000e+00 - val_loss: 3876.3247 - val_acc: 0.0000e+00\n",
            "Epoch 1443/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 4616.5830 - acc: 0.0000e+00 - val_loss: 3874.3301 - val_acc: 0.0000e+00\n",
            "Epoch 1444/1500\n",
            "348/348 [==============================] - 0s 110us/sample - loss: 4543.0859 - acc: 0.0000e+00 - val_loss: 3875.5533 - val_acc: 0.0000e+00\n",
            "Epoch 1445/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3558.6940 - acc: 0.0000e+00 - val_loss: 3874.5202 - val_acc: 0.0000e+00\n",
            "Epoch 1446/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 4222.0045 - acc: 0.0000e+00 - val_loss: 3876.0947 - val_acc: 0.0000e+00\n",
            "Epoch 1447/1500\n",
            "348/348 [==============================] - 0s 101us/sample - loss: 4042.9558 - acc: 0.0000e+00 - val_loss: 3887.4372 - val_acc: 0.0000e+00\n",
            "Epoch 1448/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4308.9608 - acc: 0.0000e+00 - val_loss: 3889.2377 - val_acc: 0.0000e+00\n",
            "Epoch 1449/1500\n",
            "348/348 [==============================] - 0s 132us/sample - loss: 3764.5376 - acc: 0.0000e+00 - val_loss: 3878.7151 - val_acc: 0.0000e+00\n",
            "Epoch 1450/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 4022.0777 - acc: 0.0000e+00 - val_loss: 3881.6288 - val_acc: 0.0000e+00\n",
            "Epoch 1451/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3897.1017 - acc: 0.0000e+00 - val_loss: 3877.0178 - val_acc: 0.0000e+00\n",
            "Epoch 1452/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3825.3599 - acc: 0.0000e+00 - val_loss: 3876.6058 - val_acc: 0.0000e+00\n",
            "Epoch 1453/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4137.5894 - acc: 0.0000e+00 - val_loss: 3874.2959 - val_acc: 0.0000e+00\n",
            "Epoch 1454/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4738.2481 - acc: 0.0000e+00 - val_loss: 3878.2357 - val_acc: 0.0000e+00\n",
            "Epoch 1455/1500\n",
            "348/348 [==============================] - 0s 105us/sample - loss: 4048.7524 - acc: 0.0000e+00 - val_loss: 3879.1563 - val_acc: 0.0000e+00\n",
            "Epoch 1456/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 3375.8833 - acc: 0.0000e+00 - val_loss: 3878.0988 - val_acc: 0.0000e+00\n",
            "Epoch 1457/1500\n",
            "348/348 [==============================] - 0s 96us/sample - loss: 3439.7504 - acc: 0.0000e+00 - val_loss: 3878.1902 - val_acc: 0.0000e+00\n",
            "Epoch 1458/1500\n",
            "348/348 [==============================] - 0s 109us/sample - loss: 3882.8991 - acc: 0.0000e+00 - val_loss: 3877.8956 - val_acc: 0.0000e+00\n",
            "Epoch 1459/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4280.3254 - acc: 0.0000e+00 - val_loss: 3878.9910 - val_acc: 0.0000e+00\n",
            "Epoch 1460/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3588.7983 - acc: 0.0000e+00 - val_loss: 3877.9430 - val_acc: 0.0000e+00\n",
            "Epoch 1461/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4298.9341 - acc: 0.0000e+00 - val_loss: 3876.5009 - val_acc: 0.0000e+00\n",
            "Epoch 1462/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 3901.3979 - acc: 0.0000e+00 - val_loss: 3878.5953 - val_acc: 0.0000e+00\n",
            "Epoch 1463/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3934.5356 - acc: 0.0000e+00 - val_loss: 3877.6267 - val_acc: 0.0000e+00\n",
            "Epoch 1464/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4392.4843 - acc: 0.0000e+00 - val_loss: 3879.5371 - val_acc: 0.0000e+00\n",
            "Epoch 1465/1500\n",
            "348/348 [==============================] - 0s 108us/sample - loss: 4117.2822 - acc: 0.0000e+00 - val_loss: 3875.6531 - val_acc: 0.0000e+00\n",
            "Epoch 1466/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3805.2491 - acc: 0.0000e+00 - val_loss: 3874.4301 - val_acc: 0.0000e+00\n",
            "Epoch 1467/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 4319.8011 - acc: 0.0000e+00 - val_loss: 3875.3973 - val_acc: 0.0000e+00\n",
            "Epoch 1468/1500\n",
            "348/348 [==============================] - 0s 98us/sample - loss: 4011.2807 - acc: 0.0000e+00 - val_loss: 3875.4982 - val_acc: 0.0000e+00\n",
            "Epoch 1469/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3935.0437 - acc: 0.0000e+00 - val_loss: 3878.3839 - val_acc: 0.0000e+00\n",
            "Epoch 1470/1500\n",
            "348/348 [==============================] - 0s 89us/sample - loss: 3822.6398 - acc: 0.0000e+00 - val_loss: 3877.9567 - val_acc: 0.0000e+00\n",
            "Epoch 1471/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 3736.3349 - acc: 0.0000e+00 - val_loss: 3874.8568 - val_acc: 0.0000e+00\n",
            "Epoch 1472/1500\n",
            "348/348 [==============================] - 0s 100us/sample - loss: 4047.6560 - acc: 0.0000e+00 - val_loss: 3874.2816 - val_acc: 0.0000e+00\n",
            "Epoch 1473/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3605.6750 - acc: 0.0000e+00 - val_loss: 3873.7630 - val_acc: 0.0000e+00\n",
            "Epoch 1474/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 3775.6886 - acc: 0.0000e+00 - val_loss: 3875.3691 - val_acc: 0.0000e+00\n",
            "Epoch 1475/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3855.1824 - acc: 0.0000e+00 - val_loss: 3876.0333 - val_acc: 0.0000e+00\n",
            "Epoch 1476/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4239.1710 - acc: 0.0000e+00 - val_loss: 3883.0952 - val_acc: 0.0000e+00\n",
            "Epoch 1477/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 3402.6615 - acc: 0.0000e+00 - val_loss: 3877.7012 - val_acc: 0.0000e+00\n",
            "Epoch 1478/1500\n",
            "348/348 [==============================] - 0s 88us/sample - loss: 3796.9359 - acc: 0.0000e+00 - val_loss: 3878.3303 - val_acc: 0.0000e+00\n",
            "Epoch 1479/1500\n",
            "348/348 [==============================] - 0s 102us/sample - loss: 4184.1570 - acc: 0.0000e+00 - val_loss: 3876.6711 - val_acc: 0.0000e+00\n",
            "Epoch 1480/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4263.3857 - acc: 0.0000e+00 - val_loss: 3885.1995 - val_acc: 0.0000e+00\n",
            "Epoch 1481/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3556.3808 - acc: 0.0000e+00 - val_loss: 3876.7404 - val_acc: 0.0000e+00\n",
            "Epoch 1482/1500\n",
            "348/348 [==============================] - 0s 99us/sample - loss: 4255.1520 - acc: 0.0000e+00 - val_loss: 3877.6517 - val_acc: 0.0000e+00\n",
            "Epoch 1483/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 4334.0760 - acc: 0.0000e+00 - val_loss: 3877.7265 - val_acc: 0.0000e+00\n",
            "Epoch 1484/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3833.6448 - acc: 0.0000e+00 - val_loss: 3883.5682 - val_acc: 0.0000e+00\n",
            "Epoch 1485/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3588.5972 - acc: 0.0000e+00 - val_loss: 3875.6882 - val_acc: 0.0000e+00\n",
            "Epoch 1486/1500\n",
            "348/348 [==============================] - 0s 87us/sample - loss: 3830.2341 - acc: 0.0000e+00 - val_loss: 3875.6172 - val_acc: 0.0000e+00\n",
            "Epoch 1487/1500\n",
            "348/348 [==============================] - 0s 94us/sample - loss: 4100.2813 - acc: 0.0000e+00 - val_loss: 3872.8833 - val_acc: 0.0000e+00\n",
            "Epoch 1488/1500\n",
            "348/348 [==============================] - 0s 97us/sample - loss: 4066.8159 - acc: 0.0000e+00 - val_loss: 3871.9625 - val_acc: 0.0000e+00\n",
            "Epoch 1489/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 3432.9094 - acc: 0.0000e+00 - val_loss: 3874.2863 - val_acc: 0.0000e+00\n",
            "Epoch 1490/1500\n",
            "348/348 [==============================] - 0s 85us/sample - loss: 3846.3484 - acc: 0.0000e+00 - val_loss: 3875.2011 - val_acc: 0.0000e+00\n",
            "Epoch 1491/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4696.0141 - acc: 0.0000e+00 - val_loss: 3892.5475 - val_acc: 0.0000e+00\n",
            "Epoch 1492/1500\n",
            "348/348 [==============================] - 0s 93us/sample - loss: 3684.1315 - acc: 0.0000e+00 - val_loss: 3878.0738 - val_acc: 0.0000e+00\n",
            "Epoch 1493/1500\n",
            "348/348 [==============================] - 0s 92us/sample - loss: 3957.0167 - acc: 0.0000e+00 - val_loss: 3877.7311 - val_acc: 0.0000e+00\n",
            "Epoch 1494/1500\n",
            "348/348 [==============================] - 0s 90us/sample - loss: 3859.5778 - acc: 0.0000e+00 - val_loss: 3873.2206 - val_acc: 0.0000e+00\n",
            "Epoch 1495/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 4326.6195 - acc: 0.0000e+00 - val_loss: 3873.0412 - val_acc: 0.0000e+00\n",
            "Epoch 1496/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3451.5175 - acc: 0.0000e+00 - val_loss: 3874.2088 - val_acc: 0.0000e+00\n",
            "Epoch 1497/1500\n",
            "348/348 [==============================] - 0s 91us/sample - loss: 3342.9298 - acc: 0.0000e+00 - val_loss: 3875.5167 - val_acc: 0.0000e+00\n",
            "Epoch 1498/1500\n",
            "348/348 [==============================] - 0s 95us/sample - loss: 3635.6162 - acc: 0.0000e+00 - val_loss: 3875.1001 - val_acc: 0.0000e+00\n",
            "Epoch 1499/1500\n",
            "348/348 [==============================] - 0s 103us/sample - loss: 3518.6427 - acc: 0.0000e+00 - val_loss: 3878.7534 - val_acc: 0.0000e+00\n",
            "Epoch 1500/1500\n",
            "348/348 [==============================] - 0s 86us/sample - loss: 3672.6191 - acc: 0.0000e+00 - val_loss: 3877.0577 - val_acc: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHRmUqWZwrIX",
        "colab_type": "code",
        "outputId": "9fea652a-c695-4d85-b974-184613304a20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "arrx = []\n",
        "arry = []\n",
        "arryyr = []\n",
        "\n",
        "#Generate graph of the model\n",
        "for i in range(0,800):\n",
        "    arrx.append(i)\n",
        "    prediction = model.predict([i]) \n",
        "    arry.append(prediction[0][0])\n",
        "    arryyr.append(prediction[0][0] * 12)\n",
        "\n",
        "#graph plot\n",
        "plt.scatter(arrx, arry)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f1eff1118d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAW40lEQVR4nO3df7BdZX3v8ff35AfGSImBkImENEoz\nOvaKwGQkDE6HKzdVqEOoCuKEW3SomWnpjFxureGSaUtHRrg6QTvt2ELpvdhSDSgckLG1uUDmThmM\nBk4gIFKCRckpkCgBuWCVwHP/2M+RTTw5e+2z195rr7Xfr5kzZ61nrb33N9n7fM5znvWstSKlhCSp\nWcaqLkCSVD7DXZIayHCXpAYy3CWpgQx3SWqguVUXAHDUUUellStXVl2GJNXKvffe+6OU0pLptg1F\nuK9cuZIdO3ZUXYYk1UpE/OBQ2xyWkaQGMtwlqYEMd0lqIMNdkhrIcJekBio0WyYiHgeeB14GDqSU\nVkfEYmALsBJ4HDg3pbQ/IgL4AnAm8CLw0ZTSfeWXLkn1s2l8F3//rR++pu2wuWNc9cHjOfvEY0p7\nnW6mQv7nlNKP2tY3AneklK6MiI15/VPAGcCq/HUy8MX8XZIabbrgLuJnB17hkht3ApQW8L3Mc18H\nnJaXrwe20Qr3dcCXUutawt+KiEURsSyl9GQvhUpSlWYb3EW9kuCz33xk4OGegH+OiAT8dUrpGmBp\nW2A/BSzNy8cAT7Q9dk9ue024R8QGYAPAihUrZle9JJVg/bX3cPdjz1RdBv/+7E9Le66i4f7ulNJk\nRBwNbI2I77VvTCmlHPyF5V8Q1wCsXr3aO4ZI6othCe4i3rRoQWnPVSjcU0qT+fveiLgFeBfw9NRw\nS0QsA/bm3SeBY9sevjy3SVJpxicmufTmB/jpS69UXUopxgI++d63lvZ8HcM9IhYCYyml5/PybwJ/\nBtwGXABcmb/fmh9yG/AHEfEVWgdSn3O8XVK36tTj7lVVs2WWAre0ZjgyF/iHlNI/RcR3gBsj4kLg\nB8C5ef9v0JoGuZvWVMiPlVatpEYYpeCeyanHLeaGj5/Sl+fuGO4ppe8D75ym/cfA6dO0J+CiUqqT\nVCtNGyrpxcL5c7jit99Ram+8G0NxyV9Jw298YpJP3rQTc7u/Pe6yGO6S+j6Hu07qENxFGO7SiBnl\nHvj5a1bw6bPfUXUZA2G4SyOi6b3zUQruIgx3qcGa0ktvylDJIBnuUgPVqZduj7s/DHepIYatlx7A\neoO7Moa7VHNV9NL7cUalymW4SzXVr7M8De5mMNylGim7l26QN5fhLtVA2b10Z580n+EuDamye+lz\nx4LPnfNOe+kjwnCXhkzZoV71BaxUDcNdGgJlX03RXroMd6lC9tLVL4a7VAEPkKrfDHdpgMoMdXvp\nmonhLg3A+MQkF2/ZWcpz2UtXEYa71Gdl9NY92UjdMtylPlq7eRuP7n1h1o+3l67ZMtylPuh1GMbL\n4KpXhrtUstlOb7SXrjIZ7lKJZjO+bi9d/WC4SyXpdnx91dEL2XrJaf0rSCPNcJdKcPIVW3n6+Z8X\n3t8hGPWb4S716Pg/+Sd+8rOXC+07FrD53BOc0qi+M9ylWep2RszSw+ez/bK1faxIepXhLs1CtzNi\nHIbRoI1VXYBUN+MTk10F+/lrVhjsGjh77lKX/vCm+wvt5/i6qmS4S104+YqtHHglddzvVw6bwwOX\nv28AFUnTc1hGKqjodMelh8832FU5w10qYO3mbYWCfdXRC50Ro6FguEsdrL/2nkJnnnrGqYaJ4S7N\nYNP4rkLXijHYNWwMd+kQis5lX3r4fINdQ8dwl6ZRdC67Z51qWBnu0jQuu2VXx33GwGDX0DLcpYOM\nT0zyws87Xwhs84dPGEA10uwUDveImBMRExFxe15/c0Rsj4jdEbElIubn9sPy+u68fWV/Spf641Nf\ne6DjPqcet9gzTzXUuum5fwJ4uG39KuDqlNKvAfuBC3P7hcD+3H513k+qhU3ju/jZgVdm3MeLgKkO\nCoV7RCwHfgv4m7wewHuAr+ZdrgfOzsvr8jp5++l5f2moFTmIumDemMGuWijac/888EfAVJfmSODZ\nlNKBvL4HmPob9RjgCYC8/bm8/2tExIaI2BERO/bt2zfL8qXyFDmI+pkPHD+ASqTedQz3iHg/sDel\ndG+ZL5xSuialtDqltHrJkiVlPrXUtSIHUR1nV50UuSrkqcBZEXEm8DrgV4AvAIsiYm7unS8HJvP+\nk8CxwJ6ImAscAfy49MqlEnU6iDpvDIdjVCsde+4ppUtTSstTSiuB84A7U0rrgbuAD+XdLgBuzcu3\n5XXy9jtTSp2vkSpVpMhB1M+e47RH1Usv89w/BVwSEbtpjalfl9uvA47M7ZcAG3srUeqvIgdRHY5R\n3XR1s46U0jZgW17+PvCuafb5D+CcEmqT+m7TuAdR1UyeoaqRdkOHXvv5a1bYa1ctGe4aWZvGdzHT\nwaB5Y/Dps98xsHqkMhnuGklFTljyIKrqzHDXSLr86w/NuH3eGA7HqNYMd42k/S++NON2e+2qO8Nd\nI6fTDBmnPqoJDHeNnE5j7U59VBMY7hop66+9Z8bt9trVFIa7Rsb4xCR3P/bMjPvYa1dTGO4aGZ0u\n6esMGTWJ4a6RUOSSvs6QUZMY7hoJnXrtXqtdTWO4q/GK9Nq9VruaxnBX43W6EceiBfMGVIk0OIa7\nGm18YrLjjTj+9KxfH1A10uAY7mq0TmPtXtJXTWW4q7GKjLV7SV81leGuxirSa5eaynBXI9lr16gz\n3NVIzpDRqDPc1TjOkJEMdzVQp167M2Q0Cgx3NUqRXrtj7RoFhrsapUivXRoFhrsaY9P4LnvtUma4\nqzFu6HD7PHvtGiWGuxph0/gu0gzb543Za9doMdxVe+MTkx1veu2NODRqDHfV3uVff2jG7d4+T6PI\ncFft7X/xpRm322vXKDLcVWubxme+ONiCeWP22jWSDHfVWqcZMp/5wPEDqkQaLoa7aqvTDBl77Rpl\nhrtqqcgMGXvtGmWGu2rJGTLSzAx31ZIzZKSZGe6qHWfISJ0Z7qodx9qlzgx31cr6a++Zcbu9dqml\nY7hHxOsi4tsRcX9EPBQRl+f2N0fE9ojYHRFbImJ+bj8sr+/O21f295+gUTE+Mcndjz0z4z722qWW\nIj33nwHvSSm9EzgBeF9ErAGuAq5OKf0asB+4MO9/IbA/t1+d95N6dtktM4+1O0NGelXHcE8t/y+v\nzstfCXgP8NXcfj1wdl5el9fJ20+PiCitYo2k8YlJXvj5yzPu4wwZ6VWFxtwjYk5E7AT2AluBx4Bn\nU0oH8i57gKku0zHAEwB5+3PAkdM854aI2BERO/bt29fbv0KN16nXfupxi+21S20KhXtK6eWU0gnA\ncuBdwNt6feGU0jUppdUppdVLlizp9enUYEV67Td8/JQBVSPVQ1ezZVJKzwJ3AacAiyJibt60HJjM\ny5PAsQB5+xHAj0upViOp002vFy2YN6BKpPooMltmSUQsyssLgLXAw7RC/kN5twuAW/PybXmdvP3O\nlNJM13eSDml8YrLjTa//9KxfH1A1Un3M7bwLy4DrI2IOrV8GN6aUbo+I7wJfiYhPAxPAdXn/64C/\ni4jdwDPAeX2oWyOi01j7+WtWONYuTaNjuKeUHgBOnKb9+7TG3w9u/w/gnFKq00grMtbuTa+l6XmG\nqoZWkV67pOkZ7hpK9tql3hjuGkrOkJF6Y7hr6DhDRuqd4a6h4wwZqXeGu4aKY+1SOQx3DZVOY+3O\nkJGKMdw1NDaN7+o41m6vXSrGcNfQuKHD7fOcISMVZ7hrKGwa30WnCxA5Q0YqznBX5cYnJjve9NoZ\nMlJ3DHdV7vKvPzTj9nljjrVL3TLcVbn9L74043Zvnyd1z3BXpTaNz3zC0oJ5Yw7HSLNguKtSnWbI\nfOYDxw+oEqlZDHdVptMMGXvt0uwZ7qpEkRky9tql2TPcVYlOFwebN4a9dqkHhrsGrsjFwZwhI/XG\ncNfAdeq1O9Yu9c5w10AV6bU71i71znDXQHW6pK+9dqkchrsGpsglfe21S+Uw3DUwnU5Ystculcdw\n10AUuaSvvXapPIa7+s5L+kqDZ7ir74qcsOQlfaVyGe7qK09YkqphuKuvPGFJqobhrr7xhCWpOoa7\n+sYTlqTqGO7qC09YkqpluKsvOk19tNcu9ZfhrtJ1ui8q2GuX+s1wV+k8YUmqnuGuUq3dvG3G7Z6w\nJA2G4a7SrL/2Hh7d+8KM+3jCkjQYhrtKsWl8F3c/9syM+3hfVGlwDHf1rMiFwcBeuzRIHcM9Io6N\niLsi4rsR8VBEfCK3L46IrRHxaP7+xtweEfHnEbE7Ih6IiJP6/Y9Qtf7wpvs77nPqcYvttUsDVKTn\nfgD47ymltwNrgIsi4u3ARuCOlNIq4I68DnAGsCp/bQC+WHrVGhprN2/jwCszX6l9DLjh46cMpiBJ\nQIFwTyk9mVK6Ly8/DzwMHAOsA67Pu10PnJ2X1wFfSi3fAhZFxLLSK1fl1m7e1vEAKsDmDzscIw1a\nV2PuEbESOBHYDixNKT2ZNz0FLM3LxwBPtD1sT247+Lk2RMSOiNixb9++LstW1YrMjAHntEtVKRzu\nEfEG4GvAxSmln7RvSykl6HgXtddIKV2TUlqdUlq9ZMmSbh6qio1PTHacGQOtcXbntEvVKBTuETGP\nVrDfkFK6OTc/PTXckr/vze2TwLFtD1+e29QA4xOTXLxlZ8f9HGeXqlVktkwA1wEPp5Q2t226Dbgg\nL18A3NrW/jt51swa4Lm24RvV2KbxXYWCHRxnl6o2t8A+pwL/FdgVEVM/2f8DuBK4MSIuBH4AnJu3\nfQM4E9gNvAh8rNSKVYlN47sKzWUH+PyHT3CcXapYx3BPKf0LEIfYfPo0+yfgoh7r0hAx2KX68QxV\nzaibYPdEJWl4FBmW0Yhaf+09hWbFAKw6eqEHUKUhYrhrWidfsZWnn/95oX1XHb2QrZec1t+CJHXF\ncNdrFJ3qOOXU4xbbY5eGkOGuX+hmfB0MdmmYGe4CuhtfB8fYpWFnuKvwBcCm2GOXhp/hPsLGJya5\nZMtOXuniMeevWeH1YqQaMNxHVLfj62MBm8/1BCWpLgz3ETSb8XWnOkr1YriPkG6nOYLj61JdGe4j\notuDpuD4ulRnhnvDdTu2PsVgl+rNcG+o2QzBAMwdCz53zjs9cCrVnOHeMOMTk3zypp281M38xswD\np1JzGO4N0Uuog8MwUtMY7g0wm4OlU+ytS81kuNfYbA+WQuvWWld71ySpsQz3GprtwdIpzl2Xms9w\nr5HZXAum3dLD57P9srWl1iRpOBnuNdBrqIMHTKVRY7gPsV7G1KcY6tJoMtyHUK9j6mCoS6POcB8i\nZQy/eLBUEhjuQ6GMUPeyAZLaGe4VKmNM3VCXNB3DvQJlhLp3RpI0E8N9gMoIdfBgqaTODPcB6Pa2\ndtNx+EVSNwz3Pun1Ko1TDHVJs2G4l6ysUHdMXVIvDPeSlDWeDo6pS+qd4d6jMs4mBThs7hhXffB4\ne+qSSmG4z1JZPXXPKJXUD4Z7l8qY+QKGuqT+MtwLKivUHU+XNAiG+wzGJya59OYH+GmvU18w1CUN\nluE+jTIu5DXFUJdUBcO9TVmh7olHkqrWMdwj4m+B9wN7U0r/KbctBrYAK4HHgXNTSvsjIoAvAGcC\nLwIfTSnd15/Sy1PWzBdDXdKwKNJz/9/AXwBfamvbCNyRUroyIjbm9U8BZwCr8tfJwBfz96FU1kHS\nhfPncMVvv8NQlzQ0OoZ7Sun/RsTKg5rXAafl5euBbbTCfR3wpZRSAr4VEYsiYllK6cmyCu5VWYEO\njqdLGl6zHXNf2hbYTwFL8/IxwBNt++3Jbb8U7hGxAdgAsGLFilmWUUyZlwYA56hLGn49H1BNKaWI\nSLN43DXANQCrV6/u+vGdlB3oYE9dUn3MNtyfnhpuiYhlwN7cPgkc27bf8tzWV/0I8ikeJJVUR7MN\n99uAC4Ar8/db29r/ICK+QutA6nP9Gm8v69K6h2KoS6qzIlMhv0zr4OlREbEH+BNaoX5jRFwI/AA4\nN+/+DVrTIHfTmgr5sT7UXNqVGKfjzBdJTVBktsxHDrHp9Gn2TcBFvRbVyWe/+Ujpz+lBUklNUssz\nVP/92Z+W8jweIJXUVLUM9zctWsDkLAPeYRdJo6CW4f7J9761qzF3A13SqKlluE+F9HSzZQxySapp\nuEMr4A1wSZreWNUFSJLKZ7hLUgMZ7pLUQIa7JDWQ4S5JDRStKwZUXETEPlrXqJmNo4AflVhOWayr\ne8Nam3V1x7q600tdv5pSWjLdhqEI915ExI6U0uqq6ziYdXVvWGuzru5YV3f6VZfDMpLUQIa7JDVQ\nE8L9mqoLOATr6t6w1mZd3bGu7vSlrtqPuUuSflkTeu6SpIMY7pLUQLUO94h4X0Q8EhG7I2LjgF/7\nbyNib0Q82Na2OCK2RsSj+fsbc3tExJ/nOh+IiJP6WNexEXFXRHw3Ih6KiE8MQ20R8bqI+HZE3J/r\nujy3vzkitufX3xIR83P7YXl9d96+sh91tdU3JyImIuL2YakrIh6PiF0RsTMiduS2YfiMLYqIr0bE\n9yLi4Yg4peq6IuKt+f9p6usnEXFx1XXl1/pv+TP/YER8Of8s9P/zlVKq5RcwB3gMeAswH7gfePsA\nX/83gJOAB9va/iewMS9vBK7Ky2cC/wgEsAbY3se6lgEn5eXDgX8F3l51bfn535CX5wHb8+vdCJyX\n2/8K+L28/PvAX+Xl84AtfX4/LwH+Abg9r1deF/A4cNRBbcPwGbse+N28PB9YNAx1tdU3B3gK+NWq\n6wKOAf4NWND2ufroID5fff1P7vMbeArwzbb1S4FLB1zDSl4b7o8Ay/LyMuCRvPzXwEem228ANd4K\nrB2m2oDXA/cBJ9M6M2/uwe8p8E3glLw8N+8XfapnOXAH8B7g9vwDPwx1Pc4vh3ul7yNwRA6rGKa6\nDqrlN4G7h6EuWuH+BLA4f15uB947iM9XnYdlpv7TpuzJbVVamlJ6Mi8/BSzNy5XUmv+kO5FWL7ny\n2vLQx05gL7CV1l9ez6aUDkzz2r+oK29/DjiyH3UBnwf+CJi6r9eRQ1JXAv45Iu6NiA25rer38c3A\nPuB/5WGsv4mIhUNQV7vzgC/n5UrrSilNAp8Dfgg8Sevzci8D+HzVOdyHWmr96q1snmlEvAH4GnBx\nSukn7duqqi2l9HJK6QRaPeV3AW8bdA0Hi4j3A3tTSvdWXcs03p1SOgk4A7goIn6jfWNF7+NcWsOR\nX0wpnQi8QGu4o+q6AMhj12cBNx28rYq68hj/Olq/FN8ELATeN4jXrnO4TwLHtq0vz21VejoilgHk\n73tz+0BrjYh5tIL9hpTSzcNUG0BK6VngLlp/ji6KiKnbPba/9i/qytuPAH7ch3JOBc6KiMeBr9Aa\nmvnCENQ11esjpbQXuIXWL8Sq38c9wJ6U0va8/lVaYV91XVPOAO5LKT2d16uu678A/5ZS2pdSegm4\nmdZnru+frzqH+3eAVfmo83xaf4rdVnFNtwEX5OULaI13T7X/Tj5CvwZ4ru1PxVJFRADXAQ+nlDYP\nS20RsSQiFuXlBbSOAzxMK+Q/dIi6pur9EHBn7nmVKqV0aUppeUppJa3P0J0ppfVV1xURCyPi8Kll\nWuPID1Lx+5hSegp4IiLemptOB75bdV1tPsKrQzJTr19lXT8E1kTE6/PP5tT/V/8/X/08sNHvL1pH\nvP+V1tjtZQN+7S/TGkN7iVZv5kJaY2N3AI8C/wdYnPcN4C9znbuA1X2s6920/vR8ANiZv86sujbg\neGAi1/Ug8Me5/S3At4HdtP6UPiy3vy6v787b3zKA9/Q0Xp0tU2ld+fXvz18PTX2+q34f82udAOzI\n7+U48MYhqWshrV7uEW1tw1DX5cD38uf+74DDBvH58vIDktRAdR6WkSQdguEuSQ1kuEtSAxnuktRA\nhrskNZDhLkkNZLhLUgP9fxGxSbePcKyEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvoQ0CVO_xnu",
        "colab_type": "code",
        "outputId": "455ac6eb-f0aa-4de0-8a8e-c792dee0cf30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#graph model with data overlain to visually see how well the model fits\n",
        "plt.scatter(arrx, arry)\n",
        "plt.scatter(arrMonth, arrWeight)\n",
        "plt.show()\n",
        "\n",
        "#Seems to fit the data pretty well!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37HYuWJTPfB_",
        "colab_type": "code",
        "outputId": "f03e9208-6a13-413a-9416-271b9e4a0da0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "arrYM = []\n",
        "for i in arrYear:\n",
        "  arrYM.append(i*12)\n",
        "  \n",
        "plt.plot(arrx, arryyr)\n",
        "plt.scatter(arrYM, arrWeightyr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSURBX0QkiSjoi4gkEQV9EZEk8v8By5Tk5OyqgBYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_fUTSFm__Jd",
        "colab_type": "code",
        "outputId": "3159eca1-a1fb-491d-e7f8-3bf487dc8e2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Allow user to enter a year to predict:\n",
        "\n",
        "def ytm(x):\n",
        "    return((x-1960) * 12)\n",
        "\n",
        "print(\"Enter a year to predict production:\")\n",
        "inval = int(input())\n",
        "sum = 0  \n",
        "for i in range(ytm(inval), ytm(inval) + 12):\n",
        "  pred = model.predict([i])\n",
        "  sum += pred[0][0]\n",
        "\n",
        "print(\"Predicted Average Monthly Production Prediction (In millions of pounds): \", sum / 12)\n",
        "print(\"Predicted Annual Production (In millions of pounds): \", sum)\n",
        "\n",
        "try:\n",
        "  yp = arrWeightyr[inval - 1960]\n",
        "  print(\"The actual annual production weight: \", yp)\n",
        "  print(\"The percent error on the prediction was: \", 100*(abs(yp - sum)/yp), \"%\")\n",
        "except:\n",
        "  print(\"No Production Data was found for this Date\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter a year to predict production:\n",
            "2018\n",
            "Predicted Average Monthly Production Prediction (In millions of pounds):  491.8091176350911\n",
            "Predicted Annual Production (In millions of pounds):  5901.709411621094\n",
            "No Production Data was found for this Date\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUEJ77AFAbGl",
        "colab_type": "code",
        "outputId": "da56c913-2fe4-4d1f-9e20-d8b7e8b131ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#export trained model for future use\n",
        "\n",
        "\n",
        "model.save(\"turkey.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "files.download('turkey.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}